{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /opt/homebrew/anaconda3/lib/python3.12/site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "\n",
    "from einops import repeat, rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.models.vision_transformer import Block\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamkitshah1262\u001b[0m (\u001b[33msamkitshah1262-warner-bros-discovery\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sshah/2024/projects/gsoc/ml4sci/fm/wandb/run-20250320_011631-nzmih1iq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational/runs/nzmih1iq' target=\"_blank\">youthful-lake-20</a></strong> to <a href='https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational' target=\"_blank\">https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational/runs/nzmih1iq' target=\"_blank\">https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational/runs/nzmih1iq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/samkitshah1262-warner-bros-discovery/deeplens-foundational/runs/nzmih1iq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x336f600b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"deeplens-foundational\", entity=\"samkitshah1262-warner-bros-discovery\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    SEED = 1\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 200\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    MASK_RATIO = 0.75\n",
    "    NUM_CLASSES = 3\n",
    "    IMG_SIZE = (64, 64)\n",
    "    USE_SAVED_MODEL = False\n",
    "    CKPT_PATH = \"./model_weights.pth\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(config.SEED)\n",
    "np.random.seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.load(\"dataset/no_sub/no_sub_sim_6956151560647865808482838248806684.npy\")  # Load .npy file\n",
    "img = torch.tensor(img, dtype=torch.float32)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_ROOT = \"/Users/sshah/2024/projects/gsoc/ml4sci/fm/Dataset\"\n",
    "DATA_PATH_AXION = \"/axion\"\n",
    "DATA_PATH_CDM = \"/cdm\"\n",
    "DATA_PATH_NO_SUB = \"/no_sub\"\n",
    "\n",
    "OUTPUT_ROOT = \"/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpyDirectoryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "\n",
    "        class_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        class_names.sort()\n",
    "        print(class_names)\n",
    "        for idx, class_name in enumerate(class_names):\n",
    "            self.class_to_idx[class_name] = idx\n",
    "\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            for file_name in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                if file_path.endswith('.npy') and os.path.isfile(file_path):\n",
    "                    self.samples.append((file_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load the data with allow_pickle=True since it's an object array\n",
    "            data = np.load(file_path, allow_pickle=True)\n",
    "            \n",
    "            # Extract the first element which contains the (64, 64) array\n",
    "            if data.dtype == np.dtype('object') and data.size > 0:\n",
    "                data = data[0]\n",
    "            \n",
    "            # Convert to tensor and ensure it's float\n",
    "            data_tensor = torch.from_numpy(data).float()\n",
    "            \n",
    "            # Add channel dimension if needed\n",
    "            if data_tensor.ndim == 2:\n",
    "                data_tensor = data_tensor.unsqueeze(0)\n",
    "                \n",
    "            # Apply transforms if any\n",
    "            if self.transform:\n",
    "                data_tensor = self.transform(data_tensor)\n",
    "            \n",
    "            return data_tensor, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            # Return a placeholder if loading fails\n",
    "            placeholder = torch.zeros((1, 64, 64))\n",
    "            return placeholder, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(root_dir, batch_size=32, train_ratio=0.8, num_workers=4, seed=42):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    full_dataset = NpyDirectoryDataset(root_dir=root_dir,transform=transforms)\n",
    "    \n",
    "    if len(full_dataset) == 0:\n",
    "        raise ValueError(f\"No valid .npy files found in {root_dir}. Please check the directory structure.\")\n",
    "    \n",
    "    print(f\"Found {len(full_dataset)} .npy files total\")\n",
    "    print(f\"Class mapping: {full_dataset.class_to_idx}\")\n",
    "\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(train_ratio * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    class_loaders = {}\n",
    "\n",
    "    class_names = list(full_dataset.class_to_idx.keys())\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_idx = full_dataset.class_to_idx[class_name]\n",
    "        class_indices = [i for i, (_, label) in enumerate(full_dataset.samples) if label == class_idx]\n",
    "        \n",
    "        if len(class_indices) == 0:\n",
    "            print(f\"Warning: No samples found for class {class_name}\")\n",
    "            continue\n",
    "\n",
    "        class_train_indices = [idx for idx in range(len(full_dataset)) if \n",
    "                              idx in train_dataset.indices and \n",
    "                              full_dataset.samples[idx][1] == class_idx]\n",
    "                              \n",
    "        class_val_indices = [idx for idx in range(len(full_dataset)) if \n",
    "                            idx in val_dataset.indices and \n",
    "                            full_dataset.samples[idx][1] == class_idx]\n",
    "        \n",
    "        class_train_subset = torch.utils.data.Subset(full_dataset, class_train_indices)\n",
    "        class_val_subset = torch.utils.data.Subset(full_dataset, class_val_indices)\n",
    "\n",
    "        class_loaders[f\"{class_name}_train\"] = DataLoader(\n",
    "            class_train_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        \n",
    "        class_loaders[f\"{class_name}_val\"] = DataLoader(\n",
    "            class_val_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "\n",
    "    loaders = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader,\n",
    "        **class_loaders\n",
    "    }\n",
    "\n",
    "    print(\"\\nDataset information:\")\n",
    "    print(f\"Training set: {len(train_dataset)} samples\")\n",
    "    print(f\"Validation set: {len(val_dataset)} samples\")\n",
    "    \n",
    "    for name, loader in class_loaders.items():\n",
    "        print(f\"{name}: {len(loader.dataset)} samples\")\n",
    "    \n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['axion', 'cdm', 'no_sub']\n",
      "Found 89104 .npy files total\n",
      "Class mapping: {'axion': 0, 'cdm': 1, 'no_sub': 2}\n",
      "\n",
      "Dataset information:\n",
      "Training set: 80193 samples\n",
      "Validation set: 8911 samples\n",
      "axion_train: 26981 samples\n",
      "axion_val: 2915 samples\n",
      "cdm_train: 26723 samples\n",
      "cdm_val: 3036 samples\n",
      "no_sub_train: 26489 samples\n",
      "no_sub_val: 2960 samples\n"
     ]
    }
   ],
   "source": [
    "root_directory = DATA_PATH_ROOT\n",
    "\n",
    "loaders = create_data_loaders(\n",
    "    root_dir=root_directory,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    train_ratio=0.9,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_indexes(size : int):\n",
    "    forward_indexes = np.arange(size)\n",
    "    np.random.shuffle(forward_indexes)\n",
    "    backward_indexes = np.argsort(forward_indexes)\n",
    "    return forward_indexes, backward_indexes\n",
    "\n",
    "def take_indexes(sequences, indexes):\n",
    "    return torch.gather(sequences, 0, repeat(indexes, 't b -> t b c', c=sequences.shape[-1]))\n",
    "\n",
    "class PatchShuffle(torch.nn.Module):\n",
    "    def __init__(self, ratio) -> None:\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def forward(self, patches : torch.Tensor):\n",
    "        T, B, C = patches.shape\n",
    "        remain_T = int(T * (1 - self.ratio))\n",
    "\n",
    "        indexes = [random_indexes(T) for _ in range(B)]\n",
    "        forward_indexes = torch.as_tensor(np.stack([i[0] for i in indexes], axis=-1), dtype=torch.long).to(patches.device)\n",
    "        backward_indexes = torch.as_tensor(np.stack([i[1] for i in indexes], axis=-1), dtype=torch.long).to(patches.device)\n",
    "\n",
    "        patches = take_indexes(patches, forward_indexes)\n",
    "        patches = patches[:remain_T]\n",
    "\n",
    "        return patches, forward_indexes, backward_indexes\n",
    "\n",
    "class MAE_Encoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=64,\n",
    "                 patch_size=4,\n",
    "                 emb_dim=192,\n",
    "                 num_layer=12,\n",
    "                 num_head=3,\n",
    "                 mask_ratio=0.75,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.cls_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** 2, 1, emb_dim))\n",
    "        self.shuffle = PatchShuffle(mask_ratio)\n",
    "\n",
    "        self.patchify = torch.nn.Conv2d(1, emb_dim, patch_size, patch_size)\n",
    "\n",
    "        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) for _ in range(num_layer)])\n",
    "\n",
    "        self.layer_norm = torch.nn.LayerNorm(emb_dim)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        trunc_normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "    def forward(self, img):\n",
    "        patches = self.patchify(img)\n",
    "        patches = rearrange(patches, 'b c h w -> (h w) b c')\n",
    "        patches = patches + self.pos_embedding\n",
    "\n",
    "        patches, forward_indexes, backward_indexes = self.shuffle(patches)\n",
    "\n",
    "        patches = torch.cat([self.cls_token.expand(-1, patches.shape[1], -1), patches], dim=0)\n",
    "        patches = rearrange(patches, 't b c -> b t c')\n",
    "        features = self.layer_norm(self.transformer(patches))\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "\n",
    "        return features, backward_indexes\n",
    "\n",
    "class MAE_Decoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=64,\n",
    "                 patch_size=4,\n",
    "                 emb_dim=192,\n",
    "                 num_layer=4,\n",
    "                 num_head=3,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** 2 + 1, 1, emb_dim))\n",
    "\n",
    "        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) for _ in range(num_layer)])\n",
    "\n",
    "        self.head = torch.nn.Linear(emb_dim,  * patch_size ** 2)\n",
    "        self.patch2img = Rearrange('(h w) b (c p1 p2) -> b c (h p1) (w p2)', p1=patch_size, p2=patch_size, h=image_size//patch_size)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.mask_token, std=.02)\n",
    "        trunc_normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "    def forward(self, features, backward_indexes):\n",
    "        T = features.shape[0]\n",
    "        backward_indexes = torch.cat([torch.zeros(1, backward_indexes.shape[1]).to(backward_indexes), backward_indexes + 1], dim=0)\n",
    "        features = torch.cat([features, self.mask_token.expand(backward_indexes.shape[0] - features.shape[0], features.shape[1], -1)], dim=0)\n",
    "        features = take_indexes(features, backward_indexes)\n",
    "        features = features + self.pos_embedding\n",
    "\n",
    "        features = rearrange(features, 't b c -> b t c')\n",
    "        features = self.transformer(features)\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "        features = features[1:]\n",
    "\n",
    "        patches = self.head(features)\n",
    "        mask = torch.zeros_like(patches)\n",
    "        mask[T-1:] = 1\n",
    "        mask = take_indexes(mask, backward_indexes[1:] - 1)\n",
    "        img = self.patch2img(patches)\n",
    "        mask = self.patch2img(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "class MAE_ViT(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=64,\n",
    "                 patch_size=4,\n",
    "                 emb_dim=192,\n",
    "                 encoder_layer=12,\n",
    "                 encoder_head=3,\n",
    "                 decoder_layer=4,\n",
    "                 decoder_head=3,\n",
    "                 mask_ratio=0.75,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MAE_Encoder(image_size, patch_size, emb_dim, encoder_layer, encoder_head, mask_ratio)\n",
    "        self.decoder = MAE_Decoder(image_size, patch_size, emb_dim, decoder_layer, decoder_head)\n",
    "\n",
    "    def forward(self, img):\n",
    "        features, backward_indexes = self.encoder(img)\n",
    "        predicted_img, mask = self.decoder(features,  backward_indexes)\n",
    "        return predicted_img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, betas=(0.9, 0.95), weight_decay=config.WEIGHT_DECAY)\n",
    "# def lr_func(epoch):\n",
    "#     return min((epoch + 1) / (200 + 1e-8), 0.5 * (math.cos(epoch / config.EPOCHS * math.pi) + 1))\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = loaders['no_sub_train']\n",
    "# val_dataloader = loaders['no_sub_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_mae(model, train_loader, optimizer, device, epoch):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    \n",
    "#     for images, _ in progress_bar:\n",
    "#         images = images.to(device)\n",
    "#         # print(\"Image shape before model:\", images.shape)   \n",
    "#         images = images.clamp(0, 1)\n",
    "#         # images = images.repeat(1, 3, 1, 1)\n",
    "#         optimizer.zero_grad()\n",
    "#         reconstructed, mask = model(images)\n",
    "#         loss = F.mse_loss(reconstructed * mask, images * mask)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item() * images.size(0)\n",
    "#         progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "#     return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# def validate_mae(model, val_loader, device, epoch):\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, _ in progress_bar:\n",
    "#             images = images.to(device)\n",
    "#             images = images.clamp(0, 1)\n",
    "#             # images = images.repeat(1, 3, 1, 1)\n",
    "#             reconstructed, mask = model(images)\n",
    "#             loss = F.mse_loss(reconstructed * mask, images * mask)\n",
    "            \n",
    "#             total_loss += loss.item() * images.size(0)\n",
    "#             progress_bar.set_postfix({'val_loss': loss.item()})\n",
    "    \n",
    "#     return total_loss / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss = float('inf')\n",
    "# for epoch in range(75):\n",
    "#     train_loss = train_mae(model, train_dataloader, optimizer, device, epoch)\n",
    "#     val_loss = validate_mae(model, val_dataloader, device, epoch)\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}/{config.EPOCHS}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "#     wandb.log({\n",
    "#         \"epoch\": epoch,\n",
    "#         \"train_loss\": train_loss,\n",
    "#         \"val_loss\": val_loss,\n",
    "#     })\n",
    "\n",
    "#     # Save best model\n",
    "#     if val_loss < best_loss:\n",
    "#         best_loss = val_loss\n",
    "#         torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': val_loss,\n",
    "#         }, \"best_mae_model2.pth\")\n",
    "#         print(f\"Saved new best model with val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_loader = loaders['train']\n",
    "total_val_loader = loaders['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_SHOW_CPP_STACKTRACES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, add this at the top of your training cell\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# class ViT_Classifier(torch.nn.Module):\n",
    "#     def __init__(self, encoder : MAE_Encoder, num_classes=3) -> None:\n",
    "#         super().__init__()\n",
    "#         encoder.mask_ratio = 0\n",
    "#         self.cls_token = encoder.cls_token\n",
    "#         self.pos_embedding = encoder.pos_embedding\n",
    "#         self.patchify = encoder.patchify\n",
    "#         self.transformer = encoder.transformer\n",
    "#         self.layer_norm = encoder.layer_norm\n",
    "#         self.head = torch.nn.Linear(self.pos_embedding.shape[-1], num_classes)\n",
    "\n",
    "#     def forward(self, img):\n",
    "#         # Enable anomaly detection\n",
    "#         with torch.autograd.detect_anomaly():\n",
    "#             patches = self.patchify(img)\n",
    "#             print(f\"After patchify shape: {patches.shape}\")\n",
    "            \n",
    "#             patches = rearrange(patches, 'b c h w -> (h w) b c')\n",
    "#             print(f\"After first rearrange shape: {patches.shape}\")\n",
    "            \n",
    "#             patches = patches + self.pos_embedding\n",
    "#             print(f\"After adding pos_embedding shape: {patches.shape}\")\n",
    "            \n",
    "#             patches = torch.cat([self.cls_token.expand(-1, patches.shape[1], -1), patches], dim=0)\n",
    "#             print(f\"After adding cls_token shape: {patches.shape}\")\n",
    "            \n",
    "#             patches = rearrange(patches, 't b c -> b t c')\n",
    "#             print(f\"After second rearrange shape: {patches.shape}\")\n",
    "            \n",
    "#             features = self.layer_norm(self.transformer(patches))\n",
    "#             print(f\"After transformer shape: {features.shape}\")\n",
    "            \n",
    "#             # Ensure tensor is contiguous before reshaping\n",
    "#             features = features.contiguous()\n",
    "#             cls_token_features = features[:, 0, :]\n",
    "#             print(f\"Classifier token features shape: {cls_token_features.shape}\")\n",
    "            \n",
    "#             logits = self.head(cls_token_features)\n",
    "#             print(f\"Final logits shape: {logits.shape}\")\n",
    "            \n",
    "#             return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_Classifier(torch.nn.Module):\n",
    "    def __init__(self, encoder: MAE_Encoder, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        # Freeze encoder parameters\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(192),  # Normalize input features\n",
    "            nn.Linear(192, 256),\n",
    "            nn.GELU(),  # GELU activation often works better than ReLU\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.constant_(module.bias, 0)\n",
    "\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Add channel dimension if needed\n",
    "        # if x.size(1) == 1:\n",
    "        #     x = x.repeat(1, 3, 1, 1)\n",
    "            \n",
    "        # Get features from encoder\n",
    "        with torch.no_grad():\n",
    "            features, _ = self.encoder(x)\n",
    "            # Take the CLS token features (first token)\n",
    "            cls_features = features[0]  # Shape: [batch_size, embedding_dim]\n",
    "            # print(\"cls_features: \",cls_features)\n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(cls_features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae = MAE_ViT(\n",
    "#         image_size=64,\n",
    "#         patch_size=4,\n",
    "#         emb_dim=192,\n",
    "#         encoder_layer=12,\n",
    "#         encoder_head=3,\n",
    "#         decoder_layer=4,\n",
    "#         decoder_head=3,\n",
    "#         mask_ratio=0\n",
    "# ).to(device)\n",
    "# mae.load_state_dict(torch.load('best_mae_model2.pth')['model_state_dict'])\n",
    "# model = ViT_Classifier(mae.encoder).to(device)\n",
    "# criterion = nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_roc(model, loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.cuda()\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    probs = torch.cat(all_probs).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels == i, probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    roc_auc[\"macro\"] = np.mean(list(roc_auc.values()))\n",
    "    \n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, train_loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(\"Image shape before model:\", images.shape)   \n",
    "        images = images.clamp(0, 1)\n",
    "        # images = images.repeat(1, 3, 1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        # print(f\"Input image shape: {images.shape}\")\n",
    "        outputs = model(images)\n",
    "        # print(f\"Model output shape: {outputs.shape}\")\n",
    "        # print(f\"Labels shape: {labels.shape}\")\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        all_probs.append(probs.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        loss = criterion(outputs, labels)\n",
    "        # print(f\"Loss value: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    probs = torch.cat(all_probs).detach().numpy()\n",
    "    labels = torch.cat(all_labels).detach().numpy()\n",
    "\n",
    "    macro_auc = roc_auc_score(labels, probs, multi_class='ovr', average='macro')\n",
    "    class_auc = roc_auc_score(labels, probs, multi_class='ovr', average=None)\n",
    "    \n",
    "    return macro_auc, class_auc , total_loss/len(train_loader.dataset)\n",
    "\n",
    "def validate_classifier(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = images.clamp(0, 1)\n",
    "            # images = images.repeat(1, 3, 1, 1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'val_loss': loss.item()})\n",
    "        \n",
    "    probs = torch.cat(all_probs).detach().numpy()\n",
    "    labels = torch.cat(all_labels).detach().numpy()\n",
    "\n",
    "    macro_auc = roc_auc_score(labels, probs, multi_class='ovr', average='macro')\n",
    "    class_auc = roc_auc_score(labels, probs, multi_class='ovr', average=None)\n",
    "    \n",
    "    return macro_auc, class_auc , total_loss/len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value after * must be an iterable, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mae \u001b[38;5;241m=\u001b[39m MAE_ViT(\n\u001b[1;32m      2\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      3\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      4\u001b[0m     emb_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m192\u001b[39m,\n\u001b[1;32m      5\u001b[0m     encoder_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m      6\u001b[0m     encoder_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      7\u001b[0m     decoder_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      8\u001b[0m     decoder_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      9\u001b[0m     mask_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m mae\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_mae_model2.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m ViT_Classifier(mae\u001b[38;5;241m.\u001b[39mencoder)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[13], line 128\u001b[0m, in \u001b[0;36mMAE_ViT.__init__\u001b[0;34m(self, image_size, patch_size, emb_dim, encoder_layer, encoder_head, decoder_layer, decoder_head, mask_ratio)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m MAE_Encoder(image_size, patch_size, emb_dim, encoder_layer, encoder_head, mask_ratio)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m MAE_Decoder(image_size, patch_size, emb_dim, decoder_layer, decoder_head)\n",
      "Cell \u001b[0;32mIn[13], line 84\u001b[0m, in \u001b[0;36mMAE_Decoder.__init__\u001b[0;34m(self, image_size, patch_size, emb_dim, num_layer, num_head)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mzeros((image_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m patch_size) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, emb_dim))\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m[Block(emb_dim, num_head) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layer)])\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(emb_dim,  \u001b[38;5;241m*\u001b[39m patch_size \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch2img \u001b[38;5;241m=\u001b[39m Rearrange(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(h w) b (c p1 p2) -> b c (h p1) (w p2)\u001b[39m\u001b[38;5;124m'\u001b[39m, p1\u001b[38;5;241m=\u001b[39mpatch_size, p2\u001b[38;5;241m=\u001b[39mpatch_size, h\u001b[38;5;241m=\u001b[39mimage_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mpatch_size)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_weight()\n",
      "\u001b[0;31mTypeError\u001b[0m: Value after * must be an iterable, not int"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "mae = MAE_ViT(\n",
    "    image_size=64,\n",
    "    patch_size=4,\n",
    "    emb_dim=192,\n",
    "    encoder_layer=12,\n",
    "    encoder_head=3,\n",
    "    decoder_layer=4,\n",
    "    decoder_head=3,\n",
    "    mask_ratio=0\n",
    ").to(device)\n",
    "mae.load_state_dict(torch.load('best_mae_model2.pth')['model_state_dict'])\n",
    "model = ViT_Classifier(mae.encoder).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(cnt\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_macro_auc, train_class_auc, train_loss \u001b[38;5;241m=\u001b[39m train_classifier(model, total_train_loader, optimizer, criterion, device, epoch)\n\u001b[1;32m      7\u001b[0m val_macro_auc, val_class_auc, val_loss \u001b[38;5;241m=\u001b[39m validate_classifier(model, total_val_loader, criterion, device, epoch)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "cnt = 0\n",
    "for epoch in range(50):\n",
    "    if(cnt>10):\n",
    "        break\n",
    "    train_macro_auc, train_class_auc, train_loss = train_classifier(model, total_train_loader, optimizer, criterion, device, epoch)\n",
    "    val_macro_auc, val_class_auc, val_loss = validate_classifier(model, total_val_loader, criterion, device, epoch)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{config.EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_macro_auc\": train_macro_auc,\n",
    "        \"val_macro_auc\": val_macro_auc,\n",
    "        \"train_loss_cls\": train_loss,\n",
    "        \"val_loss_cls\": val_loss,\n",
    "        **{f\"train_class_{i}\": train_class_auc[i] for i in range(len(train_class_auc))},\n",
    "        **{f\"val_class_{i}\": val_class_auc[i] for i in range(len(val_class_auc))}\n",
    "    })\n",
    "\n",
    "    if val_macro_auc < best_auc:\n",
    "        best_auc = val_macro_auc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'auc': val_macro_auc,\n",
    "        }, \"best_mae_model_classifier.pth\")\n",
    "        print(f\"Saved new best model with val loss: {val_loss:.4f}\")\n",
    "\n",
    "    else:\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_roc(model, loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.cuda()\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    probs = torch.cat(all_probs).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    wandb_roc_data = []\n",
    "\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels == i, probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Store data for wandb\n",
    "        for j in range(len(fpr[i])):\n",
    "            wandb_roc_data.append([fpr[i][j], tpr[i][j], f'Class {i}'])\n",
    "\n",
    "    roc_auc[\"macro\"] = np.mean(list(roc_auc.values()))\n",
    "\n",
    "    # Log ROC curve to wandb\n",
    "    wandb.log({\"roc_curve\": wandb.Table(data=wandb_roc_data, columns=[\"FPR\", \"TPR\", \"Class\"])})\n",
    "\n",
    "    # Log AUC values\n",
    "    wandb.log({f\"AUC_Class_{i}_final\": roc_auc[i] for i in range(3)})\n",
    "    wandb.log({\"AUC_Macro_final\": roc_auc[\"macro\"]})\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "fpr, tpr, roc_auc = evaluate_roc(mae, total_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on random data...\n",
      "cls_features:  tensor([[ 0.2450, -1.2289, -0.5948,  ..., -0.7491,  0.1013, -0.6281],\n",
      "        [ 0.2141, -1.0479, -0.5244,  ..., -0.8510, -0.0119, -0.4586],\n",
      "        [-0.1153, -0.9460, -0.5355,  ..., -0.8240,  0.0588, -0.5707],\n",
      "        ...,\n",
      "        [ 0.1473, -1.3263, -1.0752,  ..., -0.6534,  0.3485, -0.7120],\n",
      "        [-0.0344, -1.0565, -0.5682,  ..., -0.8781,  0.1710, -0.4143],\n",
      "        [ 0.0994, -1.1471, -0.6164,  ..., -0.8475,  0.1146, -0.7579]],\n",
      "       device='mps:0')\n",
      "Epoch: 0 | Batch: 0 | Loss: 1.1979 | Acc: 46.88%\n",
      "cls_features:  tensor([[ 0.1107, -0.9384, -0.4480,  ..., -0.7079,  0.1194, -0.5513],\n",
      "        [ 0.1257, -1.1308, -0.5046,  ..., -0.7745,  0.1917, -0.5722],\n",
      "        [ 0.0393, -1.1002, -0.6289,  ..., -0.8673,  0.2991, -0.3502],\n",
      "        ...,\n",
      "        [ 0.0504, -1.0735, -0.3893,  ..., -0.7381, -0.0332, -0.7761],\n",
      "        [-0.1058, -0.9896, -0.3954,  ..., -0.8490,  0.2324, -0.6006],\n",
      "        [ 0.1579, -0.9971, -0.6543,  ..., -0.6129,  0.1758, -0.5238]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 3.4288e-02, -1.0341e+00, -5.9579e-01,  ..., -8.1058e-01,\n",
      "          1.5667e-01, -7.3863e-01],\n",
      "        [-5.4089e-01, -1.0111e+00, -6.7853e-01,  ..., -6.9010e-01,\n",
      "          2.5052e-01, -7.0468e-01],\n",
      "        [ 2.2934e-01, -1.0438e+00, -6.3801e-01,  ..., -7.1544e-01,\n",
      "         -3.0897e-04, -4.2482e-01],\n",
      "        ...,\n",
      "        [ 3.4184e-01, -1.1696e+00, -6.9275e-01,  ..., -5.0781e-01,\n",
      "          4.9710e-02, -6.3464e-01],\n",
      "        [ 3.7516e-01, -1.0149e+00, -8.9512e-01,  ..., -5.6515e-01,\n",
      "          1.6543e-01, -5.3408e-01],\n",
      "        [ 1.3499e-01, -9.4201e-01, -7.0461e-01,  ..., -7.6068e-01,\n",
      "          3.3892e-01, -3.0423e-01]], device='mps:0')\n",
      "cls_features:  tensor([[ 0.1291, -1.0332, -0.7008,  ..., -0.6420,  0.0317, -0.8013],\n",
      "        [-0.3196, -0.9304, -0.8010,  ..., -0.9867,  0.3705, -0.6948],\n",
      "        [-0.2232, -0.9458, -0.8591,  ..., -0.7458,  0.0459, -0.6365],\n",
      "        ...,\n",
      "        [ 0.0231, -1.2441, -0.6188,  ..., -0.7705,  0.1762, -0.4985],\n",
      "        [-0.0342, -1.0906, -0.4619,  ..., -0.7902,  0.0173, -0.5510],\n",
      "        [ 0.1469, -1.0578, -0.5113,  ..., -0.7760,  0.0660, -0.3593]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1595, -1.1299, -0.7687,  ..., -0.6063,  0.0885, -0.4173],\n",
      "        [ 0.0494, -1.0664, -0.5271,  ..., -0.8189,  0.0862, -0.5411],\n",
      "        [-0.0640, -0.9327, -0.5478,  ..., -0.7149,  0.0875, -0.6156],\n",
      "        ...,\n",
      "        [ 0.3986, -1.1802, -0.6365,  ..., -0.7321, -0.1067, -0.5584],\n",
      "        [ 0.0927, -1.0497, -0.7468,  ..., -0.7944,  0.2134, -0.4072],\n",
      "        [ 0.3235, -1.1595, -0.5935,  ..., -0.8799, -0.0731, -0.4764]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1334, -1.1188, -0.5399,  ..., -0.8917,  0.1341, -0.7500],\n",
      "        [ 0.1071, -1.2675, -0.7504,  ..., -0.6277, -0.0713, -0.7323],\n",
      "        [ 0.2243, -0.8215, -0.4261,  ..., -0.7525,  0.1204, -0.4385],\n",
      "        ...,\n",
      "        [ 0.1174, -0.9705, -0.6112,  ..., -0.8247,  0.0660, -0.7740],\n",
      "        [-0.0089, -0.9267, -0.8815,  ..., -0.6332,  0.1118, -0.4425],\n",
      "        [-0.1484, -1.0712, -0.9070,  ..., -0.6933,  0.1752, -0.5241]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0464, -0.9755, -0.6226,  ..., -0.9858,  0.3320, -0.6181],\n",
      "        [-0.1403, -0.9619, -0.5773,  ..., -0.5816,  0.3093, -0.6732],\n",
      "        [ 0.0595, -1.0243, -0.4774,  ..., -0.6757, -0.1145, -0.5658],\n",
      "        ...,\n",
      "        [ 0.1060, -1.0580, -0.5003,  ..., -0.6655,  0.0586, -0.4888],\n",
      "        [-0.3278, -0.9630, -0.7630,  ..., -0.7708,  0.2166, -0.6694],\n",
      "        [-0.1998, -1.0736, -0.7413,  ..., -0.7374,  0.2541, -0.6597]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0243, -0.9814, -0.6532,  ..., -0.6801,  0.1681, -0.4675],\n",
      "        [-0.1574, -0.9494, -0.5400,  ..., -0.8185,  0.0466, -0.4453],\n",
      "        [-0.0146, -0.8787, -0.4220,  ..., -0.8022,  0.1200, -0.1833],\n",
      "        ...,\n",
      "        [ 0.0859, -1.0355, -0.4746,  ..., -0.7937,  0.1924, -0.5738],\n",
      "        [ 0.0597, -1.0624, -0.8162,  ..., -0.6463, -0.0394, -0.4307],\n",
      "        [ 0.0654, -1.0698, -0.5686,  ..., -0.8583,  0.0453, -0.6516]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0316, -0.6645, -0.5488,  ..., -0.8235,  0.0802, -0.3204],\n",
      "        [ 0.0030, -0.7512, -0.4992,  ..., -0.6102,  0.2682, -0.6112],\n",
      "        [ 0.2131, -1.1012, -0.5974,  ..., -0.9677,  0.0768, -0.4900],\n",
      "        ...,\n",
      "        [-0.1484, -1.1015, -0.7620,  ..., -0.8388,  0.2732, -0.5504],\n",
      "        [ 0.1898, -1.1441, -0.5363,  ..., -0.9067,  0.2834, -0.4584],\n",
      "        [ 0.1621, -1.1265, -0.6681,  ..., -0.7180,  0.3637, -0.6208]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1339, -1.0722, -0.8894,  ..., -0.6508,  0.2661, -0.5725],\n",
      "        [-0.3343, -0.9704, -0.3762,  ..., -0.8643,  0.3236, -0.2879],\n",
      "        [ 0.2133, -0.9788, -0.6673,  ..., -0.7442,  0.1994, -0.5125],\n",
      "        ...,\n",
      "        [-0.1290, -1.1274, -0.6305,  ..., -0.9194,  0.0336, -0.7005],\n",
      "        [ 0.0362, -0.9688, -0.4652,  ..., -0.7489,  0.2422, -0.4043],\n",
      "        [ 0.4511, -0.9228, -0.8072,  ..., -0.7733, -0.0089, -0.4430]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2945, -1.0966, -0.6769,  ..., -0.7803,  0.3192, -0.6942],\n",
      "        [-0.0641, -1.0003, -0.3730,  ..., -0.8459,  0.2335, -0.7139],\n",
      "        [ 0.1480, -1.1873, -0.7003,  ..., -0.6073, -0.0576, -0.6249],\n",
      "        ...,\n",
      "        [ 0.0666, -1.1191, -1.0275,  ..., -0.7845,  0.1764, -0.6930],\n",
      "        [-0.1333, -1.2940, -0.6851,  ..., -0.7029,  0.0942, -0.7049],\n",
      "        [-0.1275, -1.2002, -0.7666,  ..., -0.8426,  0.4515, -0.4570]],\n",
      "       device='mps:0')\n",
      "Epoch: 0 | Batch: 10 | Loss: 1.3192 | Acc: 43.75%\n",
      "cls_features:  tensor([[ 0.2233, -0.9943, -0.3152,  ..., -0.8162, -0.2380, -0.2208],\n",
      "        [ 0.0807, -1.0503, -0.6110,  ..., -0.8048,  0.0538, -0.5514],\n",
      "        [-0.1311, -1.0185, -0.4586,  ..., -0.7031, -0.0018, -0.7276],\n",
      "        ...,\n",
      "        [-0.2141, -1.0072, -0.3677,  ..., -0.8372,  0.1756, -0.5441],\n",
      "        [ 0.0050, -1.1061, -0.5483,  ..., -0.7598,  0.2138, -0.7047],\n",
      "        [ 0.1982, -0.6942, -0.4509,  ..., -0.6856, -0.0702, -0.2861]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3043, -1.0263, -0.9409,  ..., -0.6809,  0.2029, -0.5977],\n",
      "        [ 0.2802, -1.0115, -0.5768,  ..., -0.7433, -0.0970, -0.4522],\n",
      "        [-0.2737, -1.1586, -0.4709,  ..., -0.7612, -0.0031, -0.4112],\n",
      "        ...,\n",
      "        [-0.0946, -1.0906, -0.5828,  ..., -0.7924,  0.2495, -0.5294],\n",
      "        [ 0.1891, -1.0241, -0.5739,  ..., -0.7745,  0.0720, -0.4415],\n",
      "        [-0.0627, -1.1146, -0.6637,  ..., -0.6796,  0.2245, -0.3547]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1369, -0.9044, -0.4532,  ..., -0.7863,  0.0093, -0.3079],\n",
      "        [-0.1991, -1.0772, -0.7827,  ..., -0.8137,  0.2211, -0.4936],\n",
      "        [-0.0672, -1.1255, -0.6935,  ..., -0.6184,  0.1045, -0.7978],\n",
      "        ...,\n",
      "        [-0.1318, -1.0535, -0.7577,  ..., -0.6994,  0.1048, -0.4899],\n",
      "        [-0.2146, -0.9222, -0.2079,  ..., -0.7979,  0.0823, -0.5822],\n",
      "        [-0.2765, -1.2809, -0.6394,  ..., -0.9357,  0.4752, -0.6891]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3840, -1.2201, -0.5507,  ..., -0.7307,  0.0116, -0.2940],\n",
      "        [ 0.1372, -0.8323, -0.5856,  ..., -0.5977, -0.0429, -0.5089],\n",
      "        [-0.3430, -1.1351, -0.8758,  ..., -0.7443,  0.1739, -0.7047],\n",
      "        ...,\n",
      "        [-0.4838, -1.2219, -0.8351,  ..., -0.7980,  0.0035, -0.8555],\n",
      "        [-0.0420, -1.2440, -0.5037,  ..., -0.8105,  0.2686, -0.6775],\n",
      "        [ 0.0547, -1.0286, -0.6613,  ..., -0.6375,  0.0626, -0.5980]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0359, -0.8837, -0.5838,  ..., -0.9442,  0.0351, -0.3746],\n",
      "        [-0.0502, -0.9779, -0.7387,  ..., -0.6841,  0.2146, -0.5846],\n",
      "        [ 0.0275, -1.1769, -1.0689,  ..., -0.7389,  0.2133, -0.9324],\n",
      "        ...,\n",
      "        [-0.3057, -1.0587, -0.4953,  ..., -0.9084,  0.1195, -0.5127],\n",
      "        [-0.4318, -1.0355, -0.7039,  ..., -0.8465, -0.0834, -0.7209],\n",
      "        [-0.4933, -0.8822, -0.2912,  ..., -0.8501,  0.2130, -0.4396]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0834, -0.9542, -0.3563,  ..., -0.8326, -0.0800, -0.5579],\n",
      "        [ 0.0276, -1.0446, -0.5764,  ..., -0.8732,  0.1121, -0.5180],\n",
      "        [-0.0918, -1.1984, -0.6370,  ..., -0.6695,  0.2998, -0.5781],\n",
      "        ...,\n",
      "        [-0.1364, -1.0111, -0.7190,  ..., -0.7312,  0.2716, -0.6500],\n",
      "        [ 0.0297, -1.1522, -0.7595,  ..., -0.6051,  0.0987, -0.5384],\n",
      "        [-0.2407, -1.0870, -0.5522,  ..., -0.7365,  0.1965, -0.7129]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3269, -1.0253, -0.6100,  ..., -0.9399,  0.2367, -0.6532],\n",
      "        [ 0.1606, -1.0539, -0.7179,  ..., -0.7070, -0.0301, -0.5557],\n",
      "        [ 0.2825, -1.0650, -0.5928,  ..., -0.7868,  0.1065, -0.5189],\n",
      "        ...,\n",
      "        [ 0.1495, -1.2970, -0.5661,  ..., -0.6637,  0.0655, -0.5104],\n",
      "        [-0.1549, -0.9147, -0.7176,  ..., -0.8170,  0.1535, -0.5803],\n",
      "        [-0.3229, -1.1473, -0.8008,  ..., -0.7847, -0.0700, -0.8917]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3092, -1.0086, -0.4647,  ..., -0.8256,  0.1095, -0.6276],\n",
      "        [-0.1123, -1.2830, -0.6355,  ..., -0.9881,  0.2608, -0.4971],\n",
      "        [-0.0330, -1.0123, -0.6085,  ..., -0.7533,  0.2263, -0.6074],\n",
      "        ...,\n",
      "        [ 0.0666, -1.1911, -0.8977,  ..., -0.7205,  0.1681, -0.9219],\n",
      "        [-0.2334, -1.0826, -0.5116,  ..., -0.9797,  0.0190, -0.5676],\n",
      "        [-0.0579, -1.0432, -0.5460,  ..., -0.8519,  0.1505, -0.5892]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1796, -0.7137, -0.3981,  ..., -0.6962, -0.0986, -0.4846],\n",
      "        [-0.2270, -0.8869, -0.5934,  ..., -0.7402,  0.2646, -0.5762],\n",
      "        [-0.2132, -1.1742, -0.2763,  ..., -0.6990, -0.1351, -0.8492],\n",
      "        ...,\n",
      "        [ 0.1297, -1.2213, -0.6848,  ..., -0.6498, -0.0336, -0.6460],\n",
      "        [ 0.1288, -1.0167, -0.5432,  ..., -0.6229,  0.1347, -0.3415],\n",
      "        [-0.2429, -0.9194, -0.4896,  ..., -0.8237,  0.1414, -0.2840]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0219, -1.1508, -0.6929,  ..., -0.6361,  0.1414, -0.5431],\n",
      "        [-0.0480, -0.9855, -0.6387,  ..., -0.8531,  0.1430, -0.4952],\n",
      "        [-0.0905, -1.1287, -0.8408,  ..., -0.8459,  0.1037, -0.5091],\n",
      "        ...,\n",
      "        [ 0.0121, -1.2516, -0.7877,  ..., -0.7195,  0.1285, -0.7720],\n",
      "        [-0.1957, -1.2095, -0.5712,  ..., -0.6935,  0.0846, -0.7876],\n",
      "        [-0.3952, -1.0210, -0.3025,  ..., -0.9234,  0.0613, -0.3936]],\n",
      "       device='mps:0')\n",
      "Epoch: 0 | Batch: 20 | Loss: 1.1763 | Acc: 39.29%\n",
      "cls_features:  tensor([[ 0.3072, -1.2160, -0.7415,  ..., -0.7008,  0.1443, -0.4068],\n",
      "        [ 0.2245, -0.8736, -0.4611,  ..., -0.8476,  0.0798, -0.2241],\n",
      "        [-0.2536, -1.0263, -0.5918,  ..., -0.7197, -0.0524, -0.6068],\n",
      "        ...,\n",
      "        [ 0.5660, -1.1708, -0.8279,  ..., -0.3577,  0.1527, -0.4340],\n",
      "        [ 0.0149, -0.9360, -0.5710,  ..., -0.8368,  0.0240, -0.4489],\n",
      "        [ 0.1352, -1.1038, -0.6816,  ..., -0.7563,  0.2481, -0.7735]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0581, -1.1218, -0.7352,  ..., -0.7400,  0.1955, -0.5639],\n",
      "        [ 0.2678, -1.2766, -0.7237,  ..., -0.8526,  0.1828, -0.5611],\n",
      "        [-0.2529, -0.9992, -0.5284,  ..., -0.7775,  0.1387, -0.9065],\n",
      "        ...,\n",
      "        [ 0.0954, -1.0897, -0.4664,  ..., -0.8958, -0.1503, -0.6514],\n",
      "        [-0.2361, -0.8178, -0.5773,  ..., -0.6240,  0.1752, -0.4020],\n",
      "        [-0.3716, -0.7925, -0.4354,  ..., -0.7021,  0.2989, -0.3321]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0403, -0.9822, -0.7145,  ..., -0.8292, -0.1461, -0.6517],\n",
      "        [ 0.0864, -1.1285, -0.6507,  ..., -0.6662,  0.2598, -0.3963],\n",
      "        [ 0.1447, -0.8036, -0.4688,  ..., -0.8843,  0.0417, -0.3513],\n",
      "        ...,\n",
      "        [-0.0725, -1.2532, -0.8176,  ..., -0.6381,  0.1088, -0.7938],\n",
      "        [ 0.0698, -1.1822, -0.6585,  ..., -0.8234,  0.2926, -0.4119],\n",
      "        [-0.1828, -0.9057, -0.3780,  ..., -0.7480,  0.1861, -0.2732]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3307, -0.8814, -0.5930,  ..., -0.7683,  0.0894, -0.2702],\n",
      "        [ 0.0609, -1.2076, -0.6886,  ..., -0.7777,  0.0144, -0.7962],\n",
      "        [ 0.0488, -1.2327, -0.6445,  ..., -0.7153,  0.0643, -0.7679],\n",
      "        ...,\n",
      "        [-0.2974, -0.9029, -0.2935,  ..., -0.9778,  0.1339, -0.3562],\n",
      "        [ 0.5058, -1.3654, -0.5088,  ..., -0.7513, -0.1181, -0.7048],\n",
      "        [ 0.0980, -0.9364, -0.6559,  ..., -0.6438,  0.2041, -0.7276]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0610, -0.9546, -0.4953,  ..., -0.7160,  0.0985, -0.5275],\n",
      "        [-0.0547, -1.0147, -0.7242,  ..., -0.7005,  0.2461, -0.6163],\n",
      "        [-0.0600, -1.2120, -0.5194,  ..., -0.7845,  0.0792, -0.6905],\n",
      "        ...,\n",
      "        [ 0.3576, -0.9299, -0.2773,  ..., -0.8585, -0.0169, -0.1767],\n",
      "        [-0.1797, -0.8791, -0.4346,  ..., -0.7662,  0.1738, -0.6140],\n",
      "        [-0.1584, -1.2266, -0.6258,  ..., -0.6517,  0.1661, -0.7956]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1003, -1.0856, -0.3771,  ..., -0.8478,  0.0822, -0.5073],\n",
      "        [-0.3446, -0.9115, -0.6187,  ..., -0.7494,  0.2068, -0.5708],\n",
      "        [ 0.3049, -1.0085, -0.5624,  ..., -0.6573,  0.0784, -0.2544],\n",
      "        ...,\n",
      "        [ 0.1724, -0.9006, -0.5878,  ..., -0.5633,  0.1491, -0.5928],\n",
      "        [-0.0266, -1.0675, -0.4399,  ..., -0.7158, -0.0335, -0.4917],\n",
      "        [-0.0396, -0.9557, -0.7431,  ..., -0.6275,  0.0336, -0.4472]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1193, -1.2341, -0.9072,  ..., -0.6483, -0.1473, -0.7206],\n",
      "        [ 0.1301, -0.9615, -0.6979,  ..., -0.7926,  0.3321, -0.4231],\n",
      "        [ 0.0201, -1.4655, -0.7351,  ..., -0.8132,  0.1726, -0.6393],\n",
      "        ...,\n",
      "        [-0.0266, -1.2028, -0.9035,  ..., -0.5610,  0.1966, -0.7156],\n",
      "        [ 0.3326, -1.2545, -0.8889,  ..., -0.7382,  0.0691, -0.7021],\n",
      "        [-0.2795, -1.1226, -0.6107,  ..., -0.8031,  0.1654, -0.5710]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1382, -0.8397, -0.8117,  ..., -0.6021,  0.1016, -0.5778],\n",
      "        [-0.0153, -0.7387, -0.5427,  ..., -0.7781,  0.0411, -0.3281],\n",
      "        [-0.0574, -0.8573, -0.6182,  ..., -0.6872,  0.0735, -0.4575],\n",
      "        ...,\n",
      "        [-0.1982, -0.8238, -0.4672,  ..., -0.8874,  0.0438, -0.3379],\n",
      "        [ 0.0909, -0.7513, -0.7282,  ..., -0.6931,  0.1408, -0.3802],\n",
      "        [-0.4062, -0.9923, -0.7180,  ..., -0.7475,  0.2733, -0.5413]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2523, -1.0049, -0.5756,  ..., -0.8705,  0.2774, -0.6719],\n",
      "        [-0.1985, -1.2090, -0.7580,  ..., -0.8425,  0.1916, -0.6011],\n",
      "        [ 0.1025, -1.4507, -0.6536,  ..., -0.7562,  0.0947, -0.8223],\n",
      "        ...,\n",
      "        [ 0.0522, -1.1087, -0.8406,  ..., -0.7129,  0.1372, -0.7125],\n",
      "        [-0.0470, -1.0255, -0.3647,  ..., -0.8258, -0.0242, -0.4804],\n",
      "        [ 0.1480, -1.0573, -0.6707,  ..., -0.6677,  0.2628, -0.3739]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2410, -0.8953, -0.2396,  ..., -0.8513, -0.0380, -0.5441],\n",
      "        [ 0.0692, -1.1064, -0.5478,  ..., -0.8317,  0.2200, -0.3963],\n",
      "        [ 0.1000, -1.2706, -0.9422,  ..., -0.6350,  0.1048, -0.7006],\n",
      "        ...,\n",
      "        [-0.0710, -0.9163, -0.7472,  ..., -0.8162,  0.0702, -0.3427],\n",
      "        [ 0.3152, -1.0621, -0.5392,  ..., -0.6968, -0.0285, -0.3753],\n",
      "        [ 0.0288, -1.0641, -0.2980,  ..., -0.9363,  0.0526, -0.3186]],\n",
      "       device='mps:0')\n",
      "Epoch: 0 | Batch: 30 | Loss: 1.1699 | Acc: 40.93%\n",
      "cls_features:  tensor([[-0.0934, -0.8130, -0.7542,  ..., -0.7820,  0.1901, -0.4878],\n",
      "        [-0.0938, -1.0055, -0.7266,  ..., -0.8116,  0.2887, -0.6213],\n",
      "        [-0.4713, -1.2832, -0.6534,  ..., -0.9234,  0.1974, -0.6288],\n",
      "        ...,\n",
      "        [ 0.0602, -1.0343, -0.9585,  ..., -0.6923,  0.3082, -0.3504],\n",
      "        [-0.4562, -0.9176, -0.4718,  ..., -0.9163,  0.3155, -0.4556],\n",
      "        [ 0.1225, -1.1233, -0.5845,  ..., -0.6761,  0.2698, -0.6909]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2326, -0.7995, -0.4747,  ..., -0.7702,  0.2914, -0.5313],\n",
      "        [-0.1548, -0.9201, -0.4164,  ..., -0.8474, -0.0056, -0.6215],\n",
      "        [-0.4529, -0.9619, -0.4345,  ..., -0.9215,  0.1345, -0.2341],\n",
      "        ...,\n",
      "        [ 0.2499, -1.0059, -0.6497,  ..., -0.6938,  0.0411, -0.5288],\n",
      "        [ 0.2139, -1.0051, -0.4437,  ..., -0.8507,  0.0374, -0.5441],\n",
      "        [-0.0990, -0.8343, -0.9123,  ..., -0.6627,  0.1341, -0.4539]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0260, -0.9601, -0.5039,  ..., -0.6907,  0.1558, -0.3146],\n",
      "        [-0.2722, -0.8610, -0.6714,  ..., -0.7539,  0.3252, -0.3763],\n",
      "        [-0.1797, -0.7256, -0.5685,  ..., -0.9268,  0.3538, -0.4122],\n",
      "        ...,\n",
      "        [ 0.2656, -1.0400, -0.5054,  ..., -0.6770,  0.0988, -0.5886],\n",
      "        [-0.1959, -1.1304, -0.8303,  ..., -0.8573,  0.0260, -0.8918],\n",
      "        [-0.4092, -1.1161, -0.6726,  ..., -0.7572,  0.2085, -0.5254]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1923, -0.9140, -0.5956,  ..., -0.8789,  0.1905, -0.4366],\n",
      "        [-0.1569, -0.8599, -0.3480,  ..., -0.7587,  0.0193, -0.3213],\n",
      "        [-0.2706, -1.0756, -0.4968,  ..., -0.7183,  0.1885, -0.6208],\n",
      "        ...,\n",
      "        [-0.0505, -1.1380, -0.8275,  ..., -0.7461,  0.2553, -0.6573],\n",
      "        [ 0.2774, -0.9045, -0.4449,  ..., -0.7457,  0.0809, -0.4799],\n",
      "        [ 0.2034, -1.1968, -0.6721,  ..., -0.7720,  0.0487, -0.7429]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0943, -0.8153, -0.4427,  ..., -0.7607, -0.0773, -0.8436],\n",
      "        [-0.2439, -1.1641, -0.5098,  ..., -0.7128,  0.2331, -0.6152],\n",
      "        [ 0.1363, -1.1519, -0.8195,  ..., -0.6688,  0.0034, -0.5131],\n",
      "        ...,\n",
      "        [ 0.0955, -0.9829, -0.5350,  ..., -0.7844, -0.0107, -0.6952],\n",
      "        [ 0.0056, -1.1547, -0.7725,  ..., -0.6207,  0.3727, -0.5957],\n",
      "        [-0.1009, -1.0794, -0.8495,  ..., -0.8213,  0.2858, -0.4611]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3715, -0.8997, -0.6617,  ..., -0.8239,  0.1999, -0.2282],\n",
      "        [-0.1082, -0.7064, -0.5509,  ..., -0.7917,  0.2774, -0.2686],\n",
      "        [ 0.3018, -0.9063, -0.3530,  ..., -0.6781, -0.0024, -0.3863],\n",
      "        ...,\n",
      "        [ 0.2196, -1.1738, -0.5947,  ..., -0.6780,  0.0440, -0.7237],\n",
      "        [-0.1822, -1.1268, -0.8628,  ..., -0.7404,  0.3281, -0.8656],\n",
      "        [-0.1361, -1.0150, -0.4521,  ..., -0.6563,  0.1275, -0.8110]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0668, -1.1597, -0.4415,  ..., -0.8292,  0.1595, -0.4503],\n",
      "        [-0.1561, -0.9481, -0.6985,  ..., -0.8588,  0.2524, -0.4483],\n",
      "        [ 0.3879, -1.1935, -0.6147,  ..., -0.8383,  0.1475, -0.5456],\n",
      "        ...,\n",
      "        [-0.0635, -0.8726, -0.3165,  ..., -0.8076,  0.2255, -0.4317],\n",
      "        [-0.2119, -1.0333, -0.7679,  ..., -0.9379,  0.1268, -0.7548],\n",
      "        [-0.3475, -1.1107, -0.6155,  ..., -0.7513,  0.1120, -0.7664]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.6176e-01, -1.1564e+00, -5.3197e-01,  ..., -9.0170e-01,\n",
      "         -8.0631e-04, -8.5764e-01],\n",
      "        [ 1.5561e-01, -1.1294e+00, -4.5716e-01,  ..., -8.4043e-01,\n",
      "         -2.8044e-02, -6.1134e-01],\n",
      "        [ 2.1286e-01, -1.0161e+00, -6.4587e-01,  ..., -6.7691e-01,\n",
      "          6.0130e-02, -7.3311e-01],\n",
      "        ...,\n",
      "        [-4.2489e-01, -1.0063e+00, -5.8820e-01,  ..., -8.2909e-01,\n",
      "          2.2735e-01, -6.0393e-01],\n",
      "        [-5.6870e-03, -1.0643e+00, -8.1814e-01,  ..., -6.7322e-01,\n",
      "          6.3696e-02, -6.7690e-01],\n",
      "        [-2.2384e-01, -1.1137e+00, -8.5815e-01,  ..., -6.9156e-01,\n",
      "          1.9319e-01, -5.9756e-01]], device='mps:0')\n",
      "\n",
      "Epoch: 0\n",
      "Train Loss: 1.2572 | Train Acc: 40.80%\n",
      "Val Loss: 0.9695 | Val Acc: 50.00%\n",
      "cls_features:  tensor([[ 0.1384, -1.1813, -0.6701,  ..., -0.7389,  0.2786, -0.7724],\n",
      "        [ 0.5133, -1.2407, -0.8477,  ..., -0.5780,  0.1053, -0.5839],\n",
      "        [-0.3269, -1.0253, -0.6100,  ..., -0.9399,  0.2367, -0.6532],\n",
      "        ...,\n",
      "        [ 0.1667, -1.2249, -0.5353,  ..., -0.8480,  0.0256, -0.6706],\n",
      "        [ 0.0689, -0.9120, -0.6353,  ..., -0.7002,  0.1167, -0.7164],\n",
      "        [-0.2334, -1.0826, -0.5116,  ..., -0.9797,  0.0190, -0.5676]],\n",
      "       device='mps:0')\n",
      "Epoch: 1 | Batch: 0 | Loss: 1.0742 | Acc: 50.00%\n",
      "cls_features:  tensor([[-0.0797, -1.0240, -0.6541,  ..., -0.8985,  0.2668, -0.3803],\n",
      "        [-0.4304, -1.2464, -0.8816,  ..., -0.7916,  0.3179, -0.7831],\n",
      "        [-0.0441, -1.1694, -0.5914,  ..., -0.8315,  0.2083, -0.3308],\n",
      "        ...,\n",
      "        [ 0.1672, -1.1299, -0.6620,  ..., -0.7252,  0.1646, -0.5501],\n",
      "        [ 0.0994, -1.1471, -0.6164,  ..., -0.8475,  0.1146, -0.7579],\n",
      "        [ 0.3051, -1.3177, -0.8302,  ..., -0.8179,  0.0449, -0.5017]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1871, -0.9581, -0.4624,  ..., -0.7206,  0.0602, -0.7104],\n",
      "        [-0.4858, -0.8862, -0.5170,  ..., -0.8175,  0.2693, -0.5294],\n",
      "        [ 0.1489, -0.9079, -0.6037,  ..., -0.5655,  0.1262, -0.2949],\n",
      "        ...,\n",
      "        [ 0.0681, -1.1866, -0.5867,  ..., -0.8470,  0.1863, -0.4133],\n",
      "        [ 0.1480, -1.0573, -0.6707,  ..., -0.6677,  0.2628, -0.3739],\n",
      "        [ 0.1814, -1.1226, -0.6828,  ..., -0.7942,  0.3214, -0.8461]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3446, -0.9115, -0.6187,  ..., -0.7494,  0.2068, -0.5708],\n",
      "        [ 0.4658, -1.3196, -0.8484,  ..., -0.7113, -0.1982, -0.6598],\n",
      "        [-0.0535, -0.9732, -0.4391,  ..., -0.6521,  0.0720, -0.7121],\n",
      "        ...,\n",
      "        [ 0.1328, -0.9108, -0.5531,  ..., -0.7272,  0.1446, -0.2536],\n",
      "        [-0.3009, -0.8950, -0.2798,  ..., -0.8613,  0.1126, -0.4483],\n",
      "        [ 0.5058, -1.3654, -0.5088,  ..., -0.7513, -0.1181, -0.7048]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1652, -1.2318, -0.8884,  ..., -0.8287,  0.2901, -0.5493],\n",
      "        [-0.2232, -0.9458, -0.8591,  ..., -0.7458,  0.0459, -0.6365],\n",
      "        [ 0.0400, -1.0371, -0.7413,  ..., -0.7207,  0.1792, -0.6296],\n",
      "        ...,\n",
      "        [-0.0725, -1.2532, -0.8176,  ..., -0.6381,  0.1088, -0.7938],\n",
      "        [-0.0383, -1.1511, -0.8145,  ..., -0.7531,  0.0792, -0.7466],\n",
      "        [ 0.4222, -1.2460, -0.9785,  ..., -0.4883,  0.1081, -0.6599]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1308, -1.2208, -0.8774,  ..., -0.8305, -0.0791, -0.5234],\n",
      "        [-0.1901, -1.2483, -0.5592,  ..., -0.8207,  0.1285, -0.4619],\n",
      "        [-0.3229, -1.1473, -0.8008,  ..., -0.7847, -0.0700, -0.8917],\n",
      "        ...,\n",
      "        [-0.1153, -0.9460, -0.5355,  ..., -0.8240,  0.0588, -0.5707],\n",
      "        [ 0.0764, -1.1509, -0.9222,  ..., -0.7722,  0.2096, -0.3937],\n",
      "        [ 0.2657, -1.2880, -0.7053,  ..., -0.6453,  0.0050, -0.7041]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.0473e-01, -8.7428e-01, -5.8316e-01,  ..., -6.6888e-01,\n",
      "         -3.9486e-02, -5.8370e-01],\n",
      "        [-8.0257e-02, -1.1006e+00, -7.1898e-01,  ..., -7.5119e-01,\n",
      "          5.8175e-03, -5.3503e-01],\n",
      "        [ 8.8802e-02, -1.1365e+00, -4.2797e-01,  ..., -9.6270e-01,\n",
      "          1.2009e-01, -5.3565e-01],\n",
      "        ...,\n",
      "        [ 1.0477e-01, -1.2336e+00, -6.6723e-01,  ..., -6.8529e-01,\n",
      "         -1.0625e-01, -6.9910e-01],\n",
      "        [ 1.0781e-03, -1.1220e+00, -8.6178e-01,  ..., -7.5538e-01,\n",
      "          1.1696e-01, -5.3794e-01],\n",
      "        [-6.5357e-02, -9.2884e-01, -1.0120e+00,  ..., -7.9191e-01,\n",
      "          1.1545e-01, -6.9439e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.0262, -0.9968, -0.5725,  ..., -0.7486,  0.1981, -0.6944],\n",
      "        [-0.4092, -0.7637, -0.5431,  ..., -0.8641,  0.2837, -0.5811],\n",
      "        [-0.0937, -1.0667, -0.5030,  ..., -0.5388,  0.0329, -0.7385],\n",
      "        ...,\n",
      "        [-0.0125, -1.1198, -0.7140,  ..., -0.6892,  0.0492, -0.5813],\n",
      "        [ 0.3986, -1.1802, -0.6365,  ..., -0.7321, -0.1067, -0.5584],\n",
      "        [ 0.3348, -0.9878, -0.6158,  ..., -0.6151,  0.1032, -0.4525]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0597, -1.0624, -0.8162,  ..., -0.6463, -0.0394, -0.4307],\n",
      "        [-0.2765, -1.2809, -0.6394,  ..., -0.9357,  0.4752, -0.6891],\n",
      "        [-0.2652, -1.1131, -0.7387,  ..., -0.8411,  0.0998, -0.4629],\n",
      "        ...,\n",
      "        [ 0.0016, -0.9903, -0.4285,  ..., -0.8851,  0.1675, -0.4765],\n",
      "        [-0.1403, -0.9619, -0.5773,  ..., -0.5816,  0.3093, -0.6732],\n",
      "        [ 0.0681, -1.2858, -0.8279,  ..., -0.7914,  0.1805, -0.7305]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1407, -1.0374, -0.5977,  ..., -0.8030,  0.0296, -0.2904],\n",
      "        [-0.6058, -0.8157, -0.6107,  ..., -0.9238,  0.4153, -0.4256],\n",
      "        [-0.3343, -0.9704, -0.3762,  ..., -0.8643,  0.3236, -0.2879],\n",
      "        ...,\n",
      "        [-0.2154, -0.9597, -0.7312,  ..., -0.8398,  0.3090, -0.5486],\n",
      "        [ 0.3576, -0.9299, -0.2773,  ..., -0.8585, -0.0169, -0.1767],\n",
      "        [ 0.0262, -0.9190, -0.6022,  ..., -0.8293,  0.0977, -0.5432]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0830, -1.1229, -0.5419,  ..., -0.7001,  0.1442, -0.6964],\n",
      "        [-0.0152, -1.0469, -0.7011,  ..., -0.8645,  0.3509, -0.3341],\n",
      "        [ 0.3885, -1.0816, -0.4351,  ..., -0.6171, -0.2097, -0.4522],\n",
      "        ...,\n",
      "        [ 0.3360, -1.0581, -0.5408,  ..., -0.6833,  0.0662, -0.4306],\n",
      "        [-0.0147, -1.2766, -0.7067,  ..., -0.8933,  0.1435, -0.8236],\n",
      "        [-0.0111, -1.1067, -0.8319,  ..., -0.7161,  0.0179, -0.6074]],\n",
      "       device='mps:0')\n",
      "Epoch: 1 | Batch: 10 | Loss: 1.0127 | Acc: 42.61%\n",
      "cls_features:  tensor([[ 3.1316e-01, -1.1420e+00, -7.6626e-01,  ..., -7.2041e-01,\n",
      "          4.7288e-01, -5.2470e-01],\n",
      "        [-4.6540e-02, -9.5238e-01, -5.4944e-01,  ..., -6.5193e-01,\n",
      "          4.4704e-02, -3.0172e-01],\n",
      "        [-2.6391e-01, -9.3491e-01, -3.6605e-01,  ..., -9.2309e-01,\n",
      "          1.2031e-01, -3.3523e-01],\n",
      "        ...,\n",
      "        [-2.4841e-02, -1.3983e+00, -7.6301e-01,  ..., -7.2403e-01,\n",
      "          2.1258e-01, -9.1142e-01],\n",
      "        [ 2.2934e-01, -1.0438e+00, -6.3801e-01,  ..., -7.1544e-01,\n",
      "         -3.0995e-04, -4.2481e-01],\n",
      "        [-6.2473e-01, -8.9613e-01, -4.4385e-01,  ..., -8.5284e-01,\n",
      "          2.5404e-01, -2.6884e-01]], device='mps:0')\n",
      "cls_features:  tensor([[ 0.0275, -1.1769, -1.0689,  ..., -0.7389,  0.2133, -0.9324],\n",
      "        [ 0.3092, -1.2381, -0.5547,  ..., -0.8123,  0.1652, -0.7401],\n",
      "        [-0.2187, -0.9113, -0.4631,  ..., -0.9231,  0.0430, -0.5599],\n",
      "        ...,\n",
      "        [-0.2311, -1.1597, -0.6201,  ..., -0.8137,  0.2666, -0.6187],\n",
      "        [ 0.1443, -1.1851, -0.6312,  ..., -0.7336,  0.1793, -0.5242],\n",
      "        [-0.0330, -1.0123, -0.6085,  ..., -0.7533,  0.2263, -0.6074]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2189, -0.8446, -0.3566,  ..., -0.8685,  0.2549, -0.4004],\n",
      "        [-0.0149, -1.0610, -0.7012,  ..., -0.7745,  0.2036, -0.5942],\n",
      "        [-0.0340, -1.1237, -0.9073,  ..., -0.4828,  0.0901, -0.8590],\n",
      "        ...,\n",
      "        [-0.1270, -1.1209, -0.6766,  ..., -0.7922,  0.2751, -0.2481],\n",
      "        [ 0.1325, -0.9280, -0.3232,  ..., -0.7077,  0.2701, -0.6064],\n",
      "        [ 0.2673, -1.0789, -0.6183,  ..., -0.8137,  0.1570, -0.2119]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.1466e-01, -8.2478e-01, -4.7375e-01,  ..., -8.3079e-01,\n",
      "          2.1683e-01, -2.9127e-01],\n",
      "        [ 2.1055e-01, -1.0680e+00, -5.1221e-01,  ..., -7.1051e-01,\n",
      "          2.1233e-01, -7.1953e-01],\n",
      "        [ 3.4599e-01, -1.0235e+00, -5.4662e-01,  ..., -5.4506e-01,\n",
      "          1.6045e-04, -4.4693e-01],\n",
      "        ...,\n",
      "        [-2.4072e-01, -1.0870e+00, -5.5218e-01,  ..., -7.3649e-01,\n",
      "          1.9654e-01, -7.1286e-01],\n",
      "        [-1.0062e-01, -9.0091e-01, -7.1918e-01,  ..., -5.8220e-01,\n",
      "          1.3324e-01, -6.9347e-01],\n",
      "        [ 2.6189e-02, -1.3344e+00, -1.0830e+00,  ..., -6.4986e-01,\n",
      "          2.5204e-01, -6.2524e-01]], device='mps:0')\n",
      "cls_features:  tensor([[ 0.3194, -0.9816, -0.6813,  ..., -0.7008, -0.3522, -0.5842],\n",
      "        [ 0.2062, -0.9004, -0.6204,  ..., -0.5693,  0.2114, -0.3823],\n",
      "        [ 0.1595, -1.1299, -0.7687,  ..., -0.6063,  0.0885, -0.4173],\n",
      "        ...,\n",
      "        [-0.0938, -1.0055, -0.7266,  ..., -0.8116,  0.2887, -0.6213],\n",
      "        [ 0.5143, -0.7612, -0.4394,  ..., -0.5973, -0.0773, -0.4070],\n",
      "        [-0.1661, -1.0939, -0.3316,  ..., -0.6888,  0.1909, -0.6356]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0303, -0.9921, -0.5049,  ..., -0.5920,  0.0213, -0.5663],\n",
      "        [-0.0592, -0.8480, -0.3990,  ..., -0.7547, -0.0736, -0.6066],\n",
      "        [-0.0312, -1.3997, -0.6605,  ..., -0.7189,  0.2031, -0.7274],\n",
      "        ...,\n",
      "        [ 0.0145, -1.0799, -0.7881,  ..., -0.7529,  0.0959, -0.5252],\n",
      "        [-0.1005, -1.0035, -0.6725,  ..., -0.7638,  0.1953, -0.6190],\n",
      "        [ 0.2479, -0.9767, -0.4196,  ..., -0.7331, -0.0553, -0.3768]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2845, -1.4281, -0.5401,  ..., -0.7419,  0.2619, -0.6621],\n",
      "        [-0.0796, -0.9606, -0.5943,  ..., -0.8376, -0.0913, -0.4251],\n",
      "        [-0.2132, -1.1742, -0.2763,  ..., -0.6990, -0.1351, -0.8492],\n",
      "        ...,\n",
      "        [-0.1546, -1.1955, -0.7123,  ..., -0.7756,  0.2036, -0.5448],\n",
      "        [-0.0893, -1.1851, -0.6616,  ..., -0.5832,  0.1314, -0.4927],\n",
      "        [-0.2714, -1.1688, -0.8094,  ..., -0.7102,  0.1919, -0.8244]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1756, -1.0895, -0.5575,  ..., -0.5135, -0.0727, -0.4444],\n",
      "        [ 0.0230, -1.0064, -0.5190,  ..., -0.9811,  0.3898, -0.0417],\n",
      "        [-0.3825, -1.0636, -0.5821,  ..., -0.8030, -0.0748, -0.8601],\n",
      "        ...,\n",
      "        [ 0.0715, -0.9190, -0.5001,  ..., -0.8422, -0.1437, -0.4064],\n",
      "        [ 0.4065, -1.2035, -0.8937,  ..., -0.7359,  0.1523, -0.4382],\n",
      "        [-0.1529, -1.1601, -0.7585,  ..., -0.6845,  0.2254, -0.6420]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1096, -0.9836, -0.7815,  ..., -0.7912,  0.3128, -0.4454],\n",
      "        [-0.3998, -0.9582, -0.5372,  ..., -0.8484,  0.1741, -0.2910],\n",
      "        [-0.0386, -1.2370, -0.8592,  ..., -0.7422,  0.4452, -0.7555],\n",
      "        ...,\n",
      "        [ 0.1682, -0.9378, -0.7749,  ..., -0.6078,  0.1139, -0.3982],\n",
      "        [ 0.2247, -1.3217, -0.5360,  ..., -0.6799,  0.1242, -0.5167],\n",
      "        [-0.0249, -1.0333, -0.5392,  ..., -0.6072,  0.0519, -0.5206]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1724, -0.9006, -0.5878,  ..., -0.5633,  0.1491, -0.5928],\n",
      "        [-0.1101, -1.2095, -0.8014,  ..., -0.7178,  0.2269, -0.6457],\n",
      "        [ 0.1382, -0.8397, -0.8117,  ..., -0.6021,  0.1016, -0.5778],\n",
      "        ...,\n",
      "        [-0.3716, -0.7925, -0.4354,  ..., -0.7021,  0.2989, -0.3321],\n",
      "        [-0.0790, -1.0849, -0.7575,  ..., -0.8768,  0.0369, -0.4157],\n",
      "        [-0.0292, -1.0468, -0.6351,  ..., -0.6714, -0.1138, -0.7131]],\n",
      "       device='mps:0')\n",
      "Epoch: 1 | Batch: 20 | Loss: 1.0849 | Acc: 40.77%\n",
      "cls_features:  tensor([[ 0.2205, -1.0843, -0.4606,  ..., -0.7481,  0.1343, -0.4357],\n",
      "        [ 0.0362, -0.9688, -0.4652,  ..., -0.7489,  0.2422, -0.4043],\n",
      "        [ 0.0860, -1.1441, -0.5894,  ..., -0.7355, -0.0243, -0.6197],\n",
      "        ...,\n",
      "        [ 0.2418, -1.2550, -0.5850,  ..., -0.7012, -0.0725, -0.5578],\n",
      "        [-0.2246, -0.8440, -0.7282,  ..., -0.4905,  0.0531, -0.5808],\n",
      "        [-0.2322, -0.9395, -0.8143,  ..., -0.8518,  0.2381, -0.5853]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-1.0328e-01, -1.2352e+00, -8.9877e-01,  ..., -7.8681e-01,\n",
      "          2.4540e-01, -6.2729e-01],\n",
      "        [ 2.1333e-01, -9.7881e-01, -6.6729e-01,  ..., -7.4418e-01,\n",
      "          1.9939e-01, -5.1248e-01],\n",
      "        [ 2.8079e-01, -1.0595e+00, -6.8297e-01,  ..., -7.8516e-01,\n",
      "          4.8258e-03, -5.7188e-01],\n",
      "        ...,\n",
      "        [ 8.2515e-04, -1.0405e+00, -3.3133e-01,  ..., -9.0710e-01,\n",
      "          9.6758e-02, -3.4645e-01],\n",
      "        [-2.5736e-01, -1.0154e+00, -7.5380e-01,  ..., -8.5647e-01,\n",
      "          2.6923e-01, -3.4833e-01],\n",
      "        [ 1.4057e-01, -1.0851e+00, -4.6968e-01,  ..., -8.9698e-01,\n",
      "          1.1997e-01, -4.8918e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.0922, -1.1937, -0.9014,  ..., -0.7849,  0.3627, -0.5727],\n",
      "        [ 0.0100, -0.6726, -0.4991,  ..., -0.7621,  0.0689, -0.4069],\n",
      "        [ 0.2824, -1.0461, -0.5611,  ..., -0.6417, -0.0110, -0.3753],\n",
      "        ...,\n",
      "        [ 0.1983, -1.3617, -0.7876,  ..., -0.6202,  0.0129, -0.6407],\n",
      "        [ 0.0864, -1.1285, -0.6507,  ..., -0.6662,  0.2598, -0.3963],\n",
      "        [-0.3933, -1.0310, -0.3782,  ..., -0.7966,  0.1195, -0.6845]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0860, -0.8368, -0.6369,  ..., -0.6060,  0.1578, -0.6013],\n",
      "        [ 0.0834, -0.9542, -0.3563,  ..., -0.8326, -0.0800, -0.5579],\n",
      "        [-0.3427, -0.7240, -0.3813,  ..., -0.7665,  0.2509, -0.3959],\n",
      "        ...,\n",
      "        [ 0.2981, -0.8462, -0.4074,  ..., -0.7596, -0.0753, -0.2300],\n",
      "        [-0.3557, -1.0023, -0.6509,  ..., -0.7840,  0.3266, -0.3719],\n",
      "        [-0.0396, -0.9557, -0.7431,  ..., -0.6275,  0.0336, -0.4472]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3196, -0.9304, -0.8010,  ..., -0.9867,  0.3705, -0.6948],\n",
      "        [-0.0219, -1.1508, -0.6929,  ..., -0.6361,  0.1414, -0.5431],\n",
      "        [-0.2452, -0.9547, -0.8066,  ..., -0.6424,  0.7753, -0.4801],\n",
      "        ...,\n",
      "        [ 0.1486, -1.3244, -0.7078,  ..., -0.7579,  0.2571, -0.5240],\n",
      "        [ 0.3851, -1.3656, -0.7897,  ..., -0.6232,  0.2490, -0.5750],\n",
      "        [ 0.0566, -0.8031, -0.6069,  ..., -0.7476, -0.1853, -0.4478]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1831, -1.0210, -0.6501,  ..., -0.7955,  0.2069, -0.4793],\n",
      "        [-0.2151, -1.1213, -0.2223,  ..., -0.7490, -0.1359, -0.7485],\n",
      "        [-0.0649, -1.1004, -0.7694,  ..., -0.7785,  0.1888, -0.5928],\n",
      "        ...,\n",
      "        [-0.1466, -0.9060, -0.6227,  ..., -0.8533,  0.3445, -0.7471],\n",
      "        [ 0.1144, -0.7489, -0.3605,  ..., -0.8151,  0.1775, -0.2385],\n",
      "        [ 0.3750, -1.3798, -0.7073,  ..., -0.5810,  0.0248, -0.5237]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2022, -0.9312, -0.8317,  ..., -0.6932,  0.1048, -0.2123],\n",
      "        [ 0.1060, -1.0580, -0.5003,  ..., -0.6655,  0.0586, -0.4888],\n",
      "        [ 0.2546, -1.0343, -0.7192,  ..., -0.7603,  0.0896, -0.6782],\n",
      "        ...,\n",
      "        [ 0.2296, -1.1606, -0.7731,  ..., -0.7250,  0.0769, -0.4781],\n",
      "        [ 0.0818, -1.0242, -0.8003,  ..., -0.6246,  0.1083, -0.7063],\n",
      "        [ 0.1158, -0.7423, -0.6043,  ..., -0.8075, -0.1256, -0.4636]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2313, -1.0552, -0.6046,  ..., -0.8565,  0.0605, -0.4949],\n",
      "        [-0.0945, -0.8808, -0.5128,  ..., -0.8879,  0.1905, -0.4249],\n",
      "        [ 0.1581, -0.8213, -0.4073,  ..., -0.7470, -0.0223, -0.6478],\n",
      "        ...,\n",
      "        [-0.2713, -0.9653, -0.6578,  ..., -0.6797,  0.2531, -0.3205],\n",
      "        [-0.0120, -1.1291, -0.5756,  ..., -0.6832,  0.0191, -0.5016],\n",
      "        [-0.1637, -1.2361, -0.4281,  ..., -0.7399, -0.0087, -0.4824]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0104, -1.0553, -0.5708,  ..., -0.8877,  0.0982, -0.7855],\n",
      "        [ 0.1372, -0.8323, -0.5856,  ..., -0.5977, -0.0429, -0.5089],\n",
      "        [-0.5633, -1.1296, -0.8451,  ..., -0.7833,  0.3669, -0.7219],\n",
      "        ...,\n",
      "        [ 0.1301, -0.9615, -0.6979,  ..., -0.7926,  0.3321, -0.4231],\n",
      "        [-0.0922, -1.1469, -0.7442,  ..., -0.7309, -0.0126, -0.6317],\n",
      "        [ 0.0730, -1.1538, -0.6751,  ..., -0.7602,  0.3941, -0.5620]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1545, -1.3325, -0.7679,  ..., -0.8634,  0.3877, -0.5411],\n",
      "        [-0.0890, -1.1761, -0.8639,  ..., -0.4285,  0.1762, -0.8975],\n",
      "        [-0.0075, -0.7788, -0.5023,  ..., -0.7225,  0.3883, -0.4024],\n",
      "        ...,\n",
      "        [-0.1146, -1.0159, -0.6321,  ..., -0.7156,  0.1958, -0.5126],\n",
      "        [-0.0641, -1.0003, -0.3730,  ..., -0.8459,  0.2335, -0.7139],\n",
      "        [ 0.2295, -0.8823, -0.7453,  ..., -0.4268, -0.0231, -0.5786]],\n",
      "       device='mps:0')\n",
      "Epoch: 1 | Batch: 30 | Loss: 0.9837 | Acc: 41.13%\n",
      "cls_features:  tensor([[-0.1690, -0.9703, -0.6463,  ..., -0.8620,  0.2058, -0.3853],\n",
      "        [-0.2085, -1.0031, -0.6059,  ..., -0.6897,  0.2121, -0.7404],\n",
      "        [ 0.1257, -1.1308, -0.5046,  ..., -0.7745,  0.1917, -0.5722],\n",
      "        ...,\n",
      "        [ 0.1634, -1.2027, -0.7417,  ..., -0.8667,  0.2600, -0.4865],\n",
      "        [ 0.0778, -0.7513, -0.4061,  ..., -0.6846, -0.1957, -0.7020],\n",
      "        [-0.2429, -0.9194, -0.4896,  ..., -0.8237,  0.1414, -0.2840]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2326, -0.7995, -0.4747,  ..., -0.7702,  0.2914, -0.5313],\n",
      "        [-0.1548, -0.9201, -0.4164,  ..., -0.8474, -0.0056, -0.6215],\n",
      "        [-0.4529, -0.9619, -0.4345,  ..., -0.9215,  0.1345, -0.2341],\n",
      "        ...,\n",
      "        [ 0.2499, -1.0059, -0.6497,  ..., -0.6938,  0.0411, -0.5288],\n",
      "        [ 0.2139, -1.0051, -0.4437,  ..., -0.8507,  0.0374, -0.5441],\n",
      "        [-0.0990, -0.8343, -0.9123,  ..., -0.6627,  0.1341, -0.4539]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0260, -0.9601, -0.5039,  ..., -0.6907,  0.1558, -0.3146],\n",
      "        [-0.2722, -0.8610, -0.6714,  ..., -0.7539,  0.3252, -0.3763],\n",
      "        [-0.1797, -0.7256, -0.5685,  ..., -0.9268,  0.3538, -0.4122],\n",
      "        ...,\n",
      "        [ 0.2656, -1.0400, -0.5054,  ..., -0.6770,  0.0988, -0.5886],\n",
      "        [-0.1959, -1.1304, -0.8303,  ..., -0.8573,  0.0260, -0.8918],\n",
      "        [-0.4092, -1.1161, -0.6726,  ..., -0.7572,  0.2085, -0.5254]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1923, -0.9140, -0.5956,  ..., -0.8789,  0.1905, -0.4366],\n",
      "        [-0.1569, -0.8599, -0.3480,  ..., -0.7587,  0.0193, -0.3213],\n",
      "        [-0.2706, -1.0756, -0.4968,  ..., -0.7183,  0.1885, -0.6208],\n",
      "        ...,\n",
      "        [-0.0505, -1.1380, -0.8275,  ..., -0.7461,  0.2553, -0.6573],\n",
      "        [ 0.2774, -0.9045, -0.4449,  ..., -0.7457,  0.0809, -0.4799],\n",
      "        [ 0.2034, -1.1968, -0.6721,  ..., -0.7720,  0.0487, -0.7429]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0943, -0.8153, -0.4427,  ..., -0.7607, -0.0773, -0.8436],\n",
      "        [-0.2439, -1.1641, -0.5098,  ..., -0.7128,  0.2331, -0.6152],\n",
      "        [ 0.1363, -1.1519, -0.8195,  ..., -0.6688,  0.0034, -0.5131],\n",
      "        ...,\n",
      "        [ 0.0955, -0.9829, -0.5350,  ..., -0.7844, -0.0107, -0.6952],\n",
      "        [ 0.0056, -1.1547, -0.7725,  ..., -0.6207,  0.3727, -0.5957],\n",
      "        [-0.1009, -1.0794, -0.8495,  ..., -0.8213,  0.2858, -0.4611]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3715, -0.8997, -0.6617,  ..., -0.8239,  0.1999, -0.2282],\n",
      "        [-0.1082, -0.7064, -0.5509,  ..., -0.7917,  0.2774, -0.2686],\n",
      "        [ 0.3018, -0.9063, -0.3530,  ..., -0.6781, -0.0024, -0.3863],\n",
      "        ...,\n",
      "        [ 0.2196, -1.1738, -0.5947,  ..., -0.6780,  0.0440, -0.7237],\n",
      "        [-0.1822, -1.1268, -0.8628,  ..., -0.7404,  0.3281, -0.8656],\n",
      "        [-0.1361, -1.0150, -0.4521,  ..., -0.6563,  0.1275, -0.8110]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0668, -1.1597, -0.4415,  ..., -0.8292,  0.1595, -0.4503],\n",
      "        [-0.1561, -0.9481, -0.6985,  ..., -0.8588,  0.2524, -0.4483],\n",
      "        [ 0.3879, -1.1935, -0.6147,  ..., -0.8383,  0.1475, -0.5456],\n",
      "        ...,\n",
      "        [-0.0635, -0.8726, -0.3165,  ..., -0.8076,  0.2255, -0.4317],\n",
      "        [-0.2119, -1.0333, -0.7679,  ..., -0.9379,  0.1268, -0.7548],\n",
      "        [-0.3475, -1.1107, -0.6155,  ..., -0.7513,  0.1120, -0.7664]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.6176e-01, -1.1564e+00, -5.3197e-01,  ..., -9.0169e-01,\n",
      "         -8.0572e-04, -8.5764e-01],\n",
      "        [ 1.5561e-01, -1.1294e+00, -4.5716e-01,  ..., -8.4043e-01,\n",
      "         -2.8044e-02, -6.1134e-01],\n",
      "        [ 2.1286e-01, -1.0161e+00, -6.4587e-01,  ..., -6.7691e-01,\n",
      "          6.0130e-02, -7.3311e-01],\n",
      "        ...,\n",
      "        [-4.2489e-01, -1.0063e+00, -5.8820e-01,  ..., -8.2909e-01,\n",
      "          2.2735e-01, -6.0393e-01],\n",
      "        [-5.6879e-03, -1.0643e+00, -8.1814e-01,  ..., -6.7322e-01,\n",
      "          6.3696e-02, -6.7690e-01],\n",
      "        [-2.2384e-01, -1.1137e+00, -8.5815e-01,  ..., -6.9156e-01,\n",
      "          1.9319e-01, -5.9756e-01]], device='mps:0')\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss: 1.1911 | Train Acc: 40.90%\n",
      "Val Loss: 0.9860 | Val Acc: 54.50%\n",
      "cls_features:  tensor([[ 1.9214e-01, -7.4834e-01, -5.8403e-01,  ..., -7.9290e-01,\n",
      "         -1.1462e-01, -3.1036e-01],\n",
      "        [-9.9584e-02, -1.0041e+00, -8.4395e-01,  ..., -4.9405e-01,\n",
      "          1.7815e-01, -4.5832e-01],\n",
      "        [ 2.2331e-01, -9.9432e-01, -3.1522e-01,  ..., -8.1616e-01,\n",
      "         -2.3804e-01, -2.2085e-01],\n",
      "        ...,\n",
      "        [ 7.1539e-02, -9.1905e-01, -5.0010e-01,  ..., -8.4222e-01,\n",
      "         -1.4367e-01, -4.0641e-01],\n",
      "        [ 8.2491e-04, -1.0405e+00, -3.3133e-01,  ..., -9.0710e-01,\n",
      "          9.6757e-02, -3.4645e-01],\n",
      "        [ 6.8083e-02, -1.2858e+00, -8.2792e-01,  ..., -7.9139e-01,\n",
      "          1.8051e-01, -7.3051e-01]], device='mps:0')\n",
      "Epoch: 2 | Batch: 0 | Loss: 1.1727 | Acc: 40.62%\n",
      "cls_features:  tensor([[ 0.0165, -0.9618, -0.5063,  ..., -0.6484, -0.0513, -0.5063],\n",
      "        [ 0.1734, -1.0362, -0.4245,  ..., -0.8193,  0.0100, -0.6914],\n",
      "        [ 0.1480, -1.0573, -0.6707,  ..., -0.6677,  0.2628, -0.3739],\n",
      "        ...,\n",
      "        [-0.1752, -1.1689, -0.3509,  ..., -0.7110,  0.2580, -0.5896],\n",
      "        [-0.2889, -0.9562, -0.7006,  ..., -0.9715,  0.2908, -0.4267],\n",
      "        [-0.3133, -0.8526, -0.7214,  ..., -0.8822,  0.4046, -0.2496]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1273, -0.9711, -0.5232,  ..., -0.7356,  0.2616, -0.2892],\n",
      "        [ 0.4403, -1.2694, -0.8072,  ..., -0.6841,  0.1126, -0.2142],\n",
      "        [ 0.1350, -0.9420, -0.7046,  ..., -0.7607,  0.3389, -0.3042],\n",
      "        ...,\n",
      "        [ 0.1632, -1.1014, -0.5859,  ..., -0.5534, -0.2142, -0.8543],\n",
      "        [ 0.1165, -0.8943, -0.7982,  ..., -0.8253, -0.0485, -0.5676],\n",
      "        [ 0.0135, -1.0626, -0.8321,  ..., -0.8570,  0.1975, -0.7878]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0494, -0.9722, -0.4552,  ..., -1.0289,  0.1643, -0.2836],\n",
      "        [-0.4460, -1.1458, -0.5939,  ..., -0.9429,  0.2150, -0.6915],\n",
      "        [ 0.2578, -1.2300, -0.6095,  ..., -0.8212, -0.0275, -0.3233],\n",
      "        ...,\n",
      "        [-0.0570, -1.1211, -0.5714,  ..., -0.6708,  0.1696, -0.7582],\n",
      "        [-0.1686, -0.8515, -0.9600,  ..., -0.5701,  0.0789, -0.6253],\n",
      "        [-0.0784, -0.9734, -0.5087,  ..., -0.7161,  0.2959, -0.4213]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0613, -1.0551, -0.6899,  ..., -0.7614,  0.0729, -0.6864],\n",
      "        [ 0.2016, -0.9858, -0.6276,  ..., -0.6100,  0.0462, -0.4909],\n",
      "        [ 0.0574, -0.9595, -0.8116,  ..., -0.6548,  0.1344, -0.4953],\n",
      "        ...,\n",
      "        [ 0.1393, -0.8533, -0.6950,  ..., -0.7039,  0.2160, -0.3322],\n",
      "        [-0.0023, -1.2778, -0.8551,  ..., -0.7642,  0.2547, -0.6874],\n",
      "        [ 0.1911, -1.0406, -0.7234,  ..., -0.7908,  0.2479, -0.5016]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0224, -1.1401, -0.7307,  ..., -0.8131,  0.2862, -0.5036],\n",
      "        [-0.0832, -0.8393, -0.7426,  ..., -0.7450,  0.1733, -0.7124],\n",
      "        [-0.0324, -1.0897, -0.5764,  ..., -0.7642,  0.1782, -0.7193],\n",
      "        ...,\n",
      "        [ 0.0909, -0.7514, -0.7282,  ..., -0.6931,  0.1408, -0.3802],\n",
      "        [ 0.0421, -0.9649, -0.6931,  ..., -0.4082,  0.1947, -0.7745],\n",
      "        [ 0.3514, -1.0736, -0.6168,  ..., -0.5682, -0.1305, -0.5906]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2767, -1.0143, -0.6500,  ..., -0.7704,  0.0033, -0.7479],\n",
      "        [ 0.4658, -1.3196, -0.8484,  ..., -0.7113, -0.1982, -0.6598],\n",
      "        [-0.0426, -1.0647, -0.4354,  ..., -0.7380,  0.0161, -0.8681],\n",
      "        ...,\n",
      "        [-0.0628, -1.2289, -0.5406,  ..., -0.8131,  0.3917, -0.5952],\n",
      "        [-0.1185, -0.8766, -0.5465,  ..., -0.8224,  0.1341, -0.4454],\n",
      "        [-0.2239, -0.9972, -0.4749,  ..., -0.8058, -0.0716, -0.3481]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1101, -0.9147, -0.7157,  ..., -0.9275,  0.1907, -0.5164],\n",
      "        [-0.0312, -1.3997, -0.6605,  ..., -0.7189,  0.2031, -0.7274],\n",
      "        [-0.0946, -1.0906, -0.5828,  ..., -0.7924,  0.2495, -0.5294],\n",
      "        ...,\n",
      "        [-0.2232, -0.9458, -0.8591,  ..., -0.7458,  0.0459, -0.6365],\n",
      "        [-0.4318, -1.0355, -0.7039,  ..., -0.8465, -0.0834, -0.7209],\n",
      "        [-0.0918, -1.1984, -0.6370,  ..., -0.6695,  0.2998, -0.5781]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.6058, -0.8157, -0.6107,  ..., -0.9238,  0.4153, -0.4256],\n",
      "        [-0.0340, -1.1237, -0.9073,  ..., -0.4828,  0.0901, -0.8590],\n",
      "        [ 0.3628, -1.0884, -0.6632,  ..., -0.8349,  0.0120, -0.2709],\n",
      "        ...,\n",
      "        [ 0.3749, -1.0232, -0.8350,  ..., -0.5363,  0.1264, -0.3297],\n",
      "        [-0.0798, -1.0460, -0.5315,  ..., -0.7727,  0.0748, -0.5146],\n",
      "        [-0.2322, -0.9395, -0.8143,  ..., -0.8518,  0.2381, -0.5853]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0504, -1.0735, -0.3893,  ..., -0.7381, -0.0332, -0.7761],\n",
      "        [-0.4256, -1.0765, -0.7654,  ..., -0.9126,  0.3726, -0.4170],\n",
      "        [ 0.1933, -1.1268, -0.4161,  ..., -0.6803, -0.1472, -0.4296],\n",
      "        ...,\n",
      "        [ 0.2456, -1.0135, -0.4368,  ..., -0.9687,  0.0648, -0.5511],\n",
      "        [-0.2684, -0.9335, -0.7367,  ..., -0.8025,  0.1223, -0.5821],\n",
      "        [ 0.1640, -1.2480, -0.7360,  ..., -0.6566,  0.1568, -0.6060]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0234, -1.1459, -0.7965,  ..., -0.7167, -0.0578, -0.3834],\n",
      "        [ 0.2864, -1.0835, -0.5205,  ..., -0.5436, -0.0513, -0.4206],\n",
      "        [ 0.2745, -0.8862, -0.6997,  ..., -0.5648,  0.0426, -0.5512],\n",
      "        ...,\n",
      "        [-0.0480, -0.9855, -0.6387,  ..., -0.8531,  0.1430, -0.4952],\n",
      "        [ 0.0681, -1.1866, -0.5867,  ..., -0.8470,  0.1863, -0.4133],\n",
      "        [ 0.3235, -1.1595, -0.5935,  ..., -0.8799, -0.0731, -0.4764]],\n",
      "       device='mps:0')\n",
      "Epoch: 2 | Batch: 10 | Loss: 1.1812 | Acc: 39.20%\n",
      "cls_features:  tensor([[-0.2724, -1.4619, -0.7984,  ..., -0.7326,  0.1541, -0.6971],\n",
      "        [ 0.1815, -1.2353, -0.8067,  ..., -0.6124,  0.3555, -0.6631],\n",
      "        [ 0.0615, -1.1271, -0.5552,  ..., -0.8732,  0.1895, -0.3270],\n",
      "        ...,\n",
      "        [-0.1030, -1.1375, -0.5554,  ..., -0.7654,  0.0533, -0.7348],\n",
      "        [-0.0508, -1.1739, -0.6491,  ..., -0.7451,  0.2351, -0.5756],\n",
      "        [ 0.3988, -1.0708, -0.7413,  ..., -0.5885,  0.0319, -0.4228]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0580, -1.0444, -0.6646,  ..., -0.6271,  0.1521, -0.4525],\n",
      "        [ 0.1606, -1.0539, -0.7179,  ..., -0.7070, -0.0301, -0.5557],\n",
      "        [ 0.5605, -1.1058, -0.6879,  ..., -0.5945,  0.1367, -0.5936],\n",
      "        ...,\n",
      "        [-0.0618, -1.0844, -0.6679,  ..., -0.7631,  0.1779, -0.4235],\n",
      "        [ 0.3840, -1.2201, -0.5507,  ..., -0.7307,  0.0116, -0.2940],\n",
      "        [ 0.1057, -0.9621, -0.5156,  ..., -0.6353,  0.2702, -0.4741]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1621, -1.1265, -0.6680,  ..., -0.7180,  0.3637, -0.6208],\n",
      "        [-0.0108, -1.0432, -0.7245,  ..., -0.6688,  0.1010, -0.5104],\n",
      "        [-0.0556, -1.0168, -0.6653,  ..., -0.5443,  0.0399, -0.5911],\n",
      "        ...,\n",
      "        [ 0.1025, -1.4507, -0.6536,  ..., -0.7562,  0.0947, -0.8223],\n",
      "        [ 0.0613, -0.8803, -0.6818,  ..., -0.6583,  0.1180, -0.2902],\n",
      "        [-0.0507, -1.1904, -0.7436,  ..., -0.6375,  0.0631, -0.6884]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0020, -1.2579, -0.5725,  ..., -0.6721,  0.3468, -0.7143],\n",
      "        [ 0.0731, -1.2456, -0.6398,  ..., -0.7506,  0.0372, -0.2502],\n",
      "        [ 0.1082, -0.8696, -0.6401,  ..., -0.8000,  0.2696, -0.5473],\n",
      "        ...,\n",
      "        [ 0.0515, -0.8730, -0.5118,  ..., -0.6452,  0.2848, -0.5387],\n",
      "        [ 0.3348, -0.9878, -0.6158,  ..., -0.6151,  0.1032, -0.4525],\n",
      "        [ 0.1595, -1.1299, -0.7687,  ..., -0.6063,  0.0885, -0.4173]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2697, -1.3369, -0.8199,  ..., -0.6532,  0.1471, -0.7830],\n",
      "        [ 0.0522, -1.1087, -0.8406,  ..., -0.7129,  0.1372, -0.7125],\n",
      "        [-0.1005, -1.0035, -0.6725,  ..., -0.7638,  0.1953, -0.6190],\n",
      "        ...,\n",
      "        [ 0.1043, -1.2326, -0.5487,  ..., -0.6818,  0.0801, -0.5104],\n",
      "        [-0.1153, -0.9460, -0.5355,  ..., -0.8240,  0.0588, -0.5707],\n",
      "        [-0.1466, -0.9060, -0.6227,  ..., -0.8533,  0.3445, -0.7471]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0627, -1.1146, -0.6637,  ..., -0.6796,  0.2245, -0.3547],\n",
      "        [-0.0992, -0.7815, -0.3009,  ..., -0.9663,  0.1735, -0.5161],\n",
      "        [ 0.2895, -0.9804, -0.4899,  ..., -0.5077, -0.1855, -0.7193],\n",
      "        ...,\n",
      "        [ 0.2657, -1.2880, -0.7053,  ..., -0.6453,  0.0050, -0.7041],\n",
      "        [ 0.1060, -1.0580, -0.5003,  ..., -0.6655,  0.0586, -0.4888],\n",
      "        [-0.0421, -0.8369, -0.4241,  ..., -0.7993,  0.0453, -0.3805]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1926, -1.0464, -0.7201,  ..., -0.7769,  0.1913, -0.6450],\n",
      "        [-0.0525, -1.1425, -0.4388,  ..., -0.7971,  0.0450, -0.6809],\n",
      "        [-0.2361, -0.8715, -0.6750,  ..., -0.7585,  0.2474, -0.6098],\n",
      "        ...,\n",
      "        [ 0.1920, -1.0044, -0.3939,  ..., -0.8423,  0.1316, -0.3656],\n",
      "        [ 0.2924, -0.8977, -0.5255,  ..., -0.7744,  0.1012, -0.2088],\n",
      "        [-0.0954, -1.1192, -0.6242,  ..., -0.7239,  0.2659, -0.4843]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0272, -1.1899, -0.8974,  ..., -0.7238,  0.1224, -0.7988],\n",
      "        [ 0.1732, -1.1390, -0.9437,  ..., -0.6786,  0.0511, -0.5465],\n",
      "        [-0.1315, -1.0311, -0.4687,  ..., -0.8568,  0.0618, -0.4586],\n",
      "        ...,\n",
      "        [ 0.0134, -1.0420, -0.8658,  ..., -0.6518,  0.3089, -0.2904],\n",
      "        [-0.3180, -1.3397, -0.4851,  ..., -0.8365,  0.2582, -0.8999],\n",
      "        [ 0.2295, -0.8823, -0.7453,  ..., -0.4268, -0.0231, -0.5786]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2496, -0.9317, -0.5515,  ..., -0.7853,  0.1925, -0.5451],\n",
      "        [ 0.3750, -1.3798, -0.7073,  ..., -0.5810,  0.0248, -0.5237],\n",
      "        [-0.0638, -1.2919, -0.7866,  ..., -0.7226,  0.1359, -0.5577],\n",
      "        ...,\n",
      "        [-0.1889, -1.3343, -0.6682,  ..., -0.8215,  0.2440, -0.6492],\n",
      "        [ 0.0691, -0.9929, -0.6087,  ..., -0.7250,  0.1690, -0.4887],\n",
      "        [ 0.0166, -1.1741, -0.4925,  ..., -0.6732,  0.0612, -0.7586]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.4062, -0.9923, -0.7180,  ..., -0.7475,  0.2733, -0.5413],\n",
      "        [ 0.0032, -1.1229, -0.7762,  ..., -0.6645,  0.1455, -0.9530],\n",
      "        [ 0.0137, -1.0477, -0.6948,  ..., -0.5910,  0.0029, -0.6650],\n",
      "        ...,\n",
      "        [ 0.0595, -1.0243, -0.4774,  ..., -0.6757, -0.1145, -0.5658],\n",
      "        [-0.0535, -0.9732, -0.4391,  ..., -0.6521,  0.0720, -0.7121],\n",
      "        [-0.2296, -0.9752, -0.5271,  ..., -0.8560,  0.1466, -0.6802]],\n",
      "       device='mps:0')\n",
      "Epoch: 2 | Batch: 20 | Loss: 1.3241 | Acc: 39.43%\n",
      "cls_features:  tensor([[-0.2262, -0.8038, -0.6943,  ..., -0.7538,  0.1557, -0.4532],\n",
      "        [ 0.1291, -1.0332, -0.7008,  ..., -0.6420,  0.0317, -0.8013],\n",
      "        [ 0.0980, -0.9364, -0.6559,  ..., -0.6438,  0.2041, -0.7276],\n",
      "        ...,\n",
      "        [-0.1203, -1.1561, -0.7677,  ..., -0.7583, -0.1114, -0.6085],\n",
      "        [ 0.0036, -1.3682, -0.8666,  ..., -0.7135,  0.2955, -0.8269],\n",
      "        [-0.1601, -1.0651, -0.7715,  ..., -0.8326,  0.2723, -0.7615]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0589, -1.2226, -0.7750,  ..., -0.8762,  0.0616, -0.5705],\n",
      "        [ 0.0288, -1.0641, -0.2980,  ..., -0.9363,  0.0526, -0.3186],\n",
      "        [-0.0725, -1.2532, -0.8176,  ..., -0.6381,  0.1088, -0.7938],\n",
      "        ...,\n",
      "        [-0.0878, -1.1810, -0.7526,  ..., -0.8519,  0.2083, -0.6707],\n",
      "        [ 0.1084, -1.0954, -0.8413,  ..., -0.7238,  0.3618, -0.7057],\n",
      "        [ 0.4933, -1.1511, -0.4887,  ..., -0.6954, -0.2985, -0.7399]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2092, -0.9522, -0.2067,  ..., -0.8502,  0.2125, -0.5256],\n",
      "        [-0.1989, -0.9890, -0.6218,  ..., -0.6698,  0.2345, -0.5367],\n",
      "        [ 0.0458, -0.8807, -0.2054,  ..., -0.6992, -0.0013, -0.5077],\n",
      "        ...,\n",
      "        [-0.3446, -0.9115, -0.6187,  ..., -0.7494,  0.2068, -0.5708],\n",
      "        [-0.2349, -1.1415, -0.9256,  ..., -0.8287,  0.1530, -0.7152],\n",
      "        [ 0.1225, -1.1233, -0.5845,  ..., -0.6761,  0.2698, -0.6909]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1579, -0.9971, -0.6543,  ..., -0.6129,  0.1758, -0.5238],\n",
      "        [-0.0126, -0.9027, -0.6174,  ..., -0.7380,  0.1014, -0.5847],\n",
      "        [-0.1580, -1.2674, -0.5708,  ..., -0.9240,  0.1297, -0.6453],\n",
      "        ...,\n",
      "        [-0.2246, -0.8440, -0.7282,  ..., -0.4905,  0.0531, -0.5808],\n",
      "        [-0.2104, -0.8713, -0.4935,  ..., -0.7471,  0.0440, -0.7513],\n",
      "        [ 0.0038, -1.0191, -0.6438,  ..., -0.7416,  0.2559, -0.8533]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0342, -1.1576, -0.7263,  ..., -0.7788,  0.0914, -0.7655],\n",
      "        [ 0.0149, -0.9360, -0.5710,  ..., -0.8368,  0.0240, -0.4489],\n",
      "        [-0.0133, -0.8668, -0.5001,  ..., -0.7161,  0.1471, -0.4912],\n",
      "        ...,\n",
      "        [ 0.1898, -1.1441, -0.5363,  ..., -0.9067,  0.2834, -0.4584],\n",
      "        [-0.2795, -1.1226, -0.6107,  ..., -0.8031,  0.1654, -0.5710],\n",
      "        [-0.0262, -0.9968, -0.5725,  ..., -0.7486,  0.1981, -0.6944]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3159, -1.0293, -0.6334,  ..., -0.6454,  0.0776, -0.4216],\n",
      "        [-0.0478, -0.8204, -0.4113,  ..., -0.5690, -0.0332, -0.5034],\n",
      "        [-0.2635, -0.9157, -0.8611,  ..., -0.6951,  0.1707, -0.5222],\n",
      "        ...,\n",
      "        [ 0.4511, -0.9228, -0.8072,  ..., -0.7733, -0.0089, -0.4430],\n",
      "        [-0.3226, -1.0059, -0.8547,  ..., -0.5360,  0.2007, -0.7697],\n",
      "        [ 0.0778, -0.7513, -0.4061,  ..., -0.6846, -0.1957, -0.7020]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0760, -0.8783, -0.6624,  ..., -0.8375,  0.0335, -0.7298],\n",
      "        [-0.0689, -1.0017, -0.6669,  ..., -0.7865,  0.3330, -0.6312],\n",
      "        [-0.3343, -0.9704, -0.3762,  ..., -0.8643,  0.3236, -0.2879],\n",
      "        ...,\n",
      "        [ 0.0648, -0.9163, -0.5459,  ..., -0.7681,  0.3174, -0.5712],\n",
      "        [-0.1490, -1.2053, -0.7625,  ..., -0.7538,  0.1485, -0.7737],\n",
      "        [-0.2030, -1.2000, -0.7325,  ..., -0.6140, -0.1077, -0.5629]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0124, -1.0868, -0.2263,  ..., -0.5904, -0.0518, -0.7716],\n",
      "        [-0.2189, -0.8446, -0.3566,  ..., -0.8685,  0.2549, -0.4004],\n",
      "        [ 0.1405, -1.2262, -0.8079,  ..., -0.6834,  0.0992, -0.5273],\n",
      "        ...,\n",
      "        [-0.1344, -1.2967, -0.8332,  ..., -0.6773,  0.2017, -0.6869],\n",
      "        [-0.1245, -1.0744, -0.7004,  ..., -0.6755,  0.0151, -0.6488],\n",
      "        [-0.1270, -1.1209, -0.6766,  ..., -0.7922,  0.2751, -0.2481]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0509, -0.9989, -0.8005,  ..., -0.6571,  0.1851, -0.6437],\n",
      "        [-0.0863, -1.1522, -0.7392,  ..., -0.7425,  0.4315, -0.6412],\n",
      "        [ 0.0201, -0.8407, -0.4495,  ..., -0.9268,  0.1233, -0.5571],\n",
      "        ...,\n",
      "        [-0.3147, -0.8902, -0.5603,  ..., -0.7174,  0.1633, -0.5976],\n",
      "        [ 0.2078, -1.1964, -0.6902,  ..., -0.7369,  0.1046, -0.5204],\n",
      "        [ 0.1025, -1.2006, -0.6821,  ..., -0.8287,  0.1374, -0.5860]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-1.6902e-01, -9.7029e-01, -6.4627e-01,  ..., -8.6198e-01,\n",
      "          2.0582e-01, -3.8533e-01],\n",
      "        [-1.0919e-01, -9.7999e-01, -7.7765e-01,  ..., -7.2872e-01,\n",
      "          1.4098e-01, -4.6088e-01],\n",
      "        [-5.6329e-01, -1.1296e+00, -8.4509e-01,  ..., -7.8334e-01,\n",
      "          3.6691e-01, -7.2189e-01],\n",
      "        ...,\n",
      "        [-6.1250e-05, -1.1870e+00, -4.1698e-01,  ..., -6.5934e-01,\n",
      "         -6.2060e-03, -5.9925e-01],\n",
      "        [ 9.2747e-02, -1.0497e+00, -7.4675e-01,  ..., -7.9442e-01,\n",
      "          2.1337e-01, -4.0717e-01],\n",
      "        [-1.0238e-01, -1.1229e+00, -6.9029e-01,  ..., -6.5943e-01,\n",
      "         -1.2705e-02, -4.7473e-01]], device='mps:0')\n",
      "Epoch: 2 | Batch: 30 | Loss: 1.1679 | Acc: 41.13%\n",
      "cls_features:  tensor([[ 0.5143, -0.7612, -0.4394,  ..., -0.5973, -0.0773, -0.4070],\n",
      "        [ 0.0403, -1.3236, -0.6669,  ..., -0.8667,  0.1922, -0.7841],\n",
      "        [ 0.2648, -1.0559, -0.5409,  ..., -0.8616, -0.1320, -0.4381],\n",
      "        ...,\n",
      "        [-0.1529, -1.1601, -0.7585,  ..., -0.6845,  0.2254, -0.6419],\n",
      "        [-0.0162, -1.0189, -0.5765,  ..., -0.8610,  0.1026, -0.4120],\n",
      "        [ 0.0181, -1.2297, -0.4528,  ..., -0.8685,  0.4402, -0.6395]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2326, -0.7995, -0.4747,  ..., -0.7702,  0.2914, -0.5313],\n",
      "        [-0.1548, -0.9201, -0.4164,  ..., -0.8474, -0.0056, -0.6215],\n",
      "        [-0.4529, -0.9619, -0.4345,  ..., -0.9215,  0.1345, -0.2341],\n",
      "        ...,\n",
      "        [ 0.2499, -1.0059, -0.6497,  ..., -0.6938,  0.0411, -0.5288],\n",
      "        [ 0.2139, -1.0051, -0.4437,  ..., -0.8507,  0.0374, -0.5441],\n",
      "        [-0.0990, -0.8343, -0.9123,  ..., -0.6627,  0.1341, -0.4539]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0260, -0.9601, -0.5039,  ..., -0.6907,  0.1558, -0.3146],\n",
      "        [-0.2722, -0.8610, -0.6714,  ..., -0.7539,  0.3252, -0.3763],\n",
      "        [-0.1797, -0.7256, -0.5685,  ..., -0.9268,  0.3538, -0.4122],\n",
      "        ...,\n",
      "        [ 0.2656, -1.0400, -0.5054,  ..., -0.6770,  0.0988, -0.5886],\n",
      "        [-0.1959, -1.1304, -0.8303,  ..., -0.8573,  0.0260, -0.8918],\n",
      "        [-0.4092, -1.1161, -0.6726,  ..., -0.7572,  0.2085, -0.5254]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1923, -0.9140, -0.5956,  ..., -0.8789,  0.1905, -0.4366],\n",
      "        [-0.1569, -0.8599, -0.3480,  ..., -0.7587,  0.0193, -0.3213],\n",
      "        [-0.2706, -1.0756, -0.4968,  ..., -0.7183,  0.1885, -0.6208],\n",
      "        ...,\n",
      "        [-0.0505, -1.1380, -0.8275,  ..., -0.7461,  0.2553, -0.6573],\n",
      "        [ 0.2774, -0.9045, -0.4449,  ..., -0.7457,  0.0809, -0.4799],\n",
      "        [ 0.2034, -1.1968, -0.6721,  ..., -0.7720,  0.0487, -0.7429]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0943, -0.8153, -0.4427,  ..., -0.7607, -0.0773, -0.8436],\n",
      "        [-0.2439, -1.1641, -0.5098,  ..., -0.7128,  0.2331, -0.6152],\n",
      "        [ 0.1363, -1.1519, -0.8195,  ..., -0.6688,  0.0034, -0.5131],\n",
      "        ...,\n",
      "        [ 0.0955, -0.9829, -0.5350,  ..., -0.7844, -0.0107, -0.6952],\n",
      "        [ 0.0056, -1.1547, -0.7725,  ..., -0.6207,  0.3727, -0.5957],\n",
      "        [-0.1009, -1.0794, -0.8495,  ..., -0.8213,  0.2858, -0.4611]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3715, -0.8997, -0.6617,  ..., -0.8239,  0.1999, -0.2282],\n",
      "        [-0.1082, -0.7064, -0.5509,  ..., -0.7917,  0.2774, -0.2686],\n",
      "        [ 0.3018, -0.9063, -0.3530,  ..., -0.6781, -0.0024, -0.3863],\n",
      "        ...,\n",
      "        [ 0.2196, -1.1738, -0.5947,  ..., -0.6780,  0.0440, -0.7237],\n",
      "        [-0.1822, -1.1268, -0.8628,  ..., -0.7404,  0.3281, -0.8656],\n",
      "        [-0.1361, -1.0150, -0.4521,  ..., -0.6563,  0.1275, -0.8110]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0668, -1.1597, -0.4415,  ..., -0.8292,  0.1595, -0.4503],\n",
      "        [-0.1561, -0.9481, -0.6985,  ..., -0.8588,  0.2524, -0.4483],\n",
      "        [ 0.3879, -1.1935, -0.6147,  ..., -0.8383,  0.1475, -0.5456],\n",
      "        ...,\n",
      "        [-0.0635, -0.8726, -0.3165,  ..., -0.8076,  0.2255, -0.4317],\n",
      "        [-0.2119, -1.0333, -0.7679,  ..., -0.9379,  0.1268, -0.7548],\n",
      "        [-0.3475, -1.1107, -0.6155,  ..., -0.7513,  0.1120, -0.7664]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.6176e-01, -1.1564e+00, -5.3197e-01,  ..., -9.0170e-01,\n",
      "         -8.0602e-04, -8.5764e-01],\n",
      "        [ 1.5561e-01, -1.1294e+00, -4.5716e-01,  ..., -8.4043e-01,\n",
      "         -2.8045e-02, -6.1134e-01],\n",
      "        [ 2.1286e-01, -1.0161e+00, -6.4587e-01,  ..., -6.7691e-01,\n",
      "          6.0130e-02, -7.3311e-01],\n",
      "        ...,\n",
      "        [-4.2489e-01, -1.0063e+00, -5.8820e-01,  ..., -8.2909e-01,\n",
      "          2.2735e-01, -6.0393e-01],\n",
      "        [-5.6868e-03, -1.0643e+00, -8.1814e-01,  ..., -6.7322e-01,\n",
      "          6.3696e-02, -6.7690e-01],\n",
      "        [-2.2384e-01, -1.1137e+00, -8.5815e-01,  ..., -6.9156e-01,\n",
      "          1.9319e-01, -5.9756e-01]], device='mps:0')\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 1.1534 | Train Acc: 41.30%\n",
      "Val Loss: 0.9787 | Val Acc: 50.50%\n",
      "cls_features:  tensor([[ 0.1890, -1.1461, -0.7466,  ..., -0.7856,  0.1853, -0.6568],\n",
      "        [-0.2652, -1.1131, -0.7387,  ..., -0.8411,  0.0998, -0.4629],\n",
      "        [-0.3396, -0.9687, -0.8067,  ..., -0.9493,  0.2691, -0.6589],\n",
      "        ...,\n",
      "        [ 0.0335, -1.2904, -0.8230,  ..., -0.8074,  0.1306, -0.9303],\n",
      "        [-0.0764, -1.2144, -0.9440,  ..., -0.8063,  0.2591, -0.4365],\n",
      "        [ 0.1745, -1.2509, -0.3148,  ..., -0.8463,  0.0134, -0.6765]],\n",
      "       device='mps:0')\n",
      "Epoch: 3 | Batch: 0 | Loss: 1.0863 | Acc: 43.75%\n",
      "cls_features:  tensor([[ 0.2643, -1.2690, -0.7430,  ..., -0.5389,  0.0061, -0.7822],\n",
      "        [-0.1006, -0.9009, -0.7192,  ..., -0.5822,  0.1332, -0.6935],\n",
      "        [-0.1421, -0.8942, -0.5041,  ..., -0.8002,  0.1906, -0.3958],\n",
      "        ...,\n",
      "        [-0.1989, -0.9890, -0.6218,  ..., -0.6698,  0.2345, -0.5367],\n",
      "        [-0.2349, -1.1415, -0.9256,  ..., -0.8287,  0.1530, -0.7152],\n",
      "        [ 0.0100, -0.6726, -0.4991,  ..., -0.7621,  0.0689, -0.4069]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2096, -1.1807, -0.4476,  ..., -0.8584, -0.0667, -0.7856],\n",
      "        [-0.0466, -1.2605, -0.7633,  ..., -0.8750,  0.0793, -0.5408],\n",
      "        [-0.1613, -1.1728, -0.5760,  ..., -0.6414,  0.0730, -0.3791],\n",
      "        ...,\n",
      "        [ 0.0554, -1.0014, -0.8184,  ..., -0.6075,  0.1935, -0.4624],\n",
      "        [-0.0342, -1.0906, -0.4619,  ..., -0.7902,  0.0173, -0.5510],\n",
      "        [ 0.1814, -1.1226, -0.6828,  ..., -0.7942,  0.3214, -0.8461]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0016, -0.9903, -0.4285,  ..., -0.8851,  0.1675, -0.4765],\n",
      "        [-0.2511, -0.9835, -0.6799,  ..., -0.7700,  0.3372, -0.4707],\n",
      "        [ 0.1632, -1.1014, -0.5859,  ..., -0.5534, -0.2142, -0.8543],\n",
      "        ...,\n",
      "        [ 0.0978, -1.1951, -0.3823,  ..., -0.7291, -0.1429, -0.6110],\n",
      "        [-0.2407, -1.0870, -0.5522,  ..., -0.7365,  0.1965, -0.7129],\n",
      "        [ 0.3307, -0.8814, -0.5930,  ..., -0.7683,  0.0894, -0.2702]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2974, -0.9029, -0.2935,  ..., -0.9778,  0.1339, -0.3562],\n",
      "        [-0.3463, -1.1988, -0.5247,  ..., -0.8495,  0.4603, -0.5458],\n",
      "        [-0.0992, -0.7815, -0.3009,  ..., -0.9663,  0.1735, -0.5161],\n",
      "        ...,\n",
      "        [ 0.0434, -0.8980, -0.4547,  ..., -0.8720, -0.1816, -0.3499],\n",
      "        [ 0.4292, -1.0752, -0.5033,  ..., -0.4314, -0.1128, -0.6723],\n",
      "        [-0.0834, -0.9506, -0.6723,  ..., -0.8934,  0.3147, -0.6482]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0547, -0.9380, -0.6548,  ..., -0.7498,  0.1511, -0.4502],\n",
      "        [ 0.3152, -1.0621, -0.5392,  ..., -0.6968, -0.0285, -0.3753],\n",
      "        [ 0.0764, -1.1509, -0.9222,  ..., -0.7722,  0.2096, -0.3937],\n",
      "        ...,\n",
      "        [-0.1111, -1.2041, -0.8300,  ..., -0.8470,  0.4552, -0.2679],\n",
      "        [-0.4171, -1.1264, -0.6421,  ..., -0.9097,  0.1265, -0.6818],\n",
      "        [ 0.2201, -1.1324, -0.7083,  ..., -0.6859, -0.0298, -0.6395]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0262, -1.3344, -1.0830,  ..., -0.6499,  0.2520, -0.6252],\n",
      "        [ 0.0859, -1.0355, -0.4746,  ..., -0.7937,  0.1924, -0.5738],\n",
      "        [-0.3278, -0.9630, -0.7630,  ..., -0.7708,  0.2166, -0.6694],\n",
      "        ...,\n",
      "        [-0.0342, -1.1576, -0.7263,  ..., -0.7788,  0.0914, -0.7655],\n",
      "        [-0.0689, -1.0017, -0.6669,  ..., -0.7866,  0.3330, -0.6312],\n",
      "        [-0.1545, -1.3325, -0.7679,  ..., -0.8634,  0.3877, -0.5411]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0909, -0.7514, -0.7282,  ..., -0.6931,  0.1408, -0.3802],\n",
      "        [-0.1001, -1.1534, -0.8334,  ..., -0.6019,  0.1754, -0.7845],\n",
      "        [ 0.0798, -1.1573, -0.3517,  ..., -0.7793,  0.0795, -0.4380],\n",
      "        ...,\n",
      "        [-0.1991, -1.0772, -0.7827,  ..., -0.8137,  0.2211, -0.4936],\n",
      "        [-0.2142, -1.1929, -1.0085,  ..., -0.6702,  0.5953, -0.2776],\n",
      "        [ 0.0664, -1.4056, -0.9461,  ..., -0.6953,  0.2494, -0.9267]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3933, -1.0310, -0.3782,  ..., -0.7966,  0.1195, -0.6845],\n",
      "        [-0.1198, -0.8924, -0.5874,  ..., -0.5457,  0.1285, -0.6181],\n",
      "        [ 0.1060, -1.0580, -0.5003,  ..., -0.6655,  0.0586, -0.4888],\n",
      "        ...,\n",
      "        [ 0.5605, -1.1058, -0.6879,  ..., -0.5945,  0.1367, -0.5936],\n",
      "        [-0.2574, -1.0153, -0.7538,  ..., -0.8565,  0.2692, -0.3483],\n",
      "        [ 0.3235, -0.9888, -0.5747,  ..., -0.7586, -0.1594, -0.5578]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0116, -0.7296, -0.7635,  ..., -0.7107,  0.3773, -0.3491],\n",
      "        [-0.0306, -1.0937, -0.9570,  ..., -0.5805,  0.1420, -0.7495],\n",
      "        [-0.1101, -1.2095, -0.8014,  ..., -0.7178,  0.2269, -0.6457],\n",
      "        ...,\n",
      "        [ 0.1734, -1.0362, -0.4245,  ..., -0.8193,  0.0100, -0.6914],\n",
      "        [ 0.1796, -0.7137, -0.3981,  ..., -0.6962, -0.0987, -0.4846],\n",
      "        [ 0.2623, -1.2977, -0.8639,  ..., -0.6897,  0.0589, -0.7554]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1288, -1.0167, -0.5432,  ..., -0.6229,  0.1347, -0.3415],\n",
      "        [-0.1529, -1.0835, -0.4536,  ..., -0.6425,  0.1352, -0.9035],\n",
      "        [-0.0242, -1.0211, -0.6606,  ..., -0.7963,  0.3457, -0.5070],\n",
      "        ...,\n",
      "        [ 0.0355, -0.9570, -0.3666,  ..., -0.7469,  0.1020, -0.6279],\n",
      "        [-0.1357, -1.2081, -0.8115,  ..., -0.7099,  0.1258, -0.5309],\n",
      "        [ 0.0277, -1.0050, -0.6606,  ..., -0.7357,  0.0729, -0.5258]],\n",
      "       device='mps:0')\n",
      "Epoch: 3 | Batch: 10 | Loss: 0.8447 | Acc: 45.45%\n",
      "cls_features:  tensor([[-0.3103, -0.8076, -0.6448,  ..., -0.9706,  0.1509, -0.5454],\n",
      "        [ 0.2450, -1.2289, -0.5948,  ..., -0.7491,  0.1013, -0.6281],\n",
      "        [-0.4528, -1.1092, -0.5052,  ..., -0.7843,  0.4402, -0.8515],\n",
      "        ...,\n",
      "        [ 0.3885, -1.0816, -0.4351,  ..., -0.6171, -0.2097, -0.4522],\n",
      "        [-0.1185, -0.8766, -0.5465,  ..., -0.8224,  0.1341, -0.4454],\n",
      "        [-0.1024, -1.1229, -0.6903,  ..., -0.6594, -0.0127, -0.4747]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1006, -0.8594, -0.8519,  ..., -0.8790,  0.1057, -0.4700],\n",
      "        [ 0.3925, -0.9824, -0.6798,  ..., -0.6615,  0.2117, -0.2858],\n",
      "        [ 0.2339, -1.1599, -0.7043,  ..., -0.5851,  0.2271, -0.4162],\n",
      "        ...,\n",
      "        [-0.0549, -1.0127, -0.7682,  ..., -0.9668,  0.2456, -0.5628],\n",
      "        [ 0.1090, -1.0436, -0.5091,  ..., -0.9106,  0.0574, -0.6835],\n",
      "        [-0.0547, -1.0147, -0.7242,  ..., -0.7005,  0.2461, -0.6163]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0126, -0.9027, -0.6174,  ..., -0.7380,  0.1014, -0.5847],\n",
      "        [ 0.3194, -0.9816, -0.6813,  ..., -0.7008, -0.3522, -0.5842],\n",
      "        [-0.0900, -1.2999, -0.8430,  ..., -0.5549,  0.2248, -0.4850],\n",
      "        ...,\n",
      "        [ 0.0648, -0.9163, -0.5459,  ..., -0.7681,  0.3174, -0.5712],\n",
      "        [-0.4858, -0.8862, -0.5170,  ..., -0.8175,  0.2693, -0.5294],\n",
      "        [-0.1203, -1.1561, -0.7677,  ..., -0.7583, -0.1114, -0.6085]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 1.3492e-01, -1.0359e+00, -5.0863e-01,  ..., -5.8146e-01,\n",
      "          5.3059e-02, -4.0094e-01],\n",
      "        [ 1.1074e-01, -9.3840e-01, -4.4797e-01,  ..., -7.0787e-01,\n",
      "          1.1941e-01, -5.5135e-01],\n",
      "        [ 1.4548e-02, -1.0799e+00, -7.8812e-01,  ..., -7.5290e-01,\n",
      "          9.5946e-02, -5.2518e-01],\n",
      "        ...,\n",
      "        [ 4.0645e-01, -1.2035e+00, -8.9368e-01,  ..., -7.3595e-01,\n",
      "          1.5234e-01, -4.3821e-01],\n",
      "        [ 1.4426e-01, -1.1851e+00, -6.3118e-01,  ..., -7.3357e-01,\n",
      "          1.7926e-01, -5.2424e-01],\n",
      "        [ 8.2465e-04, -1.0405e+00, -3.3133e-01,  ..., -9.0710e-01,\n",
      "          9.6757e-02, -3.4645e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.3442, -0.9843, -0.5179,  ..., -0.8848,  0.1150, -0.5427],\n",
      "        [ 0.2701, -0.9995, -0.6882,  ..., -0.9293,  0.1148, -0.3716],\n",
      "        [ 0.0522, -1.1087, -0.8406,  ..., -0.7129,  0.1372, -0.7125],\n",
      "        ...,\n",
      "        [ 0.0150, -1.1653, -0.5247,  ..., -0.7440,  0.3567, -0.6713],\n",
      "        [ 0.2047, -0.8743, -0.5832,  ..., -0.6689, -0.0395, -0.5837],\n",
      "        [-0.1696, -1.1277, -0.6153,  ..., -0.8611,  0.2972, -0.4850]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1524, -1.0589, -0.7424,  ..., -0.7642,  0.3178, -0.5612],\n",
      "        [ 0.2520, -0.9918, -0.4732,  ..., -0.9548,  0.0637, -0.2517],\n",
      "        [ 0.1982, -0.6942, -0.4509,  ..., -0.6856, -0.0702, -0.2861],\n",
      "        ...,\n",
      "        [-0.0465, -0.9524, -0.5494,  ..., -0.6519,  0.0447, -0.3017],\n",
      "        [ 0.1777, -1.1049, -0.7452,  ..., -0.7812,  0.2188, -0.3240],\n",
      "        [-0.1417, -0.9212, -0.6605,  ..., -0.6073,  0.0946, -0.5609]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2479, -0.9767, -0.4196,  ..., -0.7331, -0.0553, -0.3768],\n",
      "        [ 0.0403, -1.3236, -0.6669,  ..., -0.8667,  0.1922, -0.7841],\n",
      "        [-0.0194, -0.9525, -0.7026,  ..., -0.6834,  0.0227, -0.7242],\n",
      "        ...,\n",
      "        [ 0.0994, -1.1471, -0.6164,  ..., -0.8475,  0.1146, -0.7579],\n",
      "        [-0.2104, -0.8713, -0.4935,  ..., -0.7471,  0.0440, -0.7513],\n",
      "        [ 0.0091, -1.0855, -0.4191,  ..., -0.7159,  0.1378, -0.5719]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2232, -0.9458, -0.8591,  ..., -0.7458,  0.0459, -0.6365],\n",
      "        [-0.1490, -1.2053, -0.7625,  ..., -0.7538,  0.1485, -0.7737],\n",
      "        [ 0.0276, -1.0446, -0.5764,  ..., -0.8732,  0.1121, -0.5180],\n",
      "        ...,\n",
      "        [ 0.0409, -0.9667, -0.8253,  ..., -0.6967, -0.1295, -0.8062],\n",
      "        [-0.0683, -0.9004, -0.6125,  ..., -0.6664,  0.2181, -0.4977],\n",
      "        [ 0.0666, -1.1191, -1.0275,  ..., -0.7845,  0.1764, -0.6930]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1866, -0.8551, -0.7476,  ..., -0.6093,  0.0529, -0.5912],\n",
      "        [ 0.2811, -0.9919, -0.5758,  ..., -0.5239,  0.2393, -0.5209],\n",
      "        [ 0.1043, -1.2326, -0.5487,  ..., -0.6818,  0.0801, -0.5104],\n",
      "        ...,\n",
      "        [-0.0294, -1.3198, -0.6707,  ..., -0.8885,  0.3613, -0.5401],\n",
      "        [-0.1153, -0.9460, -0.5355,  ..., -0.8240,  0.0588, -0.5707],\n",
      "        [-0.3446, -0.9115, -0.6187,  ..., -0.7494,  0.2068, -0.5708]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2302, -0.9742, -0.6729,  ..., -0.7820,  0.1208, -0.2505],\n",
      "        [-0.1016, -0.8341, -0.5529,  ..., -0.6923,  0.0129, -0.4868],\n",
      "        [-0.0649, -1.1004, -0.7694,  ..., -0.7785,  0.1888, -0.5928],\n",
      "        ...,\n",
      "        [-0.0507, -1.1904, -0.7436,  ..., -0.6375,  0.0631, -0.6884],\n",
      "        [ 0.6409, -1.1609, -0.5532,  ..., -0.7482, -0.0461, -0.4540],\n",
      "        [-0.1922, -0.9938, -0.7512,  ..., -0.7435,  0.1959, -0.3558]],\n",
      "       device='mps:0')\n",
      "Epoch: 3 | Batch: 20 | Loss: 0.9547 | Acc: 44.20%\n",
      "cls_features:  tensor([[-0.1260, -1.1185, -0.9484,  ..., -0.6957,  0.1721, -0.7400],\n",
      "        [-0.0785, -1.0273, -0.7981,  ..., -0.6006,  0.1170, -0.7063],\n",
      "        [-0.0738, -1.0881, -0.6380,  ..., -0.6332,  0.2673, -0.5659],\n",
      "        ...,\n",
      "        [-0.1526, -0.9625, -0.4863,  ..., -0.9370,  0.1968, -0.7011],\n",
      "        [ 0.1921, -0.7483, -0.5840,  ..., -0.7929, -0.1146, -0.3104],\n",
      "        [ 0.0597, -0.9894, -0.8970,  ..., -0.7356,  0.3257, -0.5040]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1440, -1.1768, -0.6827,  ..., -0.7945,  0.3782, -0.6978],\n",
      "        [ 0.1926, -1.0464, -0.7201,  ..., -0.7769,  0.1913, -0.6450],\n",
      "        [ 0.2316, -1.0108, -0.7795,  ..., -0.7803,  0.2022, -0.6064],\n",
      "        ...,\n",
      "        [ 0.0871, -0.9218, -0.3385,  ..., -0.9691,  0.1938, -0.2011],\n",
      "        [ 0.0160, -0.9289, -0.4498,  ..., -0.9086,  0.1405, -0.4891],\n",
      "        [-0.1784, -1.1289, -0.8454,  ..., -0.8231,  0.1070, -0.5418]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1245, -1.0744, -0.7004,  ..., -0.6755,  0.0151, -0.6488],\n",
      "        [ 0.0864, -1.1285, -0.6507,  ..., -0.6662,  0.2598, -0.3963],\n",
      "        [-0.0292, -1.0468, -0.6351,  ..., -0.6714, -0.1138, -0.7131],\n",
      "        ...,\n",
      "        [-0.2311, -1.1597, -0.6201,  ..., -0.8137,  0.2666, -0.6187],\n",
      "        [ 0.0325, -0.9328, -0.9484,  ..., -0.6823, -0.0903, -0.5190],\n",
      "        [ 0.1615, -1.0652, -0.7921,  ..., -0.6756, -0.0106, -0.8299]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2180, -1.1709, -0.7308,  ..., -0.6760,  0.2023, -0.5484],\n",
      "        [-0.0480, -0.9855, -0.6387,  ..., -0.8531,  0.1430, -0.4952],\n",
      "        [ 0.4323, -1.2057, -0.7014,  ..., -0.5564, -0.0076, -0.3641],\n",
      "        ...,\n",
      "        [ 0.2499, -1.2693, -0.5426,  ..., -0.8121,  0.0935, -0.8438],\n",
      "        [ 0.1528, -1.1093, -0.6921,  ..., -0.7562, -0.1303, -0.5353],\n",
      "        [-0.3391, -1.1445, -0.6918,  ..., -0.7852,  0.0597, -0.7151]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 3.5758e-01, -9.2989e-01, -2.7734e-01,  ..., -8.5847e-01,\n",
      "         -1.6895e-02, -1.7666e-01],\n",
      "        [ 2.4053e-05, -1.0759e+00, -5.7872e-01,  ..., -8.7431e-01,\n",
      "          1.8126e-01, -2.7379e-01],\n",
      "        [-1.4842e-01, -1.1015e+00, -7.6199e-01,  ..., -8.3880e-01,\n",
      "          2.7315e-01, -5.5038e-01],\n",
      "        ...,\n",
      "        [ 3.3538e-01, -1.1893e+00, -5.4182e-01,  ..., -6.1940e-01,\n",
      "         -1.3322e-01, -5.0437e-01],\n",
      "        [ 1.8153e-01, -1.2353e+00, -8.0671e-01,  ..., -6.1245e-01,\n",
      "          3.5548e-01, -6.6309e-01],\n",
      "        [-1.0115e-01, -9.0410e-01, -4.8466e-01,  ..., -8.0129e-01,\n",
      "          1.7274e-01, -6.6652e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.1871, -0.9581, -0.4624,  ..., -0.7206,  0.0602, -0.7104],\n",
      "        [-0.0352, -1.0448, -0.6770,  ..., -0.5697,  0.0612, -0.4470],\n",
      "        [ 0.3752, -1.0149, -0.8951,  ..., -0.5651,  0.1654, -0.5341],\n",
      "        ...,\n",
      "        [-0.1265, -1.0497, -0.6695,  ..., -0.7420,  0.1102, -0.7751],\n",
      "        [ 0.1273, -0.9711, -0.5232,  ..., -0.7356,  0.2616, -0.2892],\n",
      "        [ 0.1776, -1.1669, -0.5168,  ..., -0.8067,  0.0479, -0.5913]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1257, -1.1308, -0.5046,  ..., -0.7745,  0.1917, -0.5722],\n",
      "        [-0.1692, -1.1736, -0.5913,  ..., -0.7767,  0.0799, -0.6405],\n",
      "        [-0.2421, -1.2222, -1.0016,  ..., -0.9265,  0.4606, -0.5723],\n",
      "        ...,\n",
      "        [ 0.1405, -1.2262, -0.8079,  ..., -0.6834,  0.0992, -0.5273],\n",
      "        [ 0.4403, -1.2694, -0.8072,  ..., -0.6841,  0.1126, -0.2142],\n",
      "        [-0.1266, -1.1122, -0.3815,  ..., -0.7335,  0.1075, -0.4601]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0386, -1.2370, -0.8592,  ..., -0.7422,  0.4452, -0.7555],\n",
      "        [ 0.1933, -1.1268, -0.4161,  ..., -0.6803, -0.1472, -0.4296],\n",
      "        [ 0.0137, -1.0477, -0.6948,  ..., -0.5910,  0.0029, -0.6650],\n",
      "        ...,\n",
      "        [ 0.0257, -1.0188, -0.5843,  ..., -0.7504, -0.0515, -0.5261],\n",
      "        [-0.0873, -1.1382, -0.6872,  ..., -0.7295,  0.1450, -0.7517],\n",
      "        [ 0.1450, -0.9368, -0.5751,  ..., -0.7366,  0.1095, -0.4932]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1503, -1.0268, -0.5126,  ..., -1.0124,  0.0914, -0.4826],\n",
      "        [-0.2243, -1.1398, -0.7532,  ..., -0.7567,  0.2030, -0.7933],\n",
      "        [ 0.1670, -1.4367, -0.8942,  ..., -0.5827,  0.2080, -0.9111],\n",
      "        ...,\n",
      "        [-0.2449, -0.9141, -0.6438,  ..., -0.7625,  0.4323, -0.3965],\n",
      "        [ 0.1459, -1.1373, -0.4982,  ..., -0.6505,  0.2522, -0.7802],\n",
      "        [ 0.1671, -1.2013, -0.6498,  ..., -0.5715, -0.1013, -0.5450]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2245, -0.8736, -0.4611,  ..., -0.8476,  0.0798, -0.2241],\n",
      "        [-0.0640, -0.9327, -0.5478,  ..., -0.7149,  0.0875, -0.6156],\n",
      "        [ 0.0359, -0.8837, -0.5838,  ..., -0.9442,  0.0351, -0.3746],\n",
      "        ...,\n",
      "        [-0.0396, -0.9557, -0.7431,  ..., -0.6275,  0.0336, -0.4472],\n",
      "        [-0.0147, -1.2766, -0.7067,  ..., -0.8933,  0.1435, -0.8236],\n",
      "        [ 0.1480, -1.0573, -0.6707,  ..., -0.6677,  0.2628, -0.3739]],\n",
      "       device='mps:0')\n",
      "Epoch: 3 | Batch: 30 | Loss: 1.0452 | Acc: 42.64%\n",
      "cls_features:  tensor([[ 0.2892, -1.2487, -0.7498,  ..., -0.6092,  0.1936, -0.5166],\n",
      "        [-0.3269, -1.0253, -0.6100,  ..., -0.9399,  0.2367, -0.6532],\n",
      "        [ 0.2482, -0.9980, -0.5558,  ..., -0.6681,  0.0223, -0.5311],\n",
      "        ...,\n",
      "        [-0.1549, -0.9147, -0.7176,  ..., -0.8170,  0.1535, -0.5803],\n",
      "        [ 0.2161, -1.2914, -0.7089,  ..., -0.8051, -0.0714, -0.5558],\n",
      "        [-0.5409, -1.0111, -0.6785,  ..., -0.6901,  0.2505, -0.7047]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2326, -0.7995, -0.4747,  ..., -0.7702,  0.2914, -0.5313],\n",
      "        [-0.1548, -0.9201, -0.4164,  ..., -0.8474, -0.0056, -0.6215],\n",
      "        [-0.4529, -0.9619, -0.4345,  ..., -0.9215,  0.1345, -0.2341],\n",
      "        ...,\n",
      "        [ 0.2499, -1.0059, -0.6497,  ..., -0.6938,  0.0411, -0.5288],\n",
      "        [ 0.2139, -1.0051, -0.4437,  ..., -0.8507,  0.0374, -0.5441],\n",
      "        [-0.0990, -0.8343, -0.9123,  ..., -0.6627,  0.1341, -0.4539]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0260, -0.9601, -0.5039,  ..., -0.6907,  0.1558, -0.3146],\n",
      "        [-0.2722, -0.8610, -0.6714,  ..., -0.7539,  0.3252, -0.3763],\n",
      "        [-0.1797, -0.7256, -0.5685,  ..., -0.9268,  0.3538, -0.4122],\n",
      "        ...,\n",
      "        [ 0.2656, -1.0400, -0.5054,  ..., -0.6770,  0.0988, -0.5886],\n",
      "        [-0.1959, -1.1304, -0.8303,  ..., -0.8573,  0.0260, -0.8918],\n",
      "        [-0.4092, -1.1161, -0.6726,  ..., -0.7572,  0.2085, -0.5254]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1923, -0.9140, -0.5956,  ..., -0.8789,  0.1905, -0.4366],\n",
      "        [-0.1569, -0.8599, -0.3480,  ..., -0.7587,  0.0193, -0.3213],\n",
      "        [-0.2706, -1.0756, -0.4968,  ..., -0.7183,  0.1885, -0.6208],\n",
      "        ...,\n",
      "        [-0.0505, -1.1380, -0.8275,  ..., -0.7461,  0.2553, -0.6573],\n",
      "        [ 0.2774, -0.9045, -0.4449,  ..., -0.7457,  0.0809, -0.4799],\n",
      "        [ 0.2034, -1.1968, -0.6721,  ..., -0.7720,  0.0487, -0.7429]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0943, -0.8153, -0.4427,  ..., -0.7607, -0.0773, -0.8436],\n",
      "        [-0.2439, -1.1641, -0.5098,  ..., -0.7128,  0.2331, -0.6152],\n",
      "        [ 0.1363, -1.1519, -0.8195,  ..., -0.6688,  0.0034, -0.5131],\n",
      "        ...,\n",
      "        [ 0.0955, -0.9829, -0.5350,  ..., -0.7844, -0.0107, -0.6952],\n",
      "        [ 0.0056, -1.1547, -0.7725,  ..., -0.6207,  0.3727, -0.5957],\n",
      "        [-0.1009, -1.0794, -0.8495,  ..., -0.8213,  0.2858, -0.4611]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3715, -0.8997, -0.6617,  ..., -0.8239,  0.1999, -0.2282],\n",
      "        [-0.1082, -0.7064, -0.5509,  ..., -0.7917,  0.2774, -0.2686],\n",
      "        [ 0.3018, -0.9063, -0.3530,  ..., -0.6781, -0.0024, -0.3863],\n",
      "        ...,\n",
      "        [ 0.2196, -1.1738, -0.5947,  ..., -0.6780,  0.0440, -0.7237],\n",
      "        [-0.1822, -1.1268, -0.8628,  ..., -0.7404,  0.3281, -0.8656],\n",
      "        [-0.1361, -1.0150, -0.4521,  ..., -0.6563,  0.1275, -0.8110]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0668, -1.1597, -0.4415,  ..., -0.8292,  0.1595, -0.4503],\n",
      "        [-0.1561, -0.9481, -0.6985,  ..., -0.8588,  0.2524, -0.4483],\n",
      "        [ 0.3879, -1.1935, -0.6147,  ..., -0.8383,  0.1475, -0.5456],\n",
      "        ...,\n",
      "        [-0.0635, -0.8726, -0.3165,  ..., -0.8076,  0.2255, -0.4317],\n",
      "        [-0.2119, -1.0333, -0.7679,  ..., -0.9379,  0.1268, -0.7548],\n",
      "        [-0.3475, -1.1107, -0.6155,  ..., -0.7513,  0.1120, -0.7664]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.6176e-01, -1.1564e+00, -5.3197e-01,  ..., -9.0170e-01,\n",
      "         -8.0596e-04, -8.5764e-01],\n",
      "        [ 1.5561e-01, -1.1294e+00, -4.5716e-01,  ..., -8.4043e-01,\n",
      "         -2.8045e-02, -6.1134e-01],\n",
      "        [ 2.1286e-01, -1.0161e+00, -6.4587e-01,  ..., -6.7691e-01,\n",
      "          6.0130e-02, -7.3311e-01],\n",
      "        ...,\n",
      "        [-4.2489e-01, -1.0063e+00, -5.8820e-01,  ..., -8.2909e-01,\n",
      "          2.2735e-01, -6.0393e-01],\n",
      "        [-5.6875e-03, -1.0643e+00, -8.1814e-01,  ..., -6.7322e-01,\n",
      "          6.3696e-02, -6.7690e-01],\n",
      "        [-2.2384e-01, -1.1137e+00, -8.5815e-01,  ..., -6.9156e-01,\n",
      "          1.9319e-01, -5.9756e-01]], device='mps:0')\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 1.1291 | Train Acc: 42.60%\n",
      "Val Loss: 0.9777 | Val Acc: 50.50%\n",
      "cls_features:  tensor([[-0.2027, -1.1455, -0.4105,  ..., -0.6668,  0.1322, -0.5259],\n",
      "        [ 0.0391, -1.0498, -0.7412,  ..., -0.5449,  0.0615, -0.3207],\n",
      "        [ 0.1581, -0.8213, -0.4073,  ..., -0.7470, -0.0223, -0.6478],\n",
      "        ...,\n",
      "        [-0.0244, -1.1139, -0.8900,  ..., -0.7581,  0.0119, -0.7185],\n",
      "        [ 0.1372, -0.8323, -0.5856,  ..., -0.5977, -0.0429, -0.5089],\n",
      "        [ 0.3514, -1.0736, -0.6168,  ..., -0.5682, -0.1305, -0.5906]],\n",
      "       device='mps:0')\n",
      "Epoch: 4 | Batch: 0 | Loss: 1.1873 | Acc: 31.25%\n",
      "cls_features:  tensor([[-0.0784, -0.9734, -0.5087,  ..., -0.7161,  0.2959, -0.4213],\n",
      "        [ 0.0173, -0.8977, -0.6510,  ..., -0.7374, -0.1719, -0.3740],\n",
      "        [-0.2104, -0.8713, -0.4935,  ..., -0.7471,  0.0440, -0.7513],\n",
      "        ...,\n",
      "        [-0.0893, -1.1851, -0.6616,  ..., -0.5832,  0.1314, -0.4927],\n",
      "        [ 0.2845, -1.4281, -0.5401,  ..., -0.7419,  0.2619, -0.6621],\n",
      "        [ 0.3034, -1.0809, -0.6613,  ..., -0.5564, -0.0698, -0.4208]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2825, -1.0650, -0.5928,  ..., -0.7868,  0.1065, -0.5189],\n",
      "        [-0.2889, -0.9562, -0.7006,  ..., -0.9715,  0.2908, -0.4267],\n",
      "        [ 0.0494, -1.0664, -0.5271,  ..., -0.8189,  0.0862, -0.5411],\n",
      "        ...,\n",
      "        [-0.0441, -1.1694, -0.5914,  ..., -0.8315,  0.2083, -0.3308],\n",
      "        [ 0.0134, -1.0420, -0.8658,  ..., -0.6518,  0.3089, -0.2904],\n",
      "        [ 0.1682, -0.9378, -0.7749,  ..., -0.6078,  0.1139, -0.3982]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0909, -0.7514, -0.7282,  ..., -0.6931,  0.1408, -0.3802],\n",
      "        [ 0.0666, -1.1191, -1.0275,  ..., -0.7845,  0.1764, -0.6930],\n",
      "        [ 0.0013, -1.1929, -0.7658,  ..., -0.6575,  0.1195, -0.9238],\n",
      "        ...,\n",
      "        [ 0.0343, -1.0341, -0.5958,  ..., -0.8106,  0.1567, -0.7386],\n",
      "        [-0.0717, -1.1490, -0.7532,  ..., -0.8159,  0.3186, -0.4678],\n",
      "        [-0.4304, -1.2464, -0.8816,  ..., -0.7916,  0.3179, -0.7831]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2571, -1.1270, -0.6913,  ..., -0.6389,  0.0152, -0.4495],\n",
      "        [ 0.1489, -0.9079, -0.6037,  ..., -0.5655,  0.1262, -0.2949],\n",
      "        [-0.1033, -1.2353, -0.8988,  ..., -0.7868,  0.2454, -0.6273],\n",
      "        ...,\n",
      "        [ 0.0633, -1.0792, -0.7260,  ..., -0.6718,  0.2386, -0.6502],\n",
      "        [ 0.1407, -1.0374, -0.5977,  ..., -0.8030,  0.0296, -0.2904],\n",
      "        [ 0.0116, -0.7296, -0.7635,  ..., -0.7107,  0.3773, -0.3491]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2515, -1.2190, -0.6818,  ..., -0.8375,  0.4014, -0.7090],\n",
      "        [-0.1652, -1.2318, -0.8884,  ..., -0.8287,  0.2901, -0.5493],\n",
      "        [ 0.1143, -1.0830, -0.5248,  ..., -0.9414,  0.0940, -0.6684],\n",
      "        ...,\n",
      "        [-0.2532, -0.9044, -0.7118,  ..., -0.9257,  0.2266, -0.6104],\n",
      "        [-0.0436, -1.1156, -0.3168,  ..., -0.9502,  0.0375, -0.7441],\n",
      "        [ 0.0409, -0.9667, -0.8253,  ..., -0.6967, -0.1295, -0.8062]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0858, -0.8049, -0.3543,  ..., -0.6524, -0.0264, -0.4406],\n",
      "        [ 0.4222, -1.2460, -0.9785,  ..., -0.4883,  0.1081, -0.6599],\n",
      "        [-0.0785, -1.0273, -0.7981,  ..., -0.6006,  0.1170, -0.7063],\n",
      "        ...,\n",
      "        [ 0.0353, -0.7055, -0.4709,  ..., -0.9356,  0.0995, -0.3031],\n",
      "        [-0.2737, -1.1586, -0.4709,  ..., -0.7612, -0.0031, -0.4112],\n",
      "        [ 0.3152, -1.0621, -0.5392,  ..., -0.6968, -0.0285, -0.3753]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2151, -0.8816, -0.6608,  ..., -0.6499,  0.1609, -0.4786],\n",
      "        [ 0.1891, -1.0241, -0.5739,  ..., -0.7745,  0.0720, -0.4415],\n",
      "        [ 0.2745, -0.8862, -0.6997,  ..., -0.5648,  0.0427, -0.5512],\n",
      "        ...,\n",
      "        [ 0.3986, -1.1802, -0.6365,  ..., -0.7321, -0.1067, -0.5584],\n",
      "        [ 0.1480, -1.0573, -0.6707,  ..., -0.6677,  0.2628, -0.3739],\n",
      "        [-0.0487, -1.1740, -0.6545,  ..., -0.8529,  0.2884, -0.4156]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2245, -1.0482, -0.4937,  ..., -0.7612,  0.0108, -0.4856],\n",
      "        [ 0.1369, -0.9864, -0.7726,  ..., -0.5985, -0.1536, -0.6071],\n",
      "        [-0.0920, -1.0422, -0.5754,  ..., -0.6824,  0.1255, -0.6426],\n",
      "        ...,\n",
      "        [ 0.0834, -1.0506, -0.5800,  ..., -1.0022,  0.0881, -0.3885],\n",
      "        [ 0.2022, -0.9312, -0.8317,  ..., -0.6932,  0.1048, -0.2123],\n",
      "        [ 0.0614, -0.9556, -0.3067,  ..., -0.8086,  0.1996, -0.5388]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0435, -1.1284, -0.7461,  ..., -0.6604,  0.1382, -0.7621],\n",
      "        [-0.0225, -0.9143, -0.8505,  ..., -0.4691,  0.1423, -0.5459],\n",
      "        [ 0.0257, -0.9544, -0.5545,  ..., -0.6103,  0.0675, -0.2992],\n",
      "        ...,\n",
      "        [ 0.0218, -1.2921, -0.5439,  ..., -0.6865, -0.1198, -0.5934],\n",
      "        [ 0.1294, -1.1053, -0.9673,  ..., -0.6489,  0.3471, -0.7393],\n",
      "        [ 0.0303, -0.9921, -0.5049,  ..., -0.5920,  0.0213, -0.5663]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0162, -1.0189, -0.5765,  ..., -0.8610,  0.1026, -0.4120],\n",
      "        [-0.0955, -0.7532, -0.6959,  ..., -0.7152,  0.2088, -0.4653],\n",
      "        [-0.2176, -1.0885, -0.5566,  ..., -0.7373,  0.1657, -0.8843],\n",
      "        ...,\n",
      "        [ 0.0864, -1.1285, -0.6507,  ..., -0.6662,  0.2598, -0.3963],\n",
      "        [ 0.1782, -1.0613, -0.6189,  ..., -0.8548,  0.4007, -0.5808],\n",
      "        [-0.5633, -1.1296, -0.8451,  ..., -0.7833,  0.3669, -0.7219]],\n",
      "       device='mps:0')\n",
      "Epoch: 4 | Batch: 10 | Loss: 1.1666 | Acc: 37.50%\n",
      "cls_features:  tensor([[ 0.3545, -0.9796, -0.4531,  ..., -0.8923, -0.0467, -0.3215],\n",
      "        [ 0.0434, -0.8980, -0.4547,  ..., -0.8720, -0.1816, -0.3499],\n",
      "        [ 0.1061, -0.9743, -0.4456,  ..., -0.7401,  0.1456, -0.5150],\n",
      "        ...,\n",
      "        [-0.0581, -1.1218, -0.7352,  ..., -0.7400,  0.1955, -0.5639],\n",
      "        [ 0.0595, -1.0243, -0.4774,  ..., -0.6757, -0.1145, -0.5658],\n",
      "        [-0.0243, -0.9814, -0.6532,  ..., -0.6801,  0.1681, -0.4675]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0730, -1.1538, -0.6751,  ..., -0.7602,  0.3941, -0.5620],\n",
      "        [-0.1546, -1.1955, -0.7123,  ..., -0.7756,  0.2036, -0.5448],\n",
      "        [-0.2152, -1.1130, -0.6514,  ..., -0.9083,  0.5379, -0.6403],\n",
      "        ...,\n",
      "        [ 0.0030, -0.7512, -0.4992,  ..., -0.6102,  0.2682, -0.6112],\n",
      "        [-0.0547, -1.0147, -0.7242,  ..., -0.7005,  0.2461, -0.6163],\n",
      "        [ 0.0135, -1.0626, -0.8321,  ..., -0.8570,  0.1975, -0.7878]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2940, -1.0025, -0.8353,  ..., -0.8431,  0.2961, -0.5374],\n",
      "        [-0.1134, -1.1262, -0.6503,  ..., -0.8175,  0.2344, -0.5647],\n",
      "        [-0.2623, -0.8866, -0.4514,  ..., -0.8209,  0.4292, -0.3724],\n",
      "        ...,\n",
      "        [ 0.4321, -1.1255, -0.8990,  ..., -0.6988,  0.2286, -0.4530],\n",
      "        [-0.4528, -1.1092, -0.5052,  ..., -0.7843,  0.4402, -0.8515],\n",
      "        [-0.0262, -0.9968, -0.5725,  ..., -0.7486,  0.1981, -0.6944]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2981, -0.8462, -0.4074,  ..., -0.7596, -0.0753, -0.2300],\n",
      "        [ 0.2697, -1.3369, -0.8199,  ..., -0.6532,  0.1471, -0.7830],\n",
      "        [ 0.2643, -1.1003, -0.4714,  ..., -0.6469,  0.0200, -0.6581],\n",
      "        ...,\n",
      "        [-0.0425, -1.0190, -0.6559,  ..., -0.8367,  0.2039, -0.6079],\n",
      "        [ 0.0537, -1.1582, -0.7377,  ..., -0.6916,  0.1360, -0.6317],\n",
      "        [ 0.1815, -1.2353, -0.8067,  ..., -0.6124,  0.3555, -0.6631]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2578, -1.2300, -0.6095,  ..., -0.8212, -0.0275, -0.3233],\n",
      "        [-0.0945, -0.8808, -0.5128,  ..., -0.8879,  0.1905, -0.4249],\n",
      "        [ 0.1087, -1.1503, -0.7580,  ..., -0.6473,  0.1501, -0.4841],\n",
      "        ...,\n",
      "        [ 0.1632, -1.1014, -0.5859,  ..., -0.5534, -0.2142, -0.8543],\n",
      "        [-0.2684, -0.9335, -0.7367,  ..., -0.8025,  0.1223, -0.5821],\n",
      "        [-0.2677, -0.8176, -0.4768,  ..., -0.8793,  0.1301, -0.4277]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1872, -0.9721, -0.4557,  ..., -0.8278,  0.0971, -0.6413],\n",
      "        [ 0.0050, -1.1061, -0.5483,  ..., -0.7598,  0.2138, -0.7047],\n",
      "        [ 0.2669, -1.3219, -0.7736,  ..., -0.7636,  0.1210, -0.5876],\n",
      "        ...,\n",
      "        [-0.1574, -0.9494, -0.5400,  ..., -0.8185,  0.0466, -0.4453],\n",
      "        [-0.0494, -0.9722, -0.4552,  ..., -1.0289,  0.1643, -0.2836],\n",
      "        [-0.0570, -1.1211, -0.5714,  ..., -0.6708,  0.1696, -0.7582]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0108, -1.0432, -0.7245,  ..., -0.6688,  0.1010, -0.5104],\n",
      "        [-0.2718, -0.9078, -0.5481,  ..., -0.7235,  0.1845, -0.4754],\n",
      "        [-0.2724, -1.4619, -0.7984,  ..., -0.7326,  0.1541, -0.6971],\n",
      "        ...,\n",
      "        [ 0.1165, -0.8943, -0.7982,  ..., -0.8253, -0.0485, -0.5676],\n",
      "        [-0.1831, -1.0210, -0.6501,  ..., -0.7955,  0.2069, -0.4793],\n",
      "        [-0.1837, -0.8442, -0.6413,  ..., -0.6632,  0.1911, -0.6062]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2334, -1.0826, -0.5116,  ..., -0.9797,  0.0190, -0.5676],\n",
      "        [-0.2201, -0.9210, -0.6377,  ..., -0.6887,  0.1714, -0.6443],\n",
      "        [-0.1421, -0.8942, -0.5041,  ..., -0.8002,  0.1906, -0.3958],\n",
      "        ...,\n",
      "        [ 0.0166, -1.1741, -0.4925,  ..., -0.6732,  0.0612, -0.7586],\n",
      "        [-0.0574, -0.8573, -0.6182,  ..., -0.6872,  0.0735, -0.4575],\n",
      "        [ 0.0359, -0.8837, -0.5838,  ..., -0.9442,  0.0351, -0.3746]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2574, -1.0153, -0.7538,  ..., -0.8565,  0.2692, -0.3483],\n",
      "        [-0.1101, -1.2095, -0.8014,  ..., -0.7178,  0.2269, -0.6457],\n",
      "        [-0.3196, -0.9304, -0.8010,  ..., -0.9867,  0.3705, -0.6948],\n",
      "        ...,\n",
      "        [ 0.2105, -1.0680, -0.5122,  ..., -0.7105,  0.2123, -0.7195],\n",
      "        [ 0.3750, -1.3798, -0.7073,  ..., -0.5810,  0.0248, -0.5237],\n",
      "        [-0.0377, -1.1591, -0.6329,  ..., -0.7235,  0.3068, -0.6831]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0017, -1.1299, -0.6964,  ..., -0.7155, -0.0689, -0.7702],\n",
      "        [ 0.0732, -0.9622, -0.6908,  ..., -0.5807,  0.0765, -0.5525],\n",
      "        [-0.1016, -0.8341, -0.5529,  ..., -0.6923,  0.0129, -0.4868],\n",
      "        ...,\n",
      "        [-0.4712, -0.8306, -0.7493,  ..., -0.7155,  0.1347, -0.5849],\n",
      "        [-0.3902, -1.1295, -0.7982,  ..., -0.8101,  0.1201, -0.6506],\n",
      "        [-0.5522, -0.9315, -0.6516,  ..., -0.7466,  0.2290, -0.5694]],\n",
      "       device='mps:0')\n",
      "Epoch: 4 | Batch: 20 | Loss: 1.0820 | Acc: 39.58%\n",
      "cls_features:  tensor([[ 0.2304, -1.1025, -0.9038,  ..., -0.7564, -0.0994, -0.5187],\n",
      "        [-0.0469, -0.9218, -0.5923,  ..., -0.8962,  0.1795, -0.3009],\n",
      "        [-0.3043, -1.0263, -0.9409,  ..., -0.6809,  0.2029, -0.5977],\n",
      "        ...,\n",
      "        [ 0.1048, -1.2336, -0.6672,  ..., -0.6853, -0.1063, -0.6991],\n",
      "        [-0.3436, -0.6918, -0.6430,  ..., -0.7039,  0.0952, -0.3633],\n",
      "        [-0.0925, -1.0297, -0.7339,  ..., -0.4797, -0.1111, -0.5706]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 5.8487e-02, -1.0058e+00, -5.4072e-01,  ..., -5.9351e-01,\n",
      "          2.3018e-02, -5.8999e-01],\n",
      "        [ 1.0784e-03, -1.1220e+00, -8.6178e-01,  ..., -7.5538e-01,\n",
      "          1.1696e-01, -5.3795e-01],\n",
      "        [-1.1105e-01, -1.2041e+00, -8.2999e-01,  ..., -8.4701e-01,\n",
      "          4.5524e-01, -2.6789e-01],\n",
      "        ...,\n",
      "        [-2.1511e-01, -1.1213e+00, -2.2234e-01,  ..., -7.4897e-01,\n",
      "         -1.3593e-01, -7.4848e-01],\n",
      "        [ 2.7347e-01, -1.4846e+00, -7.3309e-01,  ..., -6.5105e-01,\n",
      "          7.3469e-02, -5.7444e-01],\n",
      "        [-1.3105e-01, -1.0185e+00, -4.5858e-01,  ..., -7.0310e-01,\n",
      "         -1.8385e-03, -7.2756e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.5021, -0.8172, -0.5698,  ..., -0.8356,  0.2205, -0.4539],\n",
      "        [ 0.0355, -0.9570, -0.3666,  ..., -0.7469,  0.1020, -0.6279],\n",
      "        [ 0.1640, -1.2480, -0.7360,  ..., -0.6566,  0.1568, -0.6060],\n",
      "        ...,\n",
      "        [ 0.0871, -0.9218, -0.3385,  ..., -0.9691,  0.1938, -0.2011],\n",
      "        [-0.0344, -1.0565, -0.5682,  ..., -0.8781,  0.1710, -0.4143],\n",
      "        [ 0.3348, -0.9878, -0.6158,  ..., -0.6151,  0.1032, -0.4525]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0342, -1.0906, -0.4619,  ..., -0.7902,  0.0173, -0.5510],\n",
      "        [-0.1260, -1.1185, -0.9484,  ..., -0.6957,  0.1721, -0.7400],\n",
      "        [ 0.1225, -1.1233, -0.5845,  ..., -0.6761,  0.2698, -0.6909],\n",
      "        ...,\n",
      "        [-0.1096, -0.9836, -0.7815,  ..., -0.7912,  0.3128, -0.4454],\n",
      "        [ 0.3576, -0.9299, -0.2773,  ..., -0.8585, -0.0169, -0.1767],\n",
      "        [-0.0312, -1.3997, -0.6605,  ..., -0.7189,  0.2031, -0.7274]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0893, -0.9713, -0.4458,  ..., -0.7475,  0.0434, -0.5162],\n",
      "        [-0.4858, -0.8862, -0.5170,  ..., -0.8175,  0.2693, -0.5294],\n",
      "        [-0.1006, -0.9009, -0.7192,  ..., -0.5822,  0.1332, -0.6935],\n",
      "        ...,\n",
      "        [-0.0946, -1.0906, -0.5828,  ..., -0.7924,  0.2495, -0.5294],\n",
      "        [ 0.3354, -1.1893, -0.5418,  ..., -0.6194, -0.1332, -0.5044],\n",
      "        [ 0.5058, -1.3654, -0.5088,  ..., -0.7513, -0.1181, -0.7048]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.6625, -0.8344, -0.4892,  ..., -1.0103,  0.2839, -0.6803],\n",
      "        [ 0.1082, -0.8696, -0.6401,  ..., -0.8000,  0.2696, -0.5473],\n",
      "        [-0.2690, -1.3451, -0.5744,  ..., -0.9214,  0.1869, -0.6501],\n",
      "        ...,\n",
      "        [ 0.2809, -1.0551, -0.4588,  ..., -0.8447,  0.0300, -0.5004],\n",
      "        [ 0.0623, -0.9244, -0.5976,  ..., -0.8728,  0.3171, -0.4942],\n",
      "        [-0.1030, -1.1375, -0.5554,  ..., -0.7654,  0.0533, -0.7348]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3949, -1.3398, -0.5632,  ..., -0.5893,  0.0493, -0.5255],\n",
      "        [-0.0478, -0.8204, -0.4113,  ..., -0.5690, -0.0332, -0.5034],\n",
      "        [-0.1484, -1.1015, -0.7620,  ..., -0.8388,  0.2732, -0.5504],\n",
      "        ...,\n",
      "        [-0.1549, -0.9147, -0.7176,  ..., -0.8170,  0.1535, -0.5803],\n",
      "        [-0.1175, -1.0251, -0.4052,  ..., -0.7493,  0.0462, -0.7991],\n",
      "        [-0.0281, -0.8644, -0.7750,  ..., -0.5486,  0.1147, -0.3620]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2845, -0.9603, -0.4192,  ..., -0.8385,  0.1778, -0.5655],\n",
      "        [-0.0649, -1.1004, -0.7694,  ..., -0.7785,  0.1888, -0.5928],\n",
      "        [ 0.1107, -0.9384, -0.4480,  ..., -0.7079,  0.1194, -0.5513],\n",
      "        ...,\n",
      "        [ 0.0231, -1.2441, -0.6188,  ..., -0.7705,  0.1762, -0.4985],\n",
      "        [-0.3053, -0.9908, -0.5307,  ..., -0.7773,  0.2484, -0.4070],\n",
      "        [-0.3229, -1.1473, -0.8008,  ..., -0.7847, -0.0700, -0.8917]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1280, -0.8921, -0.4901,  ..., -0.7300,  0.1515, -0.5563],\n",
      "        [ 0.0913, -1.0965, -0.7840,  ..., -0.8734,  0.1389, -0.2765],\n",
      "        [-0.0494, -1.0090, -0.5287,  ..., -0.8639,  0.3368, -0.3466],\n",
      "        ...,\n",
      "        [ 0.4292, -1.0752, -0.5033,  ..., -0.4314, -0.1128, -0.6723],\n",
      "        [-0.1463, -0.8615, -0.5334,  ..., -0.8115,  0.2035, -0.5338],\n",
      "        [-0.0022, -1.2248, -0.4905,  ..., -0.5200,  0.0661, -0.6753]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 9.9358e-02, -1.1471e+00, -6.1642e-01,  ..., -8.4746e-01,\n",
      "          1.1463e-01, -7.5793e-01],\n",
      "        [-3.3913e-01, -1.1445e+00, -6.9183e-01,  ..., -7.8517e-01,\n",
      "          5.9666e-02, -7.1506e-01],\n",
      "        [ 1.2876e-01, -1.0167e+00, -5.4323e-01,  ..., -6.2288e-01,\n",
      "          1.3473e-01, -3.4155e-01],\n",
      "        ...,\n",
      "        [ 2.0112e-02, -1.4655e+00, -7.3507e-01,  ..., -8.1318e-01,\n",
      "          1.7259e-01, -6.3932e-01],\n",
      "        [ 2.0480e-01, -8.9805e-01, -4.8778e-01,  ..., -7.6339e-01,\n",
      "          1.1116e-04, -7.0761e-01],\n",
      "        [ 4.2116e-02, -9.6491e-01, -6.9310e-01,  ..., -4.0822e-01,\n",
      "          1.9469e-01, -7.7446e-01]], device='mps:0')\n",
      "Epoch: 4 | Batch: 30 | Loss: 1.1914 | Acc: 41.94%\n",
      "cls_features:  tensor([[ 0.2353, -1.1312, -0.5095,  ..., -0.6909, -0.1372, -0.5111],\n",
      "        [ 0.3128, -1.1105, -0.5052,  ..., -0.6456,  0.1527, -0.4839],\n",
      "        [ 0.1933, -1.1268, -0.4161,  ..., -0.6803, -0.1472, -0.4296],\n",
      "        ...,\n",
      "        [-0.0905, -1.1287, -0.8408,  ..., -0.8459,  0.1037, -0.5091],\n",
      "        [ 0.1081, -1.1013, -0.8515,  ..., -0.7034,  0.1791, -0.5924],\n",
      "        [-0.0283, -0.8113, -0.3976,  ..., -0.7241,  0.0175, -0.4336]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2326, -0.7995, -0.4747,  ..., -0.7702,  0.2914, -0.5313],\n",
      "        [-0.1548, -0.9201, -0.4164,  ..., -0.8474, -0.0056, -0.6215],\n",
      "        [-0.4529, -0.9619, -0.4345,  ..., -0.9215,  0.1345, -0.2341],\n",
      "        ...,\n",
      "        [ 0.2499, -1.0059, -0.6497,  ..., -0.6938,  0.0411, -0.5288],\n",
      "        [ 0.2139, -1.0051, -0.4437,  ..., -0.8507,  0.0374, -0.5441],\n",
      "        [-0.0990, -0.8343, -0.9123,  ..., -0.6627,  0.1341, -0.4539]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0260, -0.9601, -0.5039,  ..., -0.6907,  0.1558, -0.3146],\n",
      "        [-0.2722, -0.8610, -0.6714,  ..., -0.7539,  0.3252, -0.3763],\n",
      "        [-0.1797, -0.7256, -0.5685,  ..., -0.9268,  0.3538, -0.4123],\n",
      "        ...,\n",
      "        [ 0.2656, -1.0400, -0.5054,  ..., -0.6770,  0.0988, -0.5886],\n",
      "        [-0.1959, -1.1304, -0.8303,  ..., -0.8573,  0.0260, -0.8918],\n",
      "        [-0.4092, -1.1161, -0.6726,  ..., -0.7572,  0.2085, -0.5254]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1923, -0.9140, -0.5956,  ..., -0.8789,  0.1905, -0.4366],\n",
      "        [-0.1569, -0.8599, -0.3480,  ..., -0.7587,  0.0193, -0.3213],\n",
      "        [-0.2706, -1.0756, -0.4968,  ..., -0.7183,  0.1885, -0.6208],\n",
      "        ...,\n",
      "        [-0.0505, -1.1380, -0.8275,  ..., -0.7461,  0.2553, -0.6573],\n",
      "        [ 0.2774, -0.9045, -0.4449,  ..., -0.7457,  0.0809, -0.4799],\n",
      "        [ 0.2034, -1.1968, -0.6721,  ..., -0.7720,  0.0487, -0.7429]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0943, -0.8153, -0.4427,  ..., -0.7607, -0.0773, -0.8436],\n",
      "        [-0.2439, -1.1641, -0.5098,  ..., -0.7128,  0.2331, -0.6152],\n",
      "        [ 0.1363, -1.1519, -0.8195,  ..., -0.6688,  0.0034, -0.5131],\n",
      "        ...,\n",
      "        [ 0.0955, -0.9829, -0.5350,  ..., -0.7844, -0.0107, -0.6952],\n",
      "        [ 0.0056, -1.1547, -0.7725,  ..., -0.6207,  0.3727, -0.5957],\n",
      "        [-0.1009, -1.0794, -0.8495,  ..., -0.8213,  0.2858, -0.4611]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3715, -0.8997, -0.6617,  ..., -0.8239,  0.1999, -0.2282],\n",
      "        [-0.1082, -0.7064, -0.5509,  ..., -0.7917,  0.2774, -0.2686],\n",
      "        [ 0.3018, -0.9063, -0.3530,  ..., -0.6781, -0.0024, -0.3863],\n",
      "        ...,\n",
      "        [ 0.2196, -1.1738, -0.5946,  ..., -0.6780,  0.0440, -0.7237],\n",
      "        [-0.1822, -1.1268, -0.8628,  ..., -0.7404,  0.3281, -0.8656],\n",
      "        [-0.1361, -1.0150, -0.4521,  ..., -0.6563,  0.1275, -0.8110]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0668, -1.1597, -0.4415,  ..., -0.8292,  0.1595, -0.4503],\n",
      "        [-0.1561, -0.9481, -0.6985,  ..., -0.8588,  0.2524, -0.4483],\n",
      "        [ 0.3879, -1.1935, -0.6147,  ..., -0.8383,  0.1475, -0.5456],\n",
      "        ...,\n",
      "        [-0.0635, -0.8726, -0.3165,  ..., -0.8076,  0.2255, -0.4317],\n",
      "        [-0.2119, -1.0333, -0.7679,  ..., -0.9379,  0.1268, -0.7548],\n",
      "        [-0.3475, -1.1107, -0.6155,  ..., -0.7513,  0.1120, -0.7664]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.6176e-01, -1.1564e+00, -5.3197e-01,  ..., -9.0170e-01,\n",
      "         -8.0572e-04, -8.5764e-01],\n",
      "        [ 1.5561e-01, -1.1294e+00, -4.5716e-01,  ..., -8.4043e-01,\n",
      "         -2.8045e-02, -6.1134e-01],\n",
      "        [ 2.1286e-01, -1.0161e+00, -6.4587e-01,  ..., -6.7691e-01,\n",
      "          6.0131e-02, -7.3311e-01],\n",
      "        ...,\n",
      "        [-4.2489e-01, -1.0063e+00, -5.8820e-01,  ..., -8.2909e-01,\n",
      "          2.2735e-01, -6.0393e-01],\n",
      "        [-5.6876e-03, -1.0643e+00, -8.1814e-01,  ..., -6.7322e-01,\n",
      "          6.3695e-02, -6.7690e-01],\n",
      "        [-2.2384e-01, -1.1137e+00, -8.5815e-01,  ..., -6.9156e-01,\n",
      "          1.9319e-01, -5.9756e-01]], device='mps:0')\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 1.1118 | Train Acc: 41.90%\n",
      "Val Loss: 0.9675 | Val Acc: 50.50%\n",
      "cls_features:  tensor([[ 0.0597, -0.9894, -0.8970,  ..., -0.7356,  0.3257, -0.5040],\n",
      "        [-0.0996, -1.0041, -0.8439,  ..., -0.4940,  0.1781, -0.4583],\n",
      "        [-0.4257, -0.9560, -0.3677,  ..., -0.7990,  0.1815, -0.4722],\n",
      "        ...,\n",
      "        [-0.1101, -0.9147, -0.7157,  ..., -0.9275,  0.1907, -0.5164],\n",
      "        [-0.1265, -1.0497, -0.6695,  ..., -0.7420,  0.1102, -0.7751],\n",
      "        [ 0.1486, -1.3244, -0.7078,  ..., -0.7579,  0.2571, -0.5240]],\n",
      "       device='mps:0')\n",
      "Epoch: 5 | Batch: 0 | Loss: 1.2194 | Acc: 28.12%\n",
      "cls_features:  tensor([[ 0.0744, -1.2908, -0.6302,  ..., -0.7105,  0.0476, -0.4210],\n",
      "        [-0.0632, -1.0188, -0.6711,  ..., -0.6167,  0.0521, -0.4888],\n",
      "        [-0.0306, -1.0937, -0.9570,  ..., -0.5805,  0.1420, -0.7495],\n",
      "        ...,\n",
      "        [ 0.0522, -1.1087, -0.8406,  ..., -0.7129,  0.1372, -0.7125],\n",
      "        [-0.0938, -1.0055, -0.7266,  ..., -0.8116,  0.2887, -0.6213],\n",
      "        [ 0.0234, -1.1459, -0.7965,  ..., -0.7167, -0.0578, -0.3834]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0535, -0.9732, -0.4391,  ..., -0.6521,  0.0720, -0.7121],\n",
      "        [-0.0637, -1.2050, -0.5781,  ..., -0.8834,  0.1417, -0.4280],\n",
      "        [ 0.1084, -1.0954, -0.8413,  ..., -0.7238,  0.3618, -0.7057],\n",
      "        ...,\n",
      "        [-0.3078, -1.0249, -0.5185,  ..., -0.9833,  0.3242, -0.4961],\n",
      "        [ 0.1294, -1.1053, -0.9673,  ..., -0.6489,  0.3471, -0.7393],\n",
      "        [-0.2635, -0.9157, -0.8611,  ..., -0.6951,  0.1707, -0.5222]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2669, -1.3219, -0.7736,  ..., -0.7636,  0.1210, -0.5876],\n",
      "        [ 0.1352, -1.1038, -0.6816,  ..., -0.7563,  0.2481, -0.7735],\n",
      "        [ 0.2161, -1.2914, -0.7089,  ..., -0.8051, -0.0714, -0.5558],\n",
      "        ...,\n",
      "        [ 0.0834, -1.0506, -0.5800,  ..., -1.0022,  0.0881, -0.3885],\n",
      "        [ 0.0909, -0.7513, -0.7282,  ..., -0.6931,  0.1408, -0.3802],\n",
      "        [ 0.1382, -0.8397, -0.8117,  ..., -0.6021,  0.1016, -0.5778]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1280, -0.8921, -0.4901,  ..., -0.7300,  0.1515, -0.5563],\n",
      "        [-0.2092, -0.9522, -0.2067,  ..., -0.8502,  0.2125, -0.5256],\n",
      "        [-0.0207, -1.2229, -0.6860,  ..., -0.9504,  0.3815, -0.5814],\n",
      "        ...,\n",
      "        [ 0.0173, -0.8977, -0.6510,  ..., -0.7374, -0.1719, -0.3740],\n",
      "        [ 0.1144, -0.9019, -0.5059,  ..., -0.6586,  0.1676, -0.5796],\n",
      "        [ 0.1301, -0.9615, -0.6979,  ..., -0.7926,  0.3321, -0.4231]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3128, -1.1105, -0.5052,  ..., -0.6456,  0.1527, -0.4839],\n",
      "        [ 0.0121, -1.2516, -0.7877,  ..., -0.7195,  0.1285, -0.7720],\n",
      "        [-0.0638, -1.1740, -0.5765,  ..., -0.7421, -0.0819, -0.6064],\n",
      "        ...,\n",
      "        [ 0.2108, -1.2260, -0.5357,  ..., -0.6665,  0.1362, -0.6127],\n",
      "        [-0.3226, -1.0059, -0.8547,  ..., -0.5360,  0.2007, -0.7697],\n",
      "        [ 0.1712, -0.9397, -0.4209,  ..., -0.7872, -0.0704, -0.4279]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1484, -1.0712, -0.9070,  ..., -0.6933,  0.1752, -0.5241],\n",
      "        [ 0.0609, -1.2076, -0.6886,  ..., -0.7777,  0.0144, -0.7962],\n",
      "        [-0.1461, -1.1169, -0.7433,  ..., -0.8719,  0.4437, -0.5061],\n",
      "        ...,\n",
      "        [-0.0147, -0.9781, -0.7168,  ..., -0.5473,  0.1363, -0.5387],\n",
      "        [-0.1024, -1.1229, -0.6903,  ..., -0.6594, -0.0127, -0.4747],\n",
      "        [-0.5409, -1.0111, -0.6785,  ..., -0.6901,  0.2505, -0.7047]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0487, -1.1740, -0.6545,  ..., -0.8529,  0.2884, -0.4156],\n",
      "        [-0.0022, -1.2248, -0.4905,  ..., -0.5200,  0.0661, -0.6753],\n",
      "        [ 0.1606, -1.0539, -0.7179,  ..., -0.7070, -0.0301, -0.5557],\n",
      "        ...,\n",
      "        [-0.2082, -1.0005, -0.6270,  ..., -0.9435,  0.4475, -0.3964],\n",
      "        [-0.0478, -0.8204, -0.4113,  ..., -0.5690, -0.0332, -0.5034],\n",
      "        [-0.0740, -1.0814, -0.6729,  ..., -0.5580, -0.0341, -0.6916]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.5058, -1.3654, -0.5088,  ..., -0.7513, -0.1181, -0.7048],\n",
      "        [-0.1998, -1.0736, -0.7413,  ..., -0.7374,  0.2541, -0.6597],\n",
      "        [ 0.2418, -1.2550, -0.5850,  ..., -0.7012, -0.0725, -0.5578],\n",
      "        ...,\n",
      "        [-0.0111, -1.1067, -0.8319,  ..., -0.7161,  0.0179, -0.6074],\n",
      "        [-0.3716, -0.7925, -0.4354,  ..., -0.7021,  0.2989, -0.3321],\n",
      "        [-0.0937, -1.0667, -0.5030,  ..., -0.5388,  0.0329, -0.7385]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1797, -0.8791, -0.4346,  ..., -0.7662,  0.1738, -0.6140],\n",
      "        [ 0.0944, -0.7924, -0.4231,  ..., -0.8213,  0.2358, -0.3429],\n",
      "        [ 0.2648, -1.0559, -0.5409,  ..., -0.8616, -0.1320, -0.4381],\n",
      "        ...,\n",
      "        [-0.0610, -0.9546, -0.4953,  ..., -0.7160,  0.0985, -0.5275],\n",
      "        [ 0.0013, -1.1929, -0.7658,  ..., -0.6575,  0.1195, -0.9238],\n",
      "        [ 0.1406, -1.0851, -0.4697,  ..., -0.8970,  0.1200, -0.4892]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0547, -1.0286, -0.6613,  ..., -0.6375,  0.0626, -0.5980],\n",
      "        [-0.1074, -1.1734, -0.4682,  ..., -0.8176,  0.1991, -0.3916],\n",
      "        [ 0.1800, -1.1635, -0.4987,  ..., -0.8659,  0.1684, -0.7198],\n",
      "        ...,\n",
      "        [-0.2141, -1.0072, -0.3677,  ..., -0.8372,  0.1756, -0.5441],\n",
      "        [-0.2086, -1.0551, -0.5390,  ..., -0.7519,  0.0609, -0.6585],\n",
      "        [-0.2152, -1.1130, -0.6514,  ..., -0.9083,  0.5379, -0.6403]],\n",
      "       device='mps:0')\n",
      "Epoch: 5 | Batch: 10 | Loss: 1.0887 | Acc: 39.49%\n",
      "cls_features:  tensor([[-0.1484, -1.1015, -0.7620,  ..., -0.8388,  0.2732, -0.5504],\n",
      "        [-0.0805, -0.9867, -0.5088,  ..., -0.8755,  0.2323, -0.4958],\n",
      "        [ 0.0732, -0.9622, -0.6908,  ..., -0.5807,  0.0765, -0.5525],\n",
      "        ...,\n",
      "        [ 0.2247, -1.3217, -0.5360,  ..., -0.6799,  0.1242, -0.5167],\n",
      "        [ 0.1025, -1.4507, -0.6536,  ..., -0.7562,  0.0947, -0.8223],\n",
      "        [-0.2489, -1.1244, -0.4549,  ..., -0.8685,  0.0891, -0.5616]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0666, -1.1191, -1.0275,  ..., -0.7845,  0.1764, -0.6930],\n",
      "        [ 0.0613, -1.0551, -0.6899,  ..., -0.7614,  0.0729, -0.6864],\n",
      "        [ 0.1894, -1.4914, -1.0405,  ..., -0.6378,  0.2506, -0.5965],\n",
      "        ...,\n",
      "        [-0.0925, -1.0297, -0.7339,  ..., -0.4797, -0.1111, -0.5706],\n",
      "        [-0.2733, -1.0999, -0.5894,  ..., -0.6881,  0.1359, -0.7684],\n",
      "        [-0.0603, -1.1762, -0.6461,  ..., -0.7314,  0.1791, -0.6758]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3360, -1.0581, -0.5408,  ..., -0.6833,  0.0662, -0.4306],\n",
      "        [-0.0266, -1.0630, -0.6772,  ..., -0.7025,  0.3135, -0.3054],\n",
      "        [ 0.0288, -1.0641, -0.2980,  ..., -0.9363,  0.0526, -0.3186],\n",
      "        ...,\n",
      "        [-0.0266, -1.0675, -0.4399,  ..., -0.7158, -0.0335, -0.4917],\n",
      "        [-0.3343, -0.9704, -0.3762,  ..., -0.8643,  0.3236, -0.2879],\n",
      "        [ 0.2245, -0.8736, -0.4611,  ..., -0.8476,  0.0798, -0.2241]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3178, -0.9949, -0.6509,  ..., -0.4955,  0.0511, -0.4967],\n",
      "        [-0.1921, -1.1420, -0.7894,  ..., -0.8351, -0.0091, -0.6340],\n",
      "        [ 0.0231, -1.2441, -0.6188,  ..., -0.7705,  0.1762, -0.4985],\n",
      "        ...,\n",
      "        [ 0.4621, -1.1578, -0.4823,  ..., -0.7605, -0.2074, -0.4509],\n",
      "        [-0.0386, -1.2370, -0.8592,  ..., -0.7422,  0.4452, -0.7555],\n",
      "        [-0.1749, -1.0483, -0.4953,  ..., -0.6870,  0.1573, -0.6717]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0434, -0.8980, -0.4547,  ..., -0.8720, -0.1816, -0.3499],\n",
      "        [-0.3756, -1.0103, -0.7801,  ..., -0.5980,  0.2757, -0.6688],\n",
      "        [-0.2713, -0.9653, -0.6578,  ..., -0.6797,  0.2531, -0.3205],\n",
      "        ...,\n",
      "        [-0.1463, -0.8615, -0.5334,  ..., -0.8115,  0.2035, -0.5338],\n",
      "        [ 0.3576, -0.9299, -0.2773,  ..., -0.8585, -0.0169, -0.1767],\n",
      "        [-0.1545, -1.3325, -0.7679,  ..., -0.8634,  0.3877, -0.5411]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1450, -0.9368, -0.5751,  ..., -0.7366,  0.1095, -0.4932],\n",
      "        [ 0.0657, -1.1400, -0.7406,  ..., -0.6096,  0.1062, -0.8183],\n",
      "        [-0.0316, -0.6645, -0.5488,  ..., -0.8235,  0.0802, -0.3204],\n",
      "        ...,\n",
      "        [-0.1153, -0.9460, -0.5355,  ..., -0.8240,  0.0588, -0.5707],\n",
      "        [ 0.0978, -1.1951, -0.3823,  ..., -0.7291, -0.1429, -0.6110],\n",
      "        [-0.0549, -1.0127, -0.7682,  ..., -0.9668,  0.2456, -0.5628]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2246, -0.8440, -0.7282,  ..., -0.4905,  0.0531, -0.5808],\n",
      "        [-0.2085, -1.0031, -0.6059,  ..., -0.6897,  0.2121, -0.7404],\n",
      "        [-0.5030, -1.2355, -0.7313,  ..., -0.6766,  0.3460, -0.4888],\n",
      "        ...,\n",
      "        [ 0.2673, -1.0789, -0.6183,  ..., -0.8137,  0.1570, -0.2119],\n",
      "        [ 0.0032, -1.1229, -0.7762,  ..., -0.6645,  0.1455, -0.9530],\n",
      "        [ 0.3235, -1.1595, -0.5935,  ..., -0.8799, -0.0731, -0.4764]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2147, -0.8248, -0.4737,  ..., -0.8308,  0.2168, -0.2913],\n",
      "        [-0.0579, -1.0432, -0.5460,  ..., -0.8519,  0.1505, -0.5892],\n",
      "        [ 0.0604, -1.3846, -0.8248,  ..., -0.5546, -0.1219, -0.5074],\n",
      "        ...,\n",
      "        [ 0.1443, -1.1851, -0.6312,  ..., -0.7336,  0.1793, -0.5242],\n",
      "        [-0.1315, -1.0311, -0.4687,  ..., -0.8568,  0.0618, -0.4586],\n",
      "        [-0.1318, -1.0535, -0.7577,  ..., -0.6994,  0.1048, -0.4899]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0146, -0.8787, -0.4220,  ..., -0.8022,  0.1200, -0.1833],\n",
      "        [ 0.0888, -1.1365, -0.4280,  ..., -0.9627,  0.1201, -0.5357],\n",
      "        [ 0.1724, -0.9006, -0.5878,  ..., -0.5633,  0.1491, -0.5928],\n",
      "        ...,\n",
      "        [-0.0955, -0.7532, -0.6959,  ..., -0.7152,  0.2088, -0.4653],\n",
      "        [-0.2953, -0.7344, -0.3805,  ..., -0.7186,  0.0372, -0.3660],\n",
      "        [ 0.1706, -1.0377, -0.4704,  ..., -0.8077,  0.0225, -0.7151]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1288, -1.0167, -0.5432,  ..., -0.6229,  0.1347, -0.3415],\n",
      "        [ 0.3057, -0.7791, -0.6724,  ..., -0.7467, -0.0458, -0.3310],\n",
      "        [ 0.3545, -0.9796, -0.4531,  ..., -0.8923, -0.0467, -0.3215],\n",
      "        ...,\n",
      "        [ 0.1963, -1.1575, -0.7548,  ..., -0.7243,  0.0421, -0.4418],\n",
      "        [-0.1752, -1.1689, -0.3509,  ..., -0.7110,  0.2580, -0.5896],\n",
      "        [ 0.1148, -1.0726, -0.4975,  ..., -0.7469, -0.1263, -0.8661]],\n",
      "       device='mps:0')\n",
      "Epoch: 5 | Batch: 20 | Loss: 0.9747 | Acc: 41.37%\n",
      "cls_features:  tensor([[-0.2074, -1.0191, -0.5443,  ..., -0.7784,  0.1679, -0.7243],\n",
      "        [ 0.0150, -1.1653, -0.5247,  ..., -0.7440,  0.3567, -0.6713],\n",
      "        [-0.3013, -0.9085, -0.5731,  ..., -0.9054,  0.1755, -0.3985],\n",
      "        ...,\n",
      "        [ 0.1983, -1.3617, -0.7876,  ..., -0.6202,  0.0129, -0.6407],\n",
      "        [ 0.1745, -1.2509, -0.3148,  ..., -0.8463,  0.0134, -0.6765],\n",
      "        [ 0.1564, -1.2506, -0.6335,  ..., -0.8406,  0.2149, -0.4478]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 1.7174e-01, -1.1463e+00, -5.4263e-01,  ..., -7.0154e-01,\n",
      "         -5.8502e-02, -6.6606e-01],\n",
      "        [ 4.9198e-02, -8.2499e-01, -6.2750e-01,  ..., -6.4899e-01,\n",
      "         -1.4180e-01, -5.8689e-01],\n",
      "        [ 2.0480e-01, -8.9805e-01, -4.8778e-01,  ..., -7.6339e-01,\n",
      "          1.1105e-04, -7.0761e-01],\n",
      "        ...,\n",
      "        [ 1.8141e-01, -1.1226e+00, -6.8279e-01,  ..., -7.9415e-01,\n",
      "          3.2140e-01, -8.4608e-01],\n",
      "        [ 2.2817e-01, -1.0227e+00, -5.6162e-01,  ..., -7.4759e-01,\n",
      "         -1.2104e-01, -3.4556e-01],\n",
      "        [-1.0842e-02, -1.0432e+00, -7.2450e-01,  ..., -6.6878e-01,\n",
      "          1.0104e-01, -5.1041e-01]], device='mps:0')\n",
      "cls_features:  tensor([[ 0.1920, -1.0044, -0.3939,  ..., -0.8423,  0.1316, -0.3656],\n",
      "        [-0.0267, -0.9850, -0.5707,  ..., -0.7439,  0.0381, -0.5162],\n",
      "        [-0.1327, -1.1565, -0.8770,  ..., -0.8539,  0.1676, -0.7102],\n",
      "        ...,\n",
      "        [-0.5522, -0.9315, -0.6516,  ..., -0.7466,  0.2290, -0.5694],\n",
      "        [ 0.1087, -1.1503, -0.7580,  ..., -0.6473,  0.1501, -0.4841],\n",
      "        [-0.0149, -1.0610, -0.7012,  ..., -0.7745,  0.2036, -0.5942]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 3.8396e-01, -1.2201e+00, -5.5070e-01,  ..., -7.3070e-01,\n",
      "          1.1624e-02, -2.9396e-01],\n",
      "        [ 1.0783e-03, -1.1220e+00, -8.6178e-01,  ..., -7.5538e-01,\n",
      "          1.1696e-01, -5.3795e-01],\n",
      "        [ 7.4659e-03, -1.0198e+00, -8.9128e-01,  ..., -7.0168e-01,\n",
      "          1.5421e-01, -5.2639e-01],\n",
      "        ...,\n",
      "        [-4.2097e-02, -8.3690e-01, -4.2406e-01,  ..., -7.9932e-01,\n",
      "          4.5295e-02, -3.8054e-01],\n",
      "        [ 2.7015e-01, -9.9946e-01, -6.8822e-01,  ..., -9.2932e-01,\n",
      "          1.1481e-01, -3.7159e-01],\n",
      "        [-1.9892e-01, -9.8898e-01, -6.2183e-01,  ..., -6.6982e-01,\n",
      "          2.3450e-01, -5.3674e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.2942, -1.0634, -0.8605,  ..., -0.7916,  0.4163, -0.2569],\n",
      "        [-0.3396, -0.9687, -0.8067,  ..., -0.9493,  0.2691, -0.6589],\n",
      "        [-0.1909, -0.9379, -0.6955,  ..., -0.7993,  0.3205, -0.5418],\n",
      "        ...,\n",
      "        [-0.1957, -1.2095, -0.5712,  ..., -0.6935,  0.0846, -0.7877],\n",
      "        [-0.1574, -1.0731, -0.7128,  ..., -0.6863,  0.2106, -0.3739],\n",
      "        [ 0.1921, -0.7483, -0.5840,  ..., -0.7929, -0.1146, -0.3104]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 1.4111e-01, -1.2154e+00, -7.4874e-01,  ..., -6.5051e-01,\n",
      "         -1.0893e-01, -6.6487e-01],\n",
      "        [ 6.1436e-02, -9.5562e-01, -3.0675e-01,  ..., -8.0856e-01,\n",
      "          1.9960e-01, -5.3885e-01],\n",
      "        [ 7.5760e-02, -1.1319e+00, -5.8423e-01,  ..., -8.6241e-01,\n",
      "          4.3002e-02, -4.7268e-01],\n",
      "        ...,\n",
      "        [-1.7839e-01, -1.1289e+00, -8.4538e-01,  ..., -8.2308e-01,\n",
      "          1.0695e-01, -5.4177e-01],\n",
      "        [-8.9350e-02, -9.7129e-01, -4.4578e-01,  ..., -7.4755e-01,\n",
      "          4.3446e-02, -5.1619e-01],\n",
      "        [ 1.7693e-04, -1.2362e+00, -3.3390e-01,  ..., -8.8388e-01,\n",
      "          2.0411e-01, -4.6535e-01]], device='mps:0')\n",
      "cls_features:  tensor([[ 0.0107, -0.9458, -0.7732,  ..., -0.7838,  0.3158, -0.5561],\n",
      "        [ 0.0790, -1.1530, -0.8314,  ..., -0.8659,  0.2972, -0.5363],\n",
      "        [-0.1831, -1.0210, -0.6501,  ..., -0.7955,  0.2069, -0.4793],\n",
      "        ...,\n",
      "        [ 0.1777, -1.1049, -0.7452,  ..., -0.7812,  0.2188, -0.3240],\n",
      "        [ 0.0913, -1.0965, -0.7840,  ..., -0.8734,  0.1389, -0.2765],\n",
      "        [ 0.0421, -0.9649, -0.6931,  ..., -0.4082,  0.1947, -0.7745]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2536, -1.0263, -0.5918,  ..., -0.7197, -0.0524, -0.6068],\n",
      "        [ 0.0230, -1.0065, -0.5190,  ..., -0.9811,  0.3898, -0.0417],\n",
      "        [-0.0905, -1.1287, -0.8408,  ..., -0.8459,  0.1037, -0.5091],\n",
      "        ...,\n",
      "        [-0.2297, -0.9649, -0.7534,  ..., -0.6972,  0.2010, -0.5666],\n",
      "        [-0.0654, -0.9288, -1.0120,  ..., -0.7919,  0.1154, -0.6944],\n",
      "        [ 0.0878, -0.9348, -0.4343,  ..., -0.7619, -0.0220, -0.3885]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0466, -1.2605, -0.7633,  ..., -0.8750,  0.0793, -0.5408],\n",
      "        [-0.1175, -1.0251, -0.4052,  ..., -0.7493,  0.0462, -0.7991],\n",
      "        [-0.2270, -0.8869, -0.5934,  ..., -0.7402,  0.2646, -0.5762],\n",
      "        ...,\n",
      "        [-0.2201, -0.9210, -0.6377,  ..., -0.6887,  0.1714, -0.6443],\n",
      "        [-0.3180, -1.3397, -0.4851,  ..., -0.8365,  0.2582, -0.8999],\n",
      "        [-0.3660, -0.9199, -0.7892,  ..., -0.6247,  0.1310, -0.6679]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3768, -1.0312, -0.7492,  ..., -0.7664,  0.0999, -0.5256],\n",
      "        [ 0.2672, -1.0878, -0.6682,  ..., -0.7838,  0.2491, -0.5446],\n",
      "        [-0.2239, -0.9972, -0.4749,  ..., -0.8058, -0.0716, -0.3481],\n",
      "        ...,\n",
      "        [ 0.1473, -1.0706, -0.5369,  ..., -0.5067, -0.0840, -0.6072],\n",
      "        [ 0.1911, -1.0406, -0.7234,  ..., -0.7908,  0.2479, -0.5016],\n",
      "        [-0.1574, -0.9494, -0.5400,  ..., -0.8185,  0.0466, -0.4453]],\n",
      "       device='mps:0')\n",
      "Epoch: 5 | Batch: 30 | Loss: 0.9619 | Acc: 44.15%\n",
      "cls_features:  tensor([[ 0.1982, -0.6942, -0.4509,  ..., -0.6856, -0.0702, -0.2861],\n",
      "        [ 0.0145, -1.0799, -0.7881,  ..., -0.7529,  0.0959, -0.5252],\n",
      "        [ 0.0050, -1.1061, -0.5483,  ..., -0.7598,  0.2138, -0.7047],\n",
      "        ...,\n",
      "        [ 0.1741, -1.1228, -0.8571,  ..., -0.7672,  0.4080, -0.3156],\n",
      "        [-0.2718, -0.9078, -0.5481,  ..., -0.7235,  0.1846, -0.4754],\n",
      "        [-0.1016, -0.8341, -0.5529,  ..., -0.6923,  0.0129, -0.4868]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2326, -0.7995, -0.4747,  ..., -0.7702,  0.2914, -0.5313],\n",
      "        [-0.1548, -0.9201, -0.4164,  ..., -0.8474, -0.0056, -0.6215],\n",
      "        [-0.4529, -0.9619, -0.4345,  ..., -0.9215,  0.1345, -0.2341],\n",
      "        ...,\n",
      "        [ 0.2499, -1.0059, -0.6497,  ..., -0.6938,  0.0411, -0.5288],\n",
      "        [ 0.2139, -1.0051, -0.4437,  ..., -0.8507,  0.0374, -0.5441],\n",
      "        [-0.0990, -0.8343, -0.9123,  ..., -0.6627,  0.1341, -0.4539]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0260, -0.9601, -0.5039,  ..., -0.6907,  0.1558, -0.3146],\n",
      "        [-0.2722, -0.8610, -0.6714,  ..., -0.7539,  0.3252, -0.3763],\n",
      "        [-0.1797, -0.7256, -0.5685,  ..., -0.9268,  0.3538, -0.4122],\n",
      "        ...,\n",
      "        [ 0.2656, -1.0400, -0.5054,  ..., -0.6770,  0.0988, -0.5886],\n",
      "        [-0.1959, -1.1304, -0.8303,  ..., -0.8573,  0.0260, -0.8918],\n",
      "        [-0.4092, -1.1161, -0.6726,  ..., -0.7572,  0.2085, -0.5254]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1923, -0.9140, -0.5956,  ..., -0.8789,  0.1905, -0.4366],\n",
      "        [-0.1569, -0.8599, -0.3480,  ..., -0.7587,  0.0193, -0.3213],\n",
      "        [-0.2706, -1.0756, -0.4968,  ..., -0.7183,  0.1885, -0.6208],\n",
      "        ...,\n",
      "        [-0.0505, -1.1380, -0.8276,  ..., -0.7461,  0.2553, -0.6573],\n",
      "        [ 0.2774, -0.9045, -0.4449,  ..., -0.7457,  0.0809, -0.4799],\n",
      "        [ 0.2034, -1.1968, -0.6721,  ..., -0.7720,  0.0487, -0.7429]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0943, -0.8153, -0.4427,  ..., -0.7607, -0.0773, -0.8436],\n",
      "        [-0.2439, -1.1641, -0.5098,  ..., -0.7128,  0.2331, -0.6152],\n",
      "        [ 0.1363, -1.1519, -0.8195,  ..., -0.6688,  0.0034, -0.5131],\n",
      "        ...,\n",
      "        [ 0.0955, -0.9829, -0.5350,  ..., -0.7844, -0.0107, -0.6952],\n",
      "        [ 0.0056, -1.1547, -0.7725,  ..., -0.6207,  0.3727, -0.5957],\n",
      "        [-0.1009, -1.0794, -0.8495,  ..., -0.8213,  0.2858, -0.4611]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3715, -0.8997, -0.6617,  ..., -0.8239,  0.1999, -0.2282],\n",
      "        [-0.1082, -0.7064, -0.5509,  ..., -0.7917,  0.2774, -0.2686],\n",
      "        [ 0.3018, -0.9063, -0.3530,  ..., -0.6781, -0.0024, -0.3863],\n",
      "        ...,\n",
      "        [ 0.2196, -1.1738, -0.5947,  ..., -0.6780,  0.0440, -0.7237],\n",
      "        [-0.1822, -1.1268, -0.8628,  ..., -0.7404,  0.3281, -0.8656],\n",
      "        [-0.1361, -1.0150, -0.4521,  ..., -0.6563,  0.1275, -0.8110]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0668, -1.1597, -0.4415,  ..., -0.8292,  0.1595, -0.4503],\n",
      "        [-0.1561, -0.9481, -0.6985,  ..., -0.8588,  0.2524, -0.4483],\n",
      "        [ 0.3879, -1.1935, -0.6147,  ..., -0.8383,  0.1475, -0.5456],\n",
      "        ...,\n",
      "        [-0.0635, -0.8726, -0.3165,  ..., -0.8076,  0.2255, -0.4317],\n",
      "        [-0.2119, -1.0333, -0.7679,  ..., -0.9379,  0.1268, -0.7548],\n",
      "        [-0.3475, -1.1107, -0.6155,  ..., -0.7513,  0.1120, -0.7664]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 2.6176e-01, -1.1564e+00, -5.3197e-01,  ..., -9.0169e-01,\n",
      "         -8.0502e-04, -8.5765e-01],\n",
      "        [ 1.5561e-01, -1.1294e+00, -4.5716e-01,  ..., -8.4043e-01,\n",
      "         -2.8044e-02, -6.1134e-01],\n",
      "        [ 2.1286e-01, -1.0161e+00, -6.4587e-01,  ..., -6.7691e-01,\n",
      "          6.0131e-02, -7.3311e-01],\n",
      "        ...,\n",
      "        [-4.2489e-01, -1.0063e+00, -5.8820e-01,  ..., -8.2909e-01,\n",
      "          2.2735e-01, -6.0393e-01],\n",
      "        [-5.6880e-03, -1.0643e+00, -8.1814e-01,  ..., -6.7322e-01,\n",
      "          6.3696e-02, -6.7690e-01],\n",
      "        [-2.2384e-01, -1.1137e+00, -8.5815e-01,  ..., -6.9156e-01,\n",
      "          1.9319e-01, -5.9756e-01]], device='mps:0')\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 1.0912 | Train Acc: 44.20%\n",
      "Val Loss: 0.9815 | Val Acc: 50.50%\n",
      "cls_features:  tensor([[ 0.2393, -0.9593, -0.3708,  ..., -0.7842,  0.1168, -0.1857],\n",
      "        [-0.3226, -1.0059, -0.8547,  ..., -0.5360,  0.2007, -0.7697],\n",
      "        [-0.1417, -0.9212, -0.6605,  ..., -0.6073,  0.0946, -0.5609],\n",
      "        ...,\n",
      "        [ 0.2184, -1.1313, -0.6161,  ..., -0.8460,  0.1764, -0.3035],\n",
      "        [ 0.2672, -1.0878, -0.6682,  ..., -0.7838,  0.2491, -0.5446],\n",
      "        [-0.2165, -1.3367, -0.7835,  ..., -0.7632,  0.3407, -0.6185]],\n",
      "       device='mps:0')\n",
      "Epoch: 6 | Batch: 0 | Loss: 1.3356 | Acc: 28.12%\n",
      "cls_features:  tensor([[ 0.0785, -1.2621, -0.8194,  ..., -0.8581,  0.2592, -0.3196],\n",
      "        [ 0.1542, -0.9478, -0.7102,  ..., -0.7820,  0.2415, -0.3789],\n",
      "        [ 0.1524, -1.0589, -0.7424,  ..., -0.7642,  0.3178, -0.5612],\n",
      "        ...,\n",
      "        [ 0.0218, -1.2921, -0.5439,  ..., -0.6865, -0.1198, -0.5934],\n",
      "        [ 0.0275, -1.1769, -1.0689,  ..., -0.7389,  0.2133, -0.9324],\n",
      "        [ 0.3119, -1.0275, -0.5296,  ..., -0.7828,  0.0404, -0.5726]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.3009, -0.8950, -0.2798,  ..., -0.8613,  0.1126, -0.4483],\n",
      "        [ 0.0234, -1.1459, -0.7965,  ..., -0.7167, -0.0578, -0.3834],\n",
      "        [-0.2623, -0.8866, -0.4514,  ..., -0.8209,  0.4292, -0.3724],\n",
      "        ...,\n",
      "        [-0.1344, -1.2967, -0.8332,  ..., -0.6773,  0.2017, -0.6869],\n",
      "        [-0.2714, -1.1688, -0.8094,  ..., -0.7102,  0.1919, -0.8244],\n",
      "        [-0.3066, -0.9957, -0.3497,  ..., -0.8741,  0.2719, -0.6860]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0427, -0.9612, -0.5921,  ..., -0.8132, -0.0128, -0.6478],\n",
      "        [ 0.1920, -1.0044, -0.3939,  ..., -0.8423,  0.1316, -0.3656],\n",
      "        [ 0.0604, -1.3846, -0.8248,  ..., -0.5546, -0.1219, -0.5074],\n",
      "        ...,\n",
      "        [-0.3749, -0.8255, -0.5971,  ..., -0.8071,  0.2130, -0.4731],\n",
      "        [-0.0426, -1.0647, -0.4354,  ..., -0.7380,  0.0161, -0.8681],\n",
      "        [ 0.0149, -0.9360, -0.5710,  ..., -0.8368,  0.0240, -0.4489]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2718, -0.9078, -0.5481,  ..., -0.7235,  0.1845, -0.4754],\n",
      "        [-0.0938, -1.0055, -0.7266,  ..., -0.8116,  0.2887, -0.6213],\n",
      "        [ 0.0501, -1.1323, -0.6566,  ..., -0.8235,  0.1853, -0.7074],\n",
      "        ...,\n",
      "        [-0.0465, -0.9524, -0.5494,  ..., -0.6519,  0.0447, -0.3017],\n",
      "        [-0.0162, -1.0189, -0.5765,  ..., -0.8610,  0.1026, -0.4120],\n",
      "        [-0.3196, -0.9304, -0.8010,  ..., -0.9867,  0.3705, -0.6948]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2132, -1.1742, -0.2763,  ..., -0.6990, -0.1351, -0.8492],\n",
      "        [ 0.1025, -1.4507, -0.6536,  ..., -0.7562,  0.0947, -0.8223],\n",
      "        [ 0.0664, -1.4056, -0.9461,  ..., -0.6953,  0.2494, -0.9267],\n",
      "        ...,\n",
      "        [ 0.3307, -0.8814, -0.5930,  ..., -0.7683,  0.0894, -0.2702],\n",
      "        [-0.2092, -0.9522, -0.2067,  ..., -0.8502,  0.2125, -0.5256],\n",
      "        [-0.0796, -0.9606, -0.5943,  ..., -0.8376, -0.0913, -0.4251]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0352, -1.0448, -0.6770,  ..., -0.5697,  0.0612, -0.4470],\n",
      "        [-0.0153, -0.7387, -0.5427,  ..., -0.7781,  0.0411, -0.3281],\n",
      "        [ 0.0165, -0.9618, -0.5063,  ..., -0.6484, -0.0513, -0.5063],\n",
      "        ...,\n",
      "        [ 0.2237, -0.8570, -0.4872,  ..., -0.5554,  0.1087, -0.3181],\n",
      "        [-0.1628, -0.7994, -0.6080,  ..., -0.6597,  0.0433, -0.5387],\n",
      "        [ 0.0325, -0.9328, -0.9484,  ..., -0.6823, -0.0903, -0.5190]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2239, -0.9972, -0.4749,  ..., -0.8058, -0.0716, -0.3481],\n",
      "        [ 0.0030, -0.7512, -0.4992,  ..., -0.6102,  0.2682, -0.6112],\n",
      "        [ 0.1087, -1.1503, -0.7580,  ..., -0.6473,  0.1501, -0.4841],\n",
      "        ...,\n",
      "        [ 0.1060, -1.0580, -0.5003,  ..., -0.6655,  0.0586, -0.4888],\n",
      "        [ 0.3851, -1.1277, -0.6940,  ..., -0.6157,  0.0661, -0.3595],\n",
      "        [-0.0606, -1.0303, -0.6230,  ..., -0.7477,  0.2080, -0.5859]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2220, -1.3516, -0.7872,  ..., -0.7302, -0.1671, -0.7913],\n",
      "        [-0.1357, -1.2081, -0.8115,  ..., -0.7099,  0.1258, -0.5309],\n",
      "        [-0.0797, -1.0240, -0.6541,  ..., -0.8985,  0.2668, -0.3803],\n",
      "        ...,\n",
      "        [-0.1317, -1.1972, -0.8847,  ..., -0.4667,  0.2523, -0.4966],\n",
      "        [ 0.0389, -1.1926, -0.6116,  ..., -0.7865,  0.1117, -0.4261],\n",
      "        [ 0.0283, -1.1731, -0.6040,  ..., -0.7130,  0.1556, -0.6848]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1096, -0.9836, -0.7815,  ..., -0.7912,  0.3128, -0.4454],\n",
      "        [ 0.0173, -0.8977, -0.6510,  ..., -0.7374, -0.1719, -0.3740],\n",
      "        [-0.4256, -1.0765, -0.7654,  ..., -0.9126,  0.3726, -0.4170],\n",
      "        ...,\n",
      "        [ 0.2296, -1.1606, -0.7731,  ..., -0.7250,  0.0769, -0.4781],\n",
      "        [-0.0649, -1.1004, -0.7694,  ..., -0.7785,  0.1888, -0.5928],\n",
      "        [-0.1909, -0.9379, -0.6955,  ..., -0.7993,  0.3205, -0.5418]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2410, -0.8953, -0.2396,  ..., -0.8513, -0.0380, -0.5441],\n",
      "        [ 0.0107, -0.9458, -0.7732,  ..., -0.7838,  0.3158, -0.5561],\n",
      "        [-0.3933, -1.0310, -0.3782,  ..., -0.7966,  0.1195, -0.6845],\n",
      "        ...,\n",
      "        [ 0.0257, -0.9544, -0.5545,  ..., -0.6103,  0.0675, -0.2992],\n",
      "        [-0.1101, -1.1506, -0.5714,  ..., -0.7484,  0.2676, -0.3317],\n",
      "        [-0.1275, -1.2002, -0.7666,  ..., -0.8426,  0.4515, -0.4570]],\n",
      "       device='mps:0')\n",
      "Epoch: 6 | Batch: 10 | Loss: 1.1201 | Acc: 47.16%\n",
      "cls_features:  tensor([[ 0.2735, -1.4846, -0.7331,  ..., -0.6511,  0.0735, -0.5744],\n",
      "        [ 0.5143, -0.7612, -0.4394,  ..., -0.5973, -0.0773, -0.4070],\n",
      "        [ 0.0150, -1.1653, -0.5247,  ..., -0.7440,  0.3567, -0.6713],\n",
      "        ...,\n",
      "        [ 0.2811, -0.9919, -0.5758,  ..., -0.5239,  0.2393, -0.5209],\n",
      "        [-0.0478, -0.8204, -0.4113,  ..., -0.5690, -0.0332, -0.5034],\n",
      "        [-0.3391, -1.1445, -0.6918,  ..., -0.7852,  0.0597, -0.7151]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3188, -0.7828, -0.4320,  ..., -0.6147, -0.1802, -0.6370],\n",
      "        [-0.0577, -0.8735, -0.5899,  ..., -0.5531,  0.1742, -0.7610],\n",
      "        [ 0.3092, -1.2381, -0.5547,  ..., -0.8123,  0.1652, -0.7401],\n",
      "        ...,\n",
      "        [ 0.0769, -1.1091, -0.5795,  ..., -0.7703,  0.1123, -0.4567],\n",
      "        [ 0.0944, -0.7924, -0.4231,  ..., -0.8213,  0.2358, -0.3429],\n",
      "        [-0.3952, -1.0210, -0.3025,  ..., -0.9234,  0.0613, -0.3936]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 1.7785e-04, -1.2362e+00, -3.3390e-01,  ..., -8.8389e-01,\n",
      "          2.0411e-01, -4.6535e-01],\n",
      "        [-2.8140e-02, -8.6436e-01, -7.7500e-01,  ..., -5.4862e-01,\n",
      "          1.1471e-01, -3.6204e-01],\n",
      "        [-9.9583e-02, -1.0041e+00, -8.4395e-01,  ..., -4.9405e-01,\n",
      "          1.7815e-01, -4.5832e-01],\n",
      "        ...,\n",
      "        [ 1.0707e-01, -1.2675e+00, -7.5045e-01,  ..., -6.2769e-01,\n",
      "         -7.1294e-02, -7.3229e-01],\n",
      "        [ 1.0806e-01, -1.1013e+00, -8.5151e-01,  ..., -7.0344e-01,\n",
      "          1.7906e-01, -5.9237e-01],\n",
      "        [-1.2497e-02, -1.1198e+00, -7.1400e-01,  ..., -6.8922e-01,\n",
      "          4.9246e-02, -5.8131e-01]], device='mps:0')\n",
      "cls_features:  tensor([[-0.3676, -1.1031, -0.5711,  ..., -0.9706,  0.3027, -0.5206],\n",
      "        [-0.2010, -1.1145, -0.8532,  ..., -0.8088,  0.0350, -0.5444],\n",
      "        [ 0.0509, -0.9989, -0.8005,  ..., -0.6571,  0.1851, -0.6437],\n",
      "        ...,\n",
      "        [-0.2449, -0.9141, -0.6438,  ..., -0.7625,  0.4323, -0.3965],\n",
      "        [-0.1334, -1.1188, -0.5399,  ..., -0.8917,  0.1341, -0.7500],\n",
      "        [-0.1574, -1.0731, -0.7128,  ..., -0.6863,  0.2106, -0.3739]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2808, -1.0595, -0.6830,  ..., -0.7852,  0.0048, -0.5719],\n",
      "        [-0.2868, -0.8605, -0.3033,  ..., -0.7966,  0.2354, -0.3584],\n",
      "        [ 0.1748, -0.9532, -0.6469,  ..., -0.6476, -0.1022, -0.5428],\n",
      "        ...,\n",
      "        [ 0.2924, -0.8977, -0.5255,  ..., -0.7744,  0.1012, -0.2088],\n",
      "        [-0.1311, -1.0185, -0.4586,  ..., -0.7031, -0.0018, -0.7276],\n",
      "        [-0.5409, -1.0111, -0.6785,  ..., -0.6901,  0.2505, -0.7047]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.0124, -1.0868, -0.2263,  ..., -0.5904, -0.0518, -0.7716],\n",
      "        [ 0.2536, -1.2455, -0.6763,  ..., -0.8151,  0.0530, -0.4387],\n",
      "        [-0.1203, -1.1561, -0.7677,  ..., -0.7583, -0.1114, -0.6085],\n",
      "        ...,\n",
      "        [-0.0634, -1.1422, -0.8932,  ..., -0.8949,  0.0699, -0.4989],\n",
      "        [-0.0556, -1.0168, -0.6653,  ..., -0.5443,  0.0399, -0.5911],\n",
      "        [-0.1922, -0.9938, -0.7512,  ..., -0.7435,  0.1959, -0.3558]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.4621, -1.1578, -0.4823,  ..., -0.7605, -0.2074, -0.4509],\n",
      "        [-0.4562, -0.9176, -0.4718,  ..., -0.9163,  0.3155, -0.4556],\n",
      "        [-0.1001, -1.1534, -0.8335,  ..., -0.6019,  0.1754, -0.7845],\n",
      "        ...,\n",
      "        [-0.3278, -0.9630, -0.7630,  ..., -0.7708,  0.2166, -0.6694],\n",
      "        [ 0.0731, -1.3648, -0.8115,  ..., -0.8725,  0.1175, -0.7110],\n",
      "        [-0.0638, -1.2919, -0.7866,  ..., -0.7226,  0.1359, -0.5577]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.2864, -1.0835, -0.5205,  ..., -0.5436, -0.0513, -0.4206],\n",
      "        [-0.0579, -1.0432, -0.5460,  ..., -0.8519,  0.1505, -0.5892],\n",
      "        [ 0.3194, -0.9816, -0.6813,  ..., -0.7008, -0.3522, -0.5842],\n",
      "        ...,\n",
      "        [ 0.0859, -1.0355, -0.4746,  ..., -0.7937,  0.1924, -0.5738],\n",
      "        [-0.1333, -1.2940, -0.6851,  ..., -0.7029,  0.0942, -0.7049],\n",
      "        [ 0.2304, -1.1025, -0.9038,  ..., -0.7564, -0.0994, -0.5187]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1621, -1.1265, -0.6681,  ..., -0.7180,  0.3637, -0.6208],\n",
      "        [ 0.2087, -1.2864, -0.6979,  ..., -0.5969,  0.2451, -0.7286],\n",
      "        [-0.2085, -1.0031, -0.6059,  ..., -0.6897,  0.2121, -0.7404],\n",
      "        ...,\n",
      "        [ 0.1003, -1.0856, -0.3771,  ..., -0.8478,  0.0822, -0.5073],\n",
      "        [ 0.0050, -1.1061, -0.5483,  ..., -0.7598,  0.2138, -0.7047],\n",
      "        [-0.0022, -1.2248, -0.4905,  ..., -0.5200,  0.0661, -0.6753]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1123, -1.2830, -0.6355,  ..., -0.9881,  0.2608, -0.4971],\n",
      "        [ 0.2845, -1.4281, -0.5401,  ..., -0.7419,  0.2619, -0.6621],\n",
      "        [-0.0436, -1.1156, -0.3168,  ..., -0.9502,  0.0375, -0.7441],\n",
      "        ...,\n",
      "        [ 0.2547, -1.1389, -0.8160,  ..., -0.4319, -0.0077, -0.9839],\n",
      "        [ 0.0136, -1.0157, -0.5843,  ..., -0.6073,  0.1461, -0.5203],\n",
      "        [ 0.0547, -1.0286, -0.6613,  ..., -0.6375,  0.0626, -0.5980]],\n",
      "       device='mps:0')\n",
      "Epoch: 6 | Batch: 20 | Loss: 1.2906 | Acc: 44.35%\n",
      "cls_features:  tensor([[-0.0603, -1.1249, -0.6819,  ..., -0.5558,  0.1669, -0.5063],\n",
      "        [ 0.0654, -1.0698, -0.5686,  ..., -0.8583,  0.0453, -0.6515],\n",
      "        [-0.1006, -0.8594, -0.8519,  ..., -0.8790,  0.1057, -0.4700],\n",
      "        ...,\n",
      "        [ 0.2078, -1.1964, -0.6902,  ..., -0.7369,  0.1046, -0.5204],\n",
      "        [ 0.0146, -0.9963, -0.4926,  ..., -0.8047,  0.0569, -0.4618],\n",
      "        [-0.0386, -1.2370, -0.8592,  ..., -0.7422,  0.4452, -0.7555]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.2739, -1.0357, -0.7029,  ..., -0.9088,  0.2434, -0.5008],\n",
      "        [-0.4088, -1.0382, -0.5725,  ..., -0.6925, -0.0257, -0.9442],\n",
      "        [-0.1546, -1.1955, -0.7123,  ..., -0.7756,  0.2036, -0.5448],\n",
      "        ...,\n",
      "        [-0.2708, -1.1266, -0.9201,  ..., -0.7697,  0.1084, -0.7780],\n",
      "        [ 0.1606, -1.0539, -0.7179,  ..., -0.7070, -0.0301, -0.5557],\n",
      "        [ 0.0032, -1.1229, -0.7762,  ..., -0.6645,  0.1455, -0.9530]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.3239, -1.0744, -0.4807,  ..., -0.7882,  0.1079, -0.4874],\n",
      "        [ 0.1615, -1.0652, -0.7921,  ..., -0.6756, -0.0106, -0.8299],\n",
      "        [-0.1188, -0.9521, -0.4164,  ..., -0.8236, -0.0105, -0.4537],\n",
      "        ...,\n",
      "        [-0.1991, -1.0772, -0.7827,  ..., -0.8137,  0.2211, -0.4936],\n",
      "        [ 0.1282, -1.3837, -0.7855,  ..., -0.7606,  0.2704, -0.4067],\n",
      "        [-0.2652, -1.1131, -0.7387,  ..., -0.8411,  0.0998, -0.4629]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1551, -0.7067, -0.5547,  ..., -0.6916,  0.0583, -0.4254],\n",
      "        [ 0.3548, -1.0378, -0.7121,  ..., -0.7231, -0.0580, -0.3987],\n",
      "        [ 0.2450, -1.2289, -0.5948,  ..., -0.7491,  0.1013, -0.6281],\n",
      "        ...,\n",
      "        [-0.0717, -1.1490, -0.7532,  ..., -0.8159,  0.3186, -0.4677],\n",
      "        [-0.4528, -1.1092, -0.5052,  ..., -0.7843,  0.4402, -0.8515],\n",
      "        [ 0.3524, -1.1569, -0.5293,  ..., -0.8027, -0.0223, -0.5602]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[ 0.1225, -1.1233, -0.5845,  ..., -0.6761,  0.2698, -0.6909],\n",
      "        [-0.4952, -1.1429, -0.4705,  ..., -0.8816,  0.2415, -0.4475],\n",
      "        [ 0.4403, -1.2694, -0.8072,  ..., -0.6841,  0.1126, -0.2142],\n",
      "        ...,\n",
      "        [-0.2029, -1.0867, -0.8406,  ..., -0.8466,  0.2742, -0.4025],\n",
      "        [-0.3756, -1.0103, -0.7801,  ..., -0.5980,  0.2756, -0.6688],\n",
      "        [ 0.2420, -1.3672, -0.5655,  ..., -0.8300, -0.1163, -0.7010]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1698, -1.1585, -0.4039,  ..., -0.8047, -0.1205, -0.7376],\n",
      "        [ 0.4323, -1.2057, -0.7014,  ..., -0.5564, -0.0076, -0.3641],\n",
      "        [ 0.0336, -1.2201, -0.4810,  ..., -0.5202, -0.1284, -0.7935],\n",
      "        ...,\n",
      "        [-0.0288, -1.1586, -0.6834,  ..., -0.9659,  0.1451, -0.7179],\n",
      "        [ 0.4321, -1.1255, -0.8990,  ..., -0.6987,  0.2286, -0.4530],\n",
      "        [ 0.0419, -1.2907, -0.7149,  ..., -0.9552,  0.1093, -0.6414]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.1068, -0.9504, -0.8260,  ..., -0.7145,  0.3020, -0.4451],\n",
      "        [-0.1998, -1.0736, -0.7413,  ..., -0.7374,  0.2541, -0.6597],\n",
      "        [-0.1113, -0.8630, -0.3631,  ..., -0.6834, -0.0887, -0.4205],\n",
      "        ...,\n",
      "        [ 0.1301, -0.9615, -0.6979,  ..., -0.7926,  0.3321, -0.4231],\n",
      "        [ 0.2697, -1.3369, -0.8199,  ..., -0.6532,  0.1471, -0.7830],\n",
      "        [-0.0017, -1.1299, -0.6964,  ..., -0.7155, -0.0689, -0.7702]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0073, -1.1935, -0.4999,  ..., -0.7900,  0.0395, -0.5540],\n",
      "        [-0.1837, -0.8442, -0.6413,  ..., -0.6632,  0.1911, -0.6062],\n",
      "        [-0.0758, -0.8649, -0.5069,  ..., -0.6595, -0.0476, -0.5117],\n",
      "        ...,\n",
      "        [ 0.2565, -1.0364, -0.4796,  ..., -0.6699,  0.2866, -0.4018],\n",
      "        [-0.4086, -1.2496, -0.6689,  ..., -0.8890,  0.3959, -0.7582],\n",
      "        [-0.0581, -1.2164, -0.8064,  ..., -0.8056,  0.2447, -0.6588]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0878, -1.1810, -0.7526,  ..., -0.8519,  0.2083, -0.6707],\n",
      "        [-0.0893, -0.9713, -0.4458,  ..., -0.7475,  0.0434, -0.5162],\n",
      "        [-0.1403, -0.9619, -0.5773,  ..., -0.5816,  0.3093, -0.6732],\n",
      "        ...,\n",
      "        [-0.0487, -1.1740, -0.6545,  ..., -0.8529,  0.2884, -0.4156],\n",
      "        [-0.0283, -0.8113, -0.3976,  ..., -0.7241,  0.0175, -0.4336],\n",
      "        [-0.3796, -1.2385, -0.9760,  ..., -0.7764,  0.3452, -0.5584]],\n",
      "       device='mps:0')\n",
      "cls_features:  tensor([[-0.0784, -0.9734, -0.5087,  ..., -0.7161,  0.2959, -0.4213],\n",
      "        [ 0.1297, -1.2213, -0.6848,  ..., -0.6498, -0.0336, -0.6460],\n",
      "        [ 0.3418, -1.1696, -0.6928,  ..., -0.5078,  0.0497, -0.6346],\n",
      "        ...,\n",
      "        [ 0.1107, -0.9384, -0.4480,  ..., -0.7079,  0.1194, -0.5513],\n",
      "        [-0.3396, -0.9687, -0.8067,  ..., -0.9493,  0.2691, -0.6589],\n",
      "        [ 0.0830, -1.1229, -0.5419,  ..., -0.7001,  0.1442, -0.6964]],\n",
      "       device='mps:0')\n",
      "Epoch: 6 | Batch: 30 | Loss: 0.9246 | Acc: 45.36%\n",
      "cls_features:  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 75\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     76\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     77\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[217], line 42\u001b[0m, in \u001b[0;36mViT_Classifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Take the CLS token features (first token)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     cls_features \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Shape: [batch_size, embedding_dim]\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls_features: \u001b[39m\u001b[38;5;124m\"\u001b[39m,cls_features)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Pass through classifier\u001b[39;00m\n\u001b[1;32m     44\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(cls_features)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:566\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    563\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    564\u001b[0m     )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/_tensor_str.py:708\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    707\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _str_intern(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/_tensor_str.py:625\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    624\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m, indent)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    628\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/_tensor_str.py:357\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(get_summarized_data(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/_tensor_str.py:145\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(\n\u001b[1;32m    146\u001b[0m         tensor_view, torch\u001b[38;5;241m.\u001b[39misfinite(tensor_view) \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create random data for testing convergence\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def create_random_data(num_samples=1000, img_size=64, num_classes=3):\n",
    "    # Create random images with a learnable pattern\n",
    "    images = torch.randn(num_samples, 1, img_size, img_size)\n",
    "    \n",
    "    # Create random labels with clear patterns for each class\n",
    "    labels = torch.zeros(num_samples, dtype=torch.long)\n",
    "    for i in range(num_samples):\n",
    "        # Add some pattern to make the data learnable\n",
    "        if images[i, 0, 0:32, 0:32].mean() > 0:\n",
    "            labels[i] = 0\n",
    "        elif images[i, 0, 32:64, 0:32].mean() > 0:\n",
    "            labels[i] = 1\n",
    "        else:\n",
    "            labels[i] = 2\n",
    "            \n",
    "        # Add some noise to the pattern\n",
    "        if torch.rand(1) < 0.1:  # 10% noise\n",
    "            labels[i] = torch.randint(0, 3, (1,))\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Create random datasets\n",
    "train_images, train_labels = create_random_data(num_samples=1000)\n",
    "val_images, val_labels = create_random_data(num_samples=200)\n",
    "\n",
    "# Create dataloaders\n",
    "random_train_dataset = TensorDataset(train_images, train_labels)\n",
    "random_val_dataset = TensorDataset(val_images, val_labels)\n",
    "\n",
    "random_train_loader = DataLoader(random_train_dataset, batch_size=32, shuffle=True)\n",
    "random_val_loader = DataLoader(random_val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "mae = MAE_ViT(\n",
    "    image_size=64,\n",
    "    patch_size=4,\n",
    "    emb_dim=192,\n",
    "    encoder_layer=12,\n",
    "    encoder_head=3,\n",
    "    decoder_layer=4,\n",
    "    decoder_head=3,\n",
    "    mask_ratio=0\n",
    ").to(device)\n",
    "\n",
    "# Load pre-trained weights\n",
    "mae.load_state_dict(torch.load('best_mae_model2.pth')['model_state_dict'])\n",
    "model = ViT_Classifier(mae.encoder).to(device)\n",
    "\n",
    "# Initialize optimizer and criterion\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training on random data...\")\n",
    "best_val_acc = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(random_train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch: {epoch} | Batch: {batch_idx} | Loss: {loss.item():.4f} | Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    train_acc = 100.*correct/total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in random_val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    val_acc = 100.*correct/total\n",
    "    \n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        'random_train_loss': train_loss/len(random_train_loader),\n",
    "        'random_train_acc': train_acc,\n",
    "        'random_val_loss': val_loss/len(random_val_loader),\n",
    "        'random_val_acc': val_acc,\n",
    "        'epoch': epoch\n",
    "    })\n",
    "    \n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    print(f'Train Loss: {train_loss/len(random_train_loader):.4f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss/len(random_val_loader):.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f'\\nEarly stopping triggered. Best validation accuracy: {best_val_acc:.2f}%')\n",
    "        break\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
